[["index.html", "Bio 373L Survival Guide Preface", " Bio 373L Survival Guide Christopher R. Peterson 2022-01-10 Preface This book contains advice for students in the University of Texas at Austin’s Field Ecology course. It will be updated throughout the semester. The first three chapters contain general guidelines for writing lab reports. The subsequent chapters cover the details of specific field problems. The appendices are an extensive tutorial on working with and analyzing data using R. "],["structure.html", "Chapter 1 The Structure of a Scientific Manuscript 1.1 Full Manuscripts 1.2 Preliminary Manuscripts 1.3 Figures and Tables 1.4 Citations/References", " Chapter 1 The Structure of a Scientific Manuscript Most of the work in this class is ultimately in service of writing a manuscripts. By the end of the semester, you will write full manuscripts for five group projects (the labs) and an independent project. This is an iterative process, which we will generally break into preliminary and full manuscripts. Expectations for both of them are below. 1.1 Full Manuscripts The main goal of scientific writing is to effectively communicate complicated concepts. Scientific manuscripts tend to follow a traditional structure that is intended to help an experienced reader navigate these concepts. Each section should answer a question: Abstract: Why should I read this? Introduction: Why did you do this? Methods: What did you do, how did you do it, and what species/locations did yo use? Results: What did you find? Discussion: What does it mean and why does it matter? Literature Cited: Doesn’t really answer a question, but this is where you list the citations you used. Greater detail is provided in the following sections. The five paragraphs identified as “key” are particularly important and are also part of the preliminary manuscripts. 1.1.1 Title This isn’t really a section, but your manuscripts need a title better than “Succession Lab Manuscript.” The title could be a question, a description, or a statement. A few examples: “How will succession drive changes in a Texas ecosystem?” “Red invasive fire ants reduce native species diversity.” “Historical patterns of structural heterogeneity at Brackenridge Field Lab” 1.1.2 Abstract (key) The abstract is a one paragraph summary that functions as an advertisement/elevator pitch for the rest of the paper. A biologist who reads your abstract should have a general idea about what you did, your most important results, and why that matters; ideally, it will be enough to make them interested in reading the rest of the paper. While this section should cover the intro, methods, results, and discussion, you shouldn’t re-use any of your writing from those sections here. Instead, write a sentence or two from each that hits the important points without going into all of the details. In particular, make sure you hit on all four of the other key paragraphs (described below). Don’t cite any figures, tables, or other literature in here. If this is more than 400 words, it is too long. I generally prefer to write my abstract after the rest of the paper is done (or at least mostly done), so that I can summarize the rest of the work. Other scientists like to start with the abstract and use it as an outline for the rest of their manuscript. 1.1.3 Introduction The introduction section sets the stage for the work you are about to describe and should tell your reader why your research is interesting. You should begin by describing the broader ecological context that your research fits into, and review the relevant literature. Start generally and narrow the focus to the specific project you did. The introduction should contain at least three paragraphs (with a minimum of four sentences each). You should cite at least four peer-reviewed papers in this section. 1.1.3.1 First paragraph (key) This paragraph introduces a broad ecological question that is relevant to your research. You will not be answering this question directly (a single paper couldn’t possibly do this; instead, your manuscript will examine a tiny part of it). Ultimately, you need to establish large-scale context so that the reader can understand how your work fits in with the broader context. You should not mention your study site (e.g., BFL) or your specific questions here; in most cases, your specific study species should also be avoided. 1.1.3.2 Last paragraph (key) This is where you state and explain your goals, purpose, questions, and hypotheses. While previous paragraphs are fairly general, this should be focused on what you tried to answer with your research. This serves as a good buildup to the methods section (where you talk about how you answered your questions; don’t do that here). You should talk about additional information that is relevant to understanding your question in this paragraph. For example, if your question is about a somewhat abstract process (like succession), this is where you would want to link it to some more measurable proxy (like canopy to sapling ratios). Be careful, though; it can be very easy to start talking about material that belongs in the methods section. 1.1.3.3 Middle paragraphs These bridge the first &amp; last paragraphs and are often useful for narrowing the focus from general to specific. This is a good place to review specific examples of your broad question from paragraph 1 and discuss limitations of previous research (particularly if your study will address those). If your broader subject has been studied in your species or site before, a middle paragraph would be a good place to introduce/review that. However, a general description of your study site or species is not appropriate for this section. That belongs in the methods. 1.1.3.4 An example Let’s say you’re writing a paper about the temperature tolerance of the three-eyed sandslider (Trioptis cerastes), a fictional snake species that is native to southwestern deserts. A reasonable introduction could discuss the following: Climate change in general. Severity and effects of climate change in deserts. Effects of higher temperature on ectotherm behavior. Temperature tolerance in the three-eyed sandslider. Alternatively, you could introduce the same paper in a completely different context: The evolution of animal activity budgets. Effects of temperature on foraging and reproductive behavior in ectotherms. Temperature tolerance in the three-eyed sandslider. There are many more potential ways to write this paper. The take home message is to set your specific project within the bigger picture of a large-scale concept, phenomenon, or issue. 1.1.4 Methods This section includes detailed information on your experimental setup, data collection procedures, and the statistical analyses you used. If your project focused on specific species or sites (e.g., BFL), you should start by describing these. It is often useful to organize the methods section into sub-sections. For example, for the temperature tolerance example could have the following sub-sections: Study Site Study Organism Experimental Design / Data Collection Statistical Analyses You should always include a description of all of the statistical methods you used in the methods section. This includes the test(s) performed, the predictor (independent) and response (dependent) variables, and the program used. That being said, redundancy isn’t necessary; if you did all of your analyses in R, you can simply state “All analyses were done in R v. 4.1.2.” at the end of the paragraph. 1.1.4.1 Study Site/Species Sometimes, it can be tricky to figure out if background information on your study site/ species goes in your methods section or the introduction. My suggestion: previous research on your study system that directly relates to your broader question should go in a middle paragraph of the introduction. Anything else goes in the methods. You can include sections in both. 1.1.5 Results This is where you describe your observations and the results of any analyses. Make sure you do not include new methods (including new statistical analyses) in this section; these belong in the previous section. The most important results should be presented as figures or tables (see chapter 3). However, they must also be described in the paragraph. Related results should be presented together; for example, if you created figures that showed the relative proportion of species among age classes and also ran a Chi-squared test on species-by-age class counts, you should present them together in the same sentence. It can be a good idea to organize this section into sub-sections as well, if you had multiple different sets of analysis. 1.1.5.1 Reporting statistics In general, you should begin by presenting the relevant summary statistics (such as means for measured data and frequencies for categorical data). For example, ‘The mean temperature tolerance was \\(39.2 \\pm 0.45 ºC\\) for males and \\(37.1 \\pm 0.25 ºC\\) for females.’ Notice that the temperature has units (degrees Celsius) and that I put the standard deviation after the mean. This is good practice when reporting means. When reporting statistical test results, state what they mean in words first, and then follow the statement with a parenthetical phrase containing the statistics. For example, ‘Males tolerated significantly higher temperatures than females (\\(t = 1.96\\), \\(df = 6\\), \\(p = 0.04\\))’. Notice that I included the computed t-statistic, the degrees of freedom and the p-value. All these should be reported when reporting t-test results. Note also that I indicated the direction of the difference, as well as its significance. Here is another example: ‘The number of escape behaviors performed increased significantly at high temperatures for all snakes (\\(\\chi^2 = 8.43\\), \\(df = 2\\), \\(p = 0.001\\); Figure 2)’. This is an example of how you would report chi-square test results. Again, the results are stated in words that have biological meaning and are followed by the calculated test statistic, the degrees of freedom and the p-value in parentheses. Note that I’ve also cited a relevant figure here. If your statistical analyses did not find a significant difference, you still need to report this. For example: ‘Although temperature tolerance was slightly higher for males than females, this difference was not statistically significant (\\(t = 0.657\\), \\(df = 6\\), \\(p = 0.14\\); Figure 3).’ Do not use the word “insignificant” in this context. Be sure to state your results in a biologically meaningful manner. A common mistake is to write out the results in statistical terminology without any reference to their biological meaning. For example: ‘A t-test resulted in a p-value of 0.03 meaning that we can reject the null hypothesis and accept the alternative.’ While this is a correct statistical interpretation of the calculated p-value, it tells the reader nothing about the trees or ants or mushrooms that you were studying. Do not write up your results like this; it’s unpleasant to read and you’re just going to have to fix it in revisions. 1.1.5.2 Do not interpret your data here Do not interpret your data in the results. That belongs in the discussion. Do not consider explanations for your data in the results. That belongs in the discussion. Do not consider how your data relates to your hypothesis in the results. That belongs in the discussion. This is probably the most common mistake I’ve encountered in grading student lab reports. 1.1.6 Discussion The discussion is where you should interpret your data and draw conclusions by comparing your data to what is known from the published literature. The organization of this section is a mirror-image of the introduction in terms of its organization: start narrowly, by discussing how your results relate to your original hypotheses and questions. Follow it up with a wider discussion of how these results fit into the broad concept with which you introduced the paper. This should not be a restatement of what you wrote in the introduction or in the results, but should be an exploration of the meaning of all those numbers you just crunched and what they might signify. Be careful not to make unfounded statements. There are often many potential explanations for obtaining a particular result. One may seem more likely than the others, but this does not exclude the other explanations from being true if you haven’t actually tested them. A good way to handle this is to mention the multiple alternative interpretations, express support for the one you think is most likely and explain why, then suggest a future experiment that could be done to test whether or not that is correct. 1.1.6.1 First Paragraph (key) Your result section will likely have a variety of different analyses presented in a technical manner, which may answer a variety of different questions. This paragraph should tell the reader what the most important results were, as they relate to your specific questions/hypotheses from the end of the introduction. Minor analyses, assumption checks, or other sideshows from the results can be ignored here. You should end the paragraph by talking about the biological implications/interpretations of the results, and how they relate back to your goals/hypotheses. 1.1.6.2 Last paragraph (key) This one is the most challenging of the key paragraphs to write, and is a bit less prescribed. Generally, this should connect your primary results back to the broad question from the beginning of the introduction. Ideally, this would be a great place to make a novelty statement, where you discuss how your research has moved the field forward. That can be difficult (particularly for the group projects, which have been done twice a year for the past 2 decades), so another good option is to talk about what new questions your research raises that are worth further investigation. 1.1.6.3 Middle paragraphs Between the first and last paragraphs is a good place to talk about your results in more detail, acknowledge limitations, and talk about how they relate to the literature. In particular, this is a good place to talk about some of the side-results that you omitted in the first paragraph. Consider multiple explanations, if you can. These paragraphs are also a decent place to suggesting technical improvements for future research (but not new research directions). An example: The lower temperature tolerance in females presents several possible explanations. Females are the smaller sex, meaning that they would heat up faster than males due to a greater surface area:volume ratio (Loblaw and Bluth, 2005). Alternatively, it is possible that the males had higher tolerance because their overall activity levels were lower in the experimental enclosures, which could have given them lower initial internal temperatures that would take longer to reach critical levels. The amount of activity required to create a relevant temperature change would suggest that this is an unlikely option, however. Future work could address this by taking internal temperature readings before and after temperature tolerance trials. 1.1.7 Literature You must use a minimum of six primary literature sources in your report, with at least four sources in both the introduction and discussion (it’s fine to have some overlap). Use the sources to provide background, to aid in justification of performing the project, support for your interpretation of results, etc. In some cases, you should also cite a reference in the methods section (e.g., for a non-standard data collection technique or to provide information on a study site/species). Do not cite papers in results. All thoughts, ideas, concepts, etc., that you didn’t think up on your own must be cited in the text (failure to do this is considered plagiarism). Sources need to be relevant to your lab report at more than just a surface level. For example, if your lab report is on the distribution of cottonwoods at BFL, a paper about the cottonwood’s genomic structure is probably not going to be relevant. Please note that while there is a minimum of six primary literature sources, you are encouraged to add more. Bringing in information from extra papers can really strengthen your introduction/discussion. There will be a weekly thread on Canvas to share literature relevant to the lab report; you are expected to contribute two citations to it each week. Additional guidelines on using the literature are available in the Writing Style Chapter. 1.2 Preliminary Manuscripts The first stage of manuscript writing in Bio 373L is preliminary manuscript. For this class, a preliminary manuscript is an important subset of a manuscript that will let me evaluate your writing and analysis before you spend the time to complete the whole manuscript. Preliminary manuscripts consist of: A good title An abstract The first &amp; last paragraphs of the introduction A brief list of analyses &amp; their results Your figures &amp; tables The first &amp; last paragraphs of the discussion At least four references All guidelines on writing content &amp; style should be followed. 1.2.1 The Five Paragraphs The five most important paragraphs of a paper are the abstract and the first &amp; last paragraphs of the introduction and discussion. These have been described in the full manuscript section; for a complementary view, read this excellent blog post. Submitting them as the first part of your manuscript gives me an opportunity to provide feedback faster and reduce the amount you’ll need to change or revise if you are really off-base. 1.2.2 List of Methods &amp; Analyses You should briefly list out your methods (you can use bullet points) and the associated statistical results. This can be as formal or informal as you’d like. The main point I’m interested in is the analyses you ran; you should make sure to state reason for the analysis (e.g., to compare sapling vs. canopy tree ratios in each habitat), the test you use, the statistical results (test statistics, p-values, etc), and the interpretation (e.g., no significant difference in ratios). You should also cite your relevant figures. 1.3 Figures and Tables You should create figures &amp; tables (with their associated captions) that you intend to include in the final report. Please follow all guidelines in Chapter @(figures). 1.4 Citations/References You will need to have at least two citations in your intro and two in the discussion (with a total of four unique citations). This number will be expanded to six for the final manuscripts. Please make use of the literature threads on Canvas. "],["style.html", "Chapter 2 Content and Style of an Effective Manuscript 2.1 Be Concise 2.2 Sentence Structure 2.3 Passive Voice 2.4 Using the literature in your paper (This is a common source of mistakes) 2.5 Word Choice 2.6 Scientific and Common Names 2.7 Other Grammar 2.8 Commonly Confused Definitions 2.9 Significant Digits 2.10 Tenses", " Chapter 2 Content and Style of an Effective Manuscript It’s easy to write a scientific report that confuses or bores the audience. Developing a style that keeps the reader following along can be a challenge, but it is a necessary one. This chapter contains a number of stylistic suggestions that can improve your lab reports. There isn’t ‘one true style’ for scientific writing, but I’ve found that these guidelines can help when you’re starting out. 2.1 Be Concise Parsimony is often held up as an ideal in science; if the evidence equally supports two explanations, we tend to prefer the simpler one. The same applies to scientific writing. When grading previous student lab reports, I’ve noted a bad tendency to over-explain every single detail (particularly in the methods section). Avoid providing information that is unnecessary to understand the project, and don’t over-describe straightforward tasks. If you have a long repetitive section, think of a way to express the same information in a shorter space. Here’s an example from a methods section that needs to be trimmed: “We created imaginary lines passing through each sample point that were parallel and perpendicular to the transect and used these lines to create four quadrants. One member of our group would carefully pace towards the closest canopy tree in each quadrant. This was repeated by the same group member for each sapling tree. Later, we converted our pace counts into meters by measuring the number of paces that group member took to walk ten meters. A different group member measured the diameter at breast height (DBH) of each canopy tree by holding up a ruler to the side of the tree. The third group member recorded the data.” The important information could be condensed into this: “We divided the area around each point into four quadrants, which were parallel and perpendicular to the transect. For each quadrant, we estimated the distance to the nearest canopy and sapling trees and recorded the diameter at breast height (DBH) of the canopy tree.” The same details apply for describing calculations or analyses. For standard or widely used procedures (such as a chi-squared test, or calculating relative abundance), you do not need to provide the formula that you used. In general, focus on what you did: “We used a chi-squared test to determine whether the proportions of the five most abundant species differed between canopy and sapling trees.” not the exact procedures you used to do it “We created a contingency table in Excel using pivot tables by …, then calculated the expected values by … From this we calculated the chi-square test statistic with the formula…, determined the degrees of freedom from …, and calculated the p-value with the Excel function…”. A more specialized or non-standard calculation may need to be explained (“The density at a point was estimated as \\(N / \\text{sum}(x^2)\\), where N was the number of quadrants with trees and x is the distance to the tree.”), but should also not be over-explained. The same applies to the results. If you did three similar analyses to different data sets, you should try to describe the outcomes in parallel. Instead of doing this: “Activity significantly increased with temperature in sample 1 (r = …, t = …, p = …; Figure 1). … Activity significantly increased with temperature in sample 2 (r = …, t = …, p = …; Figure 2) … Activity did not increase significantly in sample 3 (r = …, t = …, p = …; Figure 3).” You should consolidate: “Activity significantly increased with temperature in sample 1 (r = …, t = …, p = …; Figure 1A) and sample 2 (r = …, t = …, p = …; Figure 1B), but not in sample 3 (r = …, t = …, p = …; Figure 1C).” Similar advice applies to figures. 2.2 Sentence Structure Your writing should flow. When moving between topics (or sub-topics), it is helpful to include transitional elements (words, phrases, or sometimes entire sentences) to help the reader follow your train of logic. This doesn’t mean that you should start every few sentences in the Methods section with “Then, we [did something] …”. Some good words and phrases to use include “Following ___,” “Furthermore,” “However,” “Alternatively,” and “Yet,” etc. Note that transitions aren’t necessary when you are starting a new section (e.g., Methods) or labeled sub-section. Each sentence should serve a purpose (in terms of communicating information). If two or more sentences are doing the same job, try to combine them (or delete one). Conversely, sentences that are doing too much should be split. Avoid garden-path sentences and lengthy sentences that require multiple reads to understand. 2.3 Passive Voice While there are circumstances in which passive voice is useful, it is often misused in scientific writing. Many students feel that passive voice conveys a sense of objectivity. In many cases, it just obscures and adds unnecessary wordiness. This is particularly common in methods and results sections. You (in either the singular or plural sense) performed the observations or experiment; you did the calculations and analysis. You should take credit for it. If you are worried about starting every sentence with I/we, there are other ways to restructure your writing. For the record, I am not banning the use of passive voice. It can be effectively used alongside active voice when appropriate. However, I’d recommend taking a look at your passive sentences and considering if active voice would make them more straightforward. 2.4 Using the literature in your paper (This is a common source of mistakes) 2.4.1 Be specific and concice with your citations Most of the time, you cite a paper to inform the reader about specific facts or observations. You should focus on these facts when writing and use a parenthetical citation. For example: The point-quarter technique is an effective and reliable way to estimate canopy cover in the field (Smith et al., 2018). You generally don’t need to provide background on how the study you’re citing was conducted or what else they found; only talk about the part that’s relevant to what you’re trying to communicate. The following are all variations on things I’ve seen: Bad: In 2016, Garfield et al. conducted a study on the three-eyed sandslider (Trioptis cerastes) in southern Arizona, where they found that high temperatures decrease foraging activity. Bad: In their paper “Effects of extreme temperatures on Trioptis cerastes activity patterns,” researchers from the University of Fantasia found that sandsliders forage less in high temperatures (Garfield et al, 2016). Good: For example, three-eyed sandsliders (Trioptis cerastes) forage less under high temperatures (Garfield et al, 2016). In general, if you find yourself writing “In a study…”, you should see if you can reword it to focus on the important facts. 2.4.2 Do not include direct quotes from the literature Do not include direct quotes from the literature. Do not include direct quotes from the literature. Do not include direct quotes from the literature. Do not include direct quotes from the literature. I understand that this is a common practice in some parts of the humanities and social sciences. It is not acceptable here. Pull out the information that’s relevant to your paper and use that to support your broader point. 2.4.3 Where citations belong There should be multiple citations throughout the introduction and discussion. Occasionally, you’ll need to cite something in the methods. Don’t cite papers in the results. You are presenting your results, not somebody else’s. If you want to do this, it’s probably something that should be in the discussion. Don’t cite the literature in the abstract unless your entire manuscript is a response to another paper (which is unlikely to happen in this class). 2.5 Word Choice It’s tempting to use longer, more technical sounding words when writing a scientific paper. This tends to make papers harder to read with no benefit. The same is doubly true for awkward multi-word phrases that can be replaced with one, simple word. Two common offenders: Utilize: In almost every case, “use” is the better choice. “Utilize” is really only applicable for situations in which the object being used was not designed for the task to which it is being put. Even in that situation, “use” is still preferable. There are a few minor areas of biology where “utilize” is correct, but for now, stick to “use.” Approximately: use “about.” 2.6 Scientific and Common Names Latin binomials should be italicized, with genus capitalized and specific epithet in lowercase (e.g., Ulmus crassifolia). Only write the full scientific name the first time it appears in a section; afterwards, you can abbreviate the genus (e.g., U. crassifolia). At that point, stick to the abbreviation; don’t switch back and forth. Exception: You should never start a sentence with the abbreviated form. Don’t capitalize common names except for proper nouns e.g., American elm, cedar elm, Ashe’s juniper, sugar hackberry. The first time a species is mentioned, its scientific name should be given. If after that you want to just use the common name, that is fine, as long as you also gave the common name the first time. E.g., first time – ‘…..cedar elm (Ulmus crassifolia) was found in all three habitats…..’ Later ‘….the prevalence of cedar elm could be due to….’ OR ’….the prevalence of U. crassifolia could be due to…. 2.7 Other Grammar Put a comma after an introductory prepositional phrase. E.g., ‘In the pasture habitat, cedar elm was…’ or ‘During the most recent drought, laurel cherry has…’ I generally prefer Oxford commas. While you aren’t required to use them, be consistent. Please only capitalize proper nouns, acronyms, and the appropriate parts of scientific names. 2.8 Commonly Confused Definitions Population and Community: A population is a collection of individuals of the same species in a particular geographic area. E.g., all the cedar elm individuals at BFL A community is a collection of individuals of different species found in a particular geographic area. E.g., all the trees found at BFL Random and Haphazard Truly random points would be pre-selected in the lab before heading outside using a random number generator and using those randomly selected numbers as our coordinates. Haphazardly selected points follow the colloquial definition of ‘random.’ It’s sort of like the scientific vs. common usage of the word “theory.” Affect and effect While there are nuances and exceptions, affect is generally a verb and effect is usually noun. 2.9 Significant Digits We generally aren’t using high-precision instruments. As such, you should round numbers with a large number of decimal places to an appropriate extent (Note that ecologists usually don’t follow significant figures rules quite as strictly as chemists and physicists). Generally, p-values should be rounded to four digits (and noted as &lt; 0.0001 if they’re smaller than that), while test-statistics should probably have no more than two decimal places. For everything else, use your judgment. 2.10 Tenses Make sure to use the appropriate tense in each part of the report. If you’re reporting what you did (e.g. in the Methods) or what someone did in another study (e.g. in the Introduction or Discussion) then use the past tense. Also use the past tense in the Results, because the results were recorded/found in the past. However, when discussing context and theory currently held to be true (in the Introduction and Discussion), make sure to use the present tense. Future tense will typically only be used when suggesting a potential future follow-up study/studies, usually in a small section at the end of the Discussion. ## Hypotheses vs. Null Hypotheses Null hypotheses are statistical tools used for certain tests (e.g., a null hypothesis for a chi-squared test would be that the groups are independent, or that there is no difference in the species proportions between two age classes). These don’t belong in the introduction or discussion. For these sections, you should present your biological hypotheses (e.g., “BFL is undergoing succession”). It is usually a good idea to include a concrete prediction of these hypotheses in the introduction as well (e.g., “BFL is undergoing succession, which will be indicated by a difference in the relative abundances of canopy and sapling trees”). "],["figures.html", "Chapter 3 Figures and Tables 3.1 Captions 3.2 Figures 3.3 Some Example Figures 3.4 Tables", " Chapter 3 Figures and Tables Good figures are one of the most important parts of a manuscript. When learning to write scientific papers, some might view figures as an afterthought. This is a mistake. The figure should tell a fairly complete story. Combined with its caption, the reader should be able to look at the figure immediately after reading the abstract and have a general sense of what’s going on. Tables are also an important part of a paper’s results, but good figures are usually easier to interpret by the reader. Note that this chapter focuses on general guidlines for figure design. For instructions on how to create figures in R using ggplot2, see Chapter 5. The R code used to generate all of the figures in this chapter can be found here, along with some annotations. 3.1 Captions Figures and tables require captions that explain what they represent. Captions should be below figures and above captions. The first “sentence” of a caption shouldn’t actually be a sentence; it’s more of a description. See the various examples in this chapter for more details. The caption should help the figure or table stand alone from everything else. If there are abbreviations or acronyms in the figure, they should be defined in the caption. If your figure is related to a statistical test, you should present the results of the test in the figure caption. If there’s a line of best fit in a scatterplot figure, this means that a linear regression was performed behind the scenes; you should report the details. Note that figures in your manuscript should not have titles. This information belongs in the caption. 3.2 Figures Make sure the caption (and legend, if present) gives enough information that the reader can understand exactly what the figure/table represents without having to look at the text. DO refer to all tables/figures in the body of the text, and include them in order (i.e. the first table/figure the reader comes across should be called table 1/figure 1 and should be the first one referred to in the text). Note that in this chapter, the figures are numbered 3.1, 3.2, etc; this is appropriate for a multi-chapter book, but not for a paper/article/manuscript. Don’t use decimals. Figures should communicate your results, not just present/summarize your data. A good figure tells a story. If there is a trend or pattern, it should be designed to emphasize it. 3.2.1 Specific Figure Guidelines Figure design is communication, so you want to make the result/message as obvious as you can. The longer a reader has to stare at your figure before “getting it,” the more likely they are to get bored or stop caring. Avoid large amounts of empty white space. For categorical data, you should remove categories that have no data unless their absence is somehow important and interesting. For example, if you are surveying trees and a species is not observed, there’s no reason for it to be in the figure. Is your figure emphasizing what it should? If you’re contrasting two groups, are they clearly contrasted? Could re-ordering the groups improve the contrast? If you’re comparing groups of frequencies, you should order them from highest to lowest frequency. If you are trying to show a trend, is it being adequately emphasized? Please note that this doesn’t mean cheating, or changing the data. The axes and legends should be clear. Often, the default axis or legend names will be the label of a specific cell or column. You can change these defaults. Consider how your figure will look to other people. How will it look if printed from a black and white printer? Hint: the default blue and orange colors in Excel are indistinguishable in gray scale; the same is true for the default ggplot2 palette in R. How would it look to someone with color blindness? -If using R, the Viridis color scales work nicely for this. Please remember that you should be writing your lab reports as if the reader (i.e., me) didn’t know exactly what you did. 3.2.2 Be Concise If you have multiple figures that conceptually belong together (e.g., the same measurements taken in three years), you should turn them into a single multi-panel figure. Label your the panels with letters in the upper left corner; the caption should explain how the panels are different. 3.3 Some Example Figures 3.3.1 General Formatting Figure 3.1 is poorly formatted: The colors are hard to distinguish when printed and black and white; The axis and legend text are showing the default labels instead of informative values; There is a lot of white space, partially due to a bad y axis scale; The equation is in the figure instead of the caption; The caption is vague and uninformative; There is an unnecessary title; There are grid lines; Figure 3.1: Body mass (X variable) vs flipper length (Y variable). The regression is significant (\\(R^2 = 0.76\\); \\(p&lt;0.0001\\)). Figure 3.2 contains the same data, but has been reformatted to address these issues. Note the use of units in the axis labels, the formatting of scientific species names, the positioning of the legend to minimize whitespace, and the lack of a title and gridlines. This is also an example of how to plot data with a continuous response and a combination of continuous and categorical predictors. Figure 3.2: Association between body mass and flipper length in three species of penguin. Flipper length increases with body mass ((Flipper Length) = 13.7 + 1.5*(Body Mass); \\(R^2 = 0.76\\); \\(p&lt;0.0001\\)). Figure 3.3 is an example of a multi-panel figure; in the text, you should refer to parts of it as Figure 3.3A, 3.3B, etc. Figure 3.3: Association between bill length and bill depth for three species of penguins. The association is significant and different among species ((Bill Depth) = 10.6 + 0.2*(Bill Length) for Adelie, 5.5 + 0.2*(Bill Length) for Gentoo, and 8.7 + 0.2*(Bill Length) for Chinstrap; \\(R^2 = 0.77\\); \\(p_{\\text{species}} &lt; 0.0001\\); \\(p_{\\text{length}} &lt; 0.0001\\);) 3.3.2 Continuous response, categorical predictors There are a number of options for representing continuous data grouped into multiple categories. You should avoid “dynamite” plots (Figure 3.4), which use a bar with error lines to represent a mean and standard error; these figures use a lot of space to provide very little information. A better option is to use box plots (Figure 3.5), which show the median, quartiles, range, and outliers of each group. Equivalently, you could use a group of histograms (Figure 3.6). A particularly effective way to visualize this type of dataset shows the distribution of the data and the summary statistics (Figure 3.7). Figure 3.4: Mean body mass for three species of penguin, with standard errors. Body mass differs significantly among species \\((p &lt; 0.0001)\\). Figure 3.5: Distribution of body mass for three species of penguin. Body mass differs significantly among species \\((p &lt; 0.0001)\\). Figure 3.6: Distribution of body mass for three species of penguin. Body mass differs significantly among species \\((p &lt; 0.0001)\\). Figure 3.7: Distribution of body mass for three species of penguin, with mean and standard errors in red. Body mass differs significantly among species \\((p &lt; 0.0001)\\). 3.3.3 Categorical, count, or frequency responses These sorts of data usually involve examining how counts or frequencies differ among groups; they’re often associated with \\(\\chi^2\\) tests. Generally, it’s best to represent these sorts of data with bar graphs (avoid pie charts). When making a bar graph, it’s a good idea to arrange your data to emphasize any trends. The species in Figure 3.8 are organized alphabetically, which obscures any trend. A better option is to organize by decreasing frequency of either total counts (like in Figure 3.9) or of one of the groups (Figure 3.10). These make it easier to detect patterns. Figure 3.8: Number of Anolis captured from canopy and trunk perches. Figure 3.9: Number of Anolis captured from canopy and trunk perches. Figure 3.10: Number of Anolis captured from canopy and trunk perches. An important consideration is whether to represent your data with counts or proportions (AKA frequencies – vary from 0 to 1). There are pros and cons to both approaches, but frequencies are usually better if the number of observations differs among your groups (compare Figure 3.11 with Figure 3.10). Be careful when calculating frequencies, because you may inadvertently end up making a graph that isn’t answering the question you’re trying to ask. For example, Figure 3.11 shows how anole frequencies differ between perch types, but Figure 3.12 shows the frequency at which each species occupies the two perches. Figure 3.11: Frequency of Anolis species captured from canopy and trunk perches. Figure 3.12: Perch frequency for 9 species of Anolis. If there is some aspect of your data that you’d like to really emphasize, it can help to get more creative with your figures. For example, the most visually striking parts of Figure 3.13 are the colored sections of the bars, which correspond to the direction and magnitude of the difference between perches for each species. Do note that making more complicated figures may require extra explanation in the caption. Figure 3.13: Number of Anolis found at each perch position. The white bar indicates the count at the less frequent perch, the total height is the count at the more frequent perch, color indicates which perch the species was more common at, and the size of the colored regions indicates the difference between perches. 3.4 Tables Tables are an effective addition to a manuscript when you have a lot of data in the text and want to present it to the reader in an organized fashion. They are particularly helpful when you have a lot of different kinds of data that would be hard to plot together. For example, see Table 3.1. Tables are best for highly structured data. If there isn’t much data to present, the data can usually just be presented in the text of the results. If there’s a lot of data, it is worth considering if a figure would be better. Table 3.1: Standard length of three populations of rainbow trout (Oncorhynchus mykiss) in Southern Appalachian streams. Group A was collected from the New River, group B from the Watauga River and group C from Winkler Creek. Group N Mean Std. Dev. Min. Max. A 10 35.33 3.53 30.74 37.02 B 15 42.61 4.62 36.36 49.17 C 12 22.00 2.97 17.99 26.38 "],["working-with-r-and-rstudio.html", "Chapter 4 Working with R and RStudio 4.1 Introduction to RStudio 4.2 R basics", " Chapter 4 Working with R and RStudio This section include a tutorial on some data analysis topics that will be helpful for this class. Please make sure you’ve installed R and RStudio, and some essential packages according to this guide. You can skip installing git for now. 4.1 Introduction to RStudio RStudio is organized into four panels: scripts &amp; documents (upper left), the console (lower left), and two utility panels on the right that have various helpful functions. You may not see a document window on the left; if so, hit Ctrl+Shift+N to create a blank script. (Note that on Macs, Ctrl should pretty much always be replaced with Cmd). Generally, you write all of your code in the document window, then hit Ctrl+Enter (Cmd+Return) to send the R statement your cursor is on to the console window. 4.1.1 RStudio Projects RStudio’s most useful feature is R projects, which automatically manage a lot of the tedious things that can normally cause problems when working with R. Most importantly, they make it easier to keep track of where your script, data, and output files are. Let’s create a project for Bio 373L. In the upper right corner, click the down arrow next to Project: (None) (if it says something else, that’s fine), then select New Project…. Select New Directory -&gt; New Project, then give it a name relevant to the class. I’d recommend making the project a subdirectory of where you keep the rest of your 373L files. Create the project; RStudio will take a moment to reset, then the upper-right corner of the screen should have the name of your project. Always make sure the project is loaded when you’re working on material for this class; if it isn’t, just click the project drop-down arrow and select it from the list. Now that your project is loaded, click the Files tab in one of the two utility panels; this shows everything in the project directory. All of the script &amp; data files you work should be put in this directory. I recommend creating a folder for each lab (click the New Folder button) to keep things organized. If you want to open the folder in Windows Explorer/Finder/whateverfile manager you use, click the More button, then Show Folder in New Window. 4.1.2 Customizing RStudio I have a couple of recommendations for customizing RStudio to make it easier to use. Go to Tools -&gt; Global Options. Under the General tab, make sure that the Workspace options are unchecked and set to Never; this will make sure you start with a fresh slate every time you start up R and prevent some weird errors from cropping up. Under Appearance, I’d take a look at some of the Editor themes. I’m rather fond of Vibrant Ink. Under Pane Layout, you can reorganize your panels. I like to put the Console in the lower right, and make sure that the lower left pane contains only History, Connections, Packages, and Tutorial. I generally find those four functions to be generally useless, so I can keep that pane minimized and have a larger document window on the left. 4.2 R basics 4.2.1 Statements &amp; vectors Let’s take a look at some R basics. First, R can be used as an excessively fancy calculator. The following block contains R expressions, followed by the results of running them in the console (preceded with ##). Try running it yourself. (4^2 + 8)/10 ## [1] 2.4 log(5) + 12 ## [1] 13.60944 sqrt(abs(-20)) ## [1] 4.472136 R works naturally with vectors of numbers (or text). 1:10 # Create a sequence of numbers ## [1] 1 2 3 4 5 6 7 8 9 10 c(1, 4, 9, 12, 98.7) # use c() to make a vector ## [1] 1.0 4.0 9.0 12.0 98.7 c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;) # Here&#39;s a character vector ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; # Most operations work with vectors (1:10) + 2 ## [1] 3 4 5 6 7 8 9 10 11 12 (1:5) + c(10, 20, 30, 40, 50) ## [1] 11 22 33 44 55 # Vectors can only be of one type; mixing numbers &amp; text will convert them all to text c(&quot;I have been at UT for &quot;, 5, &quot;Years&quot;) ## [1] &quot;I have been at UT for &quot; &quot;5&quot; &quot;Years&quot; Note that anything following a # is a comment, and ignored by R. I highly advise using comments to document your code. 4.2.2 Variables You can save values &amp; objects by creating variables. # You can use either &lt;- or = to assign a variable first_ten &lt;- 1:10 second_ten = 11:20 # Run the variable&#39;s name to see it&#39;s value (this is callled printing) first_ten ## [1] 1 2 3 4 5 6 7 8 9 10 second_ten ## [1] 11 12 13 14 15 16 17 18 19 20 # You can use variables just like you would use their values first_ten + 1 ## [1] 2 3 4 5 6 7 8 9 10 11 first_ten + second_ten ## [1] 12 14 16 18 20 22 24 26 28 30 # Note that variable names are case-sensitive first_Ten # doesn&#39;t work ## Error in eval(expr, envir, enclos): object &#39;first_Ten&#39; not found 4.2.3 Reading &amp; working with data frames Before we get started with this you’ll need to download an example data file. From RStudio, create an example_data directory, then save this file in it (make sure the name is still anoles.csv). Note that you may need to go to go to **File -&gt; Save Page As…* (or some variant) in your web browser to save it. Now, let’s load the data into R. To do that, we need to load the readr package, which is part of the tidyverse. We will be using the read_csv() function. Note that there’s also a read.csv() function; don’t use that one, it has a tendency to change the column names of your data. RStudio also has some built-in ways to load datasets; I would strongly advise not using them, because it makes it harder to go back &amp; repeat your analysis if something changes. library(tidyverse) lizards &lt;- read_csv(&quot;example_data/anoles.csv&quot;) # Note that the path is relative to your project directory. This is a data frame (effectively a spreadsheet). Technically, it’s a type of data frame called a tibble, which doesn’t really matter for what we’re doing right now. Let’s take a look at it: # quick view of data frame; note that there&#39;s more columns and rows lizards # listed than are displayed ## # A tibble: 657 x 9 ## Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 A Green 14.3 6.46 8 164 61.8 43.9 Other ## 2 A Brown 12.3 5.82 18 151 57.1 42.2 Tree ## 3 A Blue 10.5 4.29 36 130 49.1 25 Building ## 4 A Brown 10.3 5.29 31 131 51.2 38.2 Tree ## 5 A Brown 10.9 5.69 20 138 51.5 46.9 Shrub ## 6 A Brown 10.4 5.84 25 137 45.3 59 Shrub ## 7 A Green 11.1 5.91 7 138 49.7 47.6 Building ## 8 A Brown 10 5.09 20 141 48 34.9 Tree ## 9 A Brown 12.3 7.2 19 129 54.9 61 Tree ## 10 A Brown 11.2 6.66 15 134 52.7 50.4 Tree ## # … with 647 more rows # Look at the first few rows of each column glimpse(lizards) ## Rows: 657 ## Columns: 9 ## $ Site &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;… ## $ Color_morph &lt;chr&gt; &quot;Green&quot;, &quot;Brown&quot;, &quot;Blue&quot;, &quot;Brown&quot;, &quot;Brown&quot;, &quot;Brown&quot;, &quot;Gree… ## $ Limb &lt;dbl&gt; 14.3, 12.3, 10.5, 10.3, 10.9, 10.4, 11.1, 10.0, 12.3, 11.2… ## $ Mass &lt;dbl&gt; 6.46, 5.82, 4.29, 5.29, 5.69, 5.84, 5.91, 5.09, 7.20, 6.66… ## $ Diameter &lt;dbl&gt; 8, 18, 36, 31, 20, 25, 7, 20, 19, 15, 31, 35, 10, 19, 30, … ## $ Height &lt;dbl&gt; 164, 151, 130, 131, 138, 137, 138, 141, 129, 134, 143, 150… ## $ SVL &lt;dbl&gt; 61.8, 57.1, 49.1, 51.2, 51.5, 45.3, 49.7, 48.0, 54.9, 52.7… ## $ Tail &lt;dbl&gt; 43.9, 42.2, 25.0, 38.2, 46.9, 59.0, 47.6, 34.9, 61.0, 50.4… ## $ Perch_type &lt;chr&gt; &quot;Other&quot;, &quot;Tree&quot;, &quot;Building&quot;, &quot;Tree&quot;, &quot;Shrub&quot;, &quot;Shrub&quot;, &quot;Bu… # View the data in an RStudio pane View(lizards) Each column of the data frame is a vector of the same length. We can pull our columns and work with them directly: # Let&#39;s extract the color column lizards$Color_morph lizards[[&quot;Color_morph&quot;]] pull(lizards, Color_morph) # requires dplyr package, which is in the tidyverse # Note that some of these require quotes, some of them don&#39;t; this is # I haven&#39;t included output here, because it&#39;s rather long 4.2.4 Functions Pretty much everything that isn’t data is a function. Some of the examples we’ve used include log, abs, read_csv, and mean. Most functions have arguments, which tell the function what to work with. For example: mean(x = 1:5) # mean of 1 through 5 ## [1] 3 sd(x = lizards$Mass) # standard deviation of lizard mass ## [1] 1.088521 Functions can have multiple arguments; for example log has the arguments x and base. Arguments can be matched by name or by their position. Some arguments have default values that are used if the argument isn’t provided. log(x = 1:5) # argument is matched by name; base uses it&#39;s default value ## [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379 log(1:5, base = 10) # specifies a base; this overrides the default ## [1] 0.0000000 0.3010300 0.4771213 0.6020600 0.6989700 log(1:5, 10) # same as above, but matched by position ## [1] 0.0000000 0.3010300 0.4771213 0.6020600 0.6989700 4.2.5 Getting Help R has a built-in help system to look up functions, their arguments, and what they do: ?read_csv ?mean ?log "],["ggplot-tutorial.html", "Chapter 5 Making graphs in R with ggplot2 5.1 Components of a plot 5.2 Aesthetics and scales 5.3 Geometry 5.4 Facets 5.5 Changing the theme, axis titles, &amp; other visual elements 5.6 More references", " Chapter 5 Making graphs in R with ggplot2 5.1 Components of a plot In this chapter, we discuss the basics of making figures with with the ggplot2 package in R (part of the tidyverse. The ggplot2 package assembles a graph from several components. The important components are: Data: You should have the data going into a plot organized into a data frame, where each row is an observation and each column is a different variable. This is called “tidy data;” we’ll talk more about it later. Aesthetics: Which variables (columns) in the data connect to visual components of the plot? E.g., what goes on the X &amp; Y axes, what does color mean, etc? Scales: How do your aesthetics visually appear? For example, if your aesthetics say that “Mass” is represented by color, a scale would say what colors those actually are. Geometry: What’s actually drawn on your graph (e.g., points, lines, bars, etc) Facets: If you’re splitting your figure into multiple panels, what data is informing that? Let’s look at an example: # Load packages &amp; data library(tidyverse) lizards &lt;- read_csv(&quot;example_data/anoles.csv&quot;) # If this throws an error, see Appendix A for how to download it. base_plot &lt;- ggplot(data = lizards) + # Data: sets up a plot around lizards aes(x = SVL, y = Tail) + # Aesthetics: Connects columns of lizards to x and y geom_point() # Geometry: we&#39;re using points # Scales aren&#39;t listed, so they&#39;re using default values base_plot # show results This is a functional plot, but it doesn’t look much like a scientific figure. One quick option to change some of the default values is to use a theme. For this class, I’d like everyone to use the cowplot theme. Setting the theme will apply until you restart R. # Include these two lines after loading tidyverse/ggplot2 # at the top of each script library(cowplot) theme_set(theme_cowplot()) # Now view the plot again, and see the results base_plot 5.2 Aesthetics and scales Aesthetics connect a column of data to a visual representation on the plot. For example, x and y are aesthetics that correspond to axis positions. 5.2.1 Color Color is a commonly use aesthetic; let’s add it to our base_plot. # Connect the color aesthetic with the Color_morph column in the data base_plot + aes(color = Color_morph) # This is a discrete color # Connect the color aesthetic with the Limb column in the data base_plot + aes(color = Limb) # This is a continuous color These aren’t particularly great color defaults; we can use scales to change them. The viridis color scale is a good default option, since it’s generally colorblind friendly and isn’t terrible when printed in black &amp; white. base_plot + aes(color = Color_morph) + scale_color_viridis_d() # uses the &quot;Viridis&quot; colors, discrete scale base_plot + aes(color = Limb) + scale_color_viridis_c() # uses the &quot;Viridis&quot; colors, discrete scale You can also define your own colors for discrete variables: my_morph_colors = c(&quot;#a06f00&quot;, &quot;#004368&quot;, &quot;#e0a1c4&quot;) # Color Hex codes; if you&#39;re unfamiliar, google it. base_plot + aes(color = Color_morph) + scale_color_manual(values = my_morph_colors) 5.2.2 Shape Shape only works for discrete variables base_plot + aes(shape = Color_morph) base_plot + aes(shape = Color_morph) + scale_shape(solid = FALSE) If you want to set manual shapes, look at ?pch to see which the options. 5.2.3 Size base_plot + aes(size = Limb) This is kind of a mess in its current state. Let’s fix that. 5.2.4 Fixed aesthetics You can define an aesthetic value as a constant within a geom_* call, and it will refer to that literal value instead of a data column. # Note that I&#39;m including the aes() term with ggplot() instead # of adding it; these are equivalent ggplot(data = lizards, aes(x = SVL, y = Tail, size = Limb)) + # Define a default color &amp; shape for points geom_point(color = &quot;cornflowerblue&quot;, shape = 1) This makes the previous cloud of points a bit easier to separate. 5.2.5 Combining aesthetics Aesthetics are particularly powerful when combined. It can be helpful to double-up the aesthetics for a variable (to help improve clarity to the reader). ggplot(data = lizards) + aes(x = SVL, y = Tail, shape = Color_morph, color = Color_morph) + geom_point(size = 2.5) + scale_shape(solid = FALSE) + scale_color_viridis_d() Or to use different aesthetics with different variables to explore different variable combinations base_plot + aes(color = Limb, shape = Color_morph) + scale_shape(solid = FALSE) + scale_color_viridis_c() 5.3 Geometry Geometry layers are different ways to visualize your data (primarly along the x and y aesthetics); different types of geom_* objects are suitable to different types of x and y data. 5.3.1 Continuous X, no Y Histograms: ggplot(data = lizards) + aes(x = Diameter) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Note that this generates a warning. R automatically assigns the data into bins. To remove the warning, povide the binwidth argument. ggplot(data = lizards) + aes(x = Diameter) + geom_histogram(binwidth = 2.5, color = &quot;black&quot;, fill = &quot;white&quot;) Note that we used the color and fill aesthetics; for solid objects (like bars), color refers to the outline and fill refers to the solid color. Density Plots do something similar, but with a smooth estimate. ggplot(data = lizards) + aes(x = Diameter) + geom_density() If you wanted to separate the density estimates by color morph, all you’d need to do is add that aesthetic. ggplot(data = lizards) + aes(x = Diameter, color = Color_morph) + geom_density() Challenge: How would you do the same with a histogram? 5.3.2 Discrete X, continuous Y Boxplots: these show the quartile distributions of datasets. Let’s compare perch height distribution at each site: box_plots &lt;- ggplot(data = lizards) + aes(x = Site, y = Height) + geom_boxplot() box_plots Now let’s break that down by color morph box_plots + aes(fill = Color_morph) + # We&#39;re using fill because boxplots are solid theme(legend.position = &quot;bottom&quot;) # Move the legend to the bottom to give us more room Violin plots are similar to density plots, but are more effective at comparing several groups. ggplot(data = lizards) + aes(x = Site, y = Height) + geom_violin() Jitter plots show individual data points for discrete groups; they add a bit of random noise to each x and y to prevent points from overlapping; the width and height arguments control how much in each direction. In this case, we only want jitter along the x. ggplot(data = lizards) + aes(x = Site, y = Height) + geom_jitter(width = .25, height = 0) An alternate to the jitter plot is provided by geom_sina in the ggforce package (you’ll need to install it to make this work). This jitters the points on the x axis so they’ll fit within a violin plot. # install.packages(&quot;ggforce&quot;) # Uncomment this to install library(ggforce) ggplot(data = lizards) + aes(x = Site, y = Height) + geom_violin() + geom_sina(color = &quot;grey30&quot;, fill = &quot;grey70&quot;, shape = 21) # Note that shape 21 uses both color a fill as aesthetics Note that we’ve included two geom_* layers here, and that the one that was called second (geom_sina) was plotted on top of the one called first. Sometimes, you’ll want to show means &amp; confidence intervals of your different groups. If possible, it’s helpful to put those in the context of the raw data. The below plot looks at differences in perch diameter among colors, with the raw data in grey and the means in black. The error bars (geom_errorbar) take aesthetics ymin and ymax, which indicate their range. We used plus &amp; minus 1.96 standard errors because that’s the definition of a 95% confidence interval for normally distributed data. Be sure to tell your reader/audience what an error bar represents in your figure captions. # We need to create a new data frame for mean &amp; standard error of perch diameter # This uses dplyr commands, which are explained in the next appendix diameter_mean_se = lizards %&gt;% group_by(Color_morph) %&gt;% summarize( Diameter_se = sd(Diameter) / sqrt(n()), # Standard error Diameter = mean(Diameter)) # This mean diameter ggplot(lizards) + aes(x = Color_morph, y = Diameter) + # Show the raw data (from the lizards data frame) geom_sina(, color = &quot;grey60&quot;) + # Show the Mean +/- 95% confidence interval geom_errorbar( # 95% CI is the mean diamter +/- 1.96 * se aes(ymin = Diameter - 1.96 * Diameter_se, ymax = Diameter + 1.96 * Diameter_se), color = &quot;black&quot;, width = .3, # How wide the error bars are data = diameter_mean_se # Use the summary data frame instead of lizards # The column names should match with the global aesthetics (in this case, x and y) ) + geom_point(color = &quot;black&quot;, size = 2, data = diameter_mean_se # This one also uses the summary data frame # It keeps the global aesthetics, which match # the color morph &amp; mean value ) In this example, we’ve also used two data frames in the plot. This can be useful if you’re combining two different types of data (such as raw &amp; summary, or individual &amp; site-level). The important thing to remember is that any columns named in the global aesthetics (defined by an aes() call that isn’t inside a geom_*) must be present in both data frames. In this case, those aesthetics are Color_morph and Diameter. Diameter_se is a local aesthetic (in geom_errorbar), so it doesn’t need to appear in all datasets. 5.3.3 Continuous X and Y We’ve already seen geom_point used for continuous data. Here are a few other options: Heatmap: this is sort of a 2-d histogram, where the data is divided into bins along both the x and y axis; the fill indicates how many data points fall into that region. This is helpful if you have a lot of points that are all overlapping in the same area. ggplot(lizards) + aes(x = SVL, y = Tail) + geom_bin2d(bins = 25) + scale_fill_viridis_c() It’s often helpful to add regression lines to scatterpoint plots. This shows the the Tail ~ SVL regression, with the shaded region indicating the standard errors. regression_plot = ggplot(data = lizards) + aes(x = SVL, y = Tail) + geom_smooth(method = &quot;lm&quot;, se = TRUE) + # method = &quot;lm&quot; uses a linear regression # use se = FALSE to disable error regions geom_point() regression_plot You can also fit a regression to different groups of the data. This fits a separate one for each color: ggplot(data = lizards) + aes(x = SVL, y = Tail, color = Color_morph) + geom_smooth(method = &quot;lm&quot;, se = TRUE) + geom_point() + scale_color_viridis_d() Given that these regression lines all seem to be mostly the same, it may be better to fit them as one, but still indicate the different color morphs of the individual fits. You can specify certain aesthetics that only apply to a single geometric layer by including an aes() statement inside the geom_* call. ggplot(data = lizards) + aes(x = SVL, y = Tail) + geom_smooth(method = &quot;lm&quot;, se = TRUE) + geom_point(aes(color = Color_morph)) + # call color here to only make it apply to points scale_color_viridis_d() 5.3.4 Time series data If your x variable is related to time (or date), you’ll probably want to use a line plot to visualize it. Our anole dataset doesn’t work for this, so you’ll need to save this as \"example_data/beavers.csv\". This data has info on the body temperature of two beavers over time. beavers = read_csv(&quot;example_data/beavers.csv&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## Time = col_datetime(format = &quot;&quot;), ## Temperature = col_double(), ## activ = col_double(), ## beaver = col_character() ## ) ggplot(beavers) + aes(x = Time, y = Temperature, color = beaver) + geom_line() + scale_x_datetime(date_labels = &quot;%H:%M&quot;) # This tells R that you&#39;ve got a time on the x axis # date_labels says to use hours:minutes as the axis format 5.3.5 Discrete X and Y Bar graphs are good for showing counts, frequencies, and proportions. This shows how many individual lizards were in each site; It works by counting the number of rows in which the Site column has each value. ggplot(data = lizards) + aes(x = Site) + geom_bar() If you use a grouping aesthetic, you’ll get a stacked bar plot by default: ggplot(data = lizards) + aes(x = Site, fill = Perch_type) + geom_bar() + scale_fill_viridis_d() Sometimes, stacking can be hard to interpret; you can have your categories lined next to each other by specifying the bar position as dodge: ggplot(data = lizards) + aes(x = Site, fill = Perch_type) + geom_bar(position = &quot;dodge&quot;) + scale_fill_viridis_d() It’s usually a good idea to have your bars ordered in a descending frequency; you can do this by using fct_infreq() in your aes() statement. ggplot(data = lizards) + aes(x = fct_infreq(Site), # Note how this changes the axis label fill = Perch_type) + # We&#39;ll talk about how to fix that in a bit geom_bar() If you wish to use frequencies instead of counts along the y axis, it’s usually a better idea to calculate them yourself and display those numbers. You can use geom_col() for these displays; it’s like geom_bar(), but it takes a user-suplied y aesthetic. # This code uses dplyr, which is discussed in the next appendix. Don&#39;t worry if it doesn&#39;t make sense now. # Overal perch_height frequency lizard_perch_freq = lizards %&gt;% group_by(Perch_type) %&gt;% summarize(count = n()) %&gt;% # calculate frequencies per-group mutate(frequency = count/sum(count)) %&gt;% # sort by frequency arrange(desc(frequency)) %&gt;% # tell ggplot to plot Perch_type in its current order mutate(Perch_type = fct_inorder(Perch_type)) # feel free to use View() to look at this ggplot(lizard_perch_freq) + aes(x = Perch_type, y = frequency) + geom_col() 5.4 Facets You can use facets to make multi-panel figures. This can highlight differences between groups if including them in the same panel is too busy or messy. Let’s start by taking our previous regression plot and separating it by color morph. regression_plot + facet_wrap(~Color_morph) # note the ~ It doesn’t look like there’s much there. What about faceting by site? regression_plot + facet_wrap(~Site) # note the ~ In this case, it looks like the data ranges are quite a bit different among the sites. This leads to a large amount of unused space. You may wish to remove this whitespace. regression_plot + facet_wrap(~Site, scales = &quot;free_x&quot;) # scales can also be &#39;free_y&#39; or &#39;free&#39; (which does both x and y) You can also facet by two variables into rows &amp; columns with facet_grid(). regression_plot + facet_grid(Perch_type~Color_morph) # rows ~ columns 5.5 Changing the theme, axis titles, &amp; other visual elements By default, ggplot will name your axis labels &amp; legends by whatever you put in the aes string. You may wish to change that. For example, the labels on this plot could be improved: ggplot(lizards) + aes(x = Limb, y = Diameter, color = Color_morph) + geom_point() + scale_color_viridis_d() The xlab() and ylab() commands can provide labels for their respective axes, while the name argument can re-label scales. ggplot(lizards) + aes(x = Limb, y = Diameter, color = Color_morph) + geom_point() + scale_color_viridis_d(name = &quot;Color Morph&quot;) + xlab(&quot;Hind Limb Length (mm)&quot;) + ylab(&quot;Perch Diameter (mm)&quot;) More complicated options involve tweaking the theme. I’m not going to get into this right now, but I may update this later if conditions call for it. There is an example of using it to move the legend position several sections ago. 5.6 More references You can find a cheatsheet for ggplot2 in RStudio under Help -&gt; Cheatsheets; this covers most of the basic functions. The official website has a full list of geoms, scales, aesthetics, theme options, and everything else; it’s a more developed version of R’s built-in help mechanism. R for Data Science has a chapter on ggplot2 that is also quite helpful. Finally, it’s worth looking at the Figures chapter of this book for more examples; the code used to make those figures is linked at the bottom of the chapter. "],["dplyr-tutorial.html", "Chapter 6 Data manipulation with dplyr 6.1 The Pipe (%&gt;%) 6.2 Adding/modifying columns (mutate) 6.3 Subsetting by row (filter) 6.4 Subsetting by column (select) 6.5 Sorting by columns (arrange) 6.6 Summarizing data 6.7 Group Operations", " Chapter 6 Data manipulation with dplyr Let’s talk about data manipulation. We’ll be using the dplyr package, which is part of tidyverse. You can find a quick reference page under Help -&gt; Cheatsheets in RStudio. First, we need to load our packages &amp; data. library(tidyverse) library(cowplot) theme_set(theme_cowplot()) lizards &lt;- read_csv(&quot;example_data/anoles.csv&quot;) # See Appendix A if you don&#39;t have this data 6.1 The Pipe (%&gt;%) The pipe ( %&gt;% ) operator strings functions together in a sequence. It takes the result of the function on its left and makes it the first argument to the function on the right. Let’s say you wanted to calculate the base-12 log of the mean of the square root of the absolute value of numbers between -50 and 50. The traditional way to write that would be: log(mean(sqrt(abs(-50:50))), base = 12) ## [1] 0.6256332 This is rather difficult to read; it has a lot of nested parentheses, and you need to start from the inside and work your way out to see what’s happening. With the pipe, you could re-write it like this: -50:50 %&gt;% abs() %&gt;% sqrt() %&gt;% mean() %&gt;% log(base = 12) ## [1] 0.6256332 Using pipes can make your code much clearer, and is quite helpful when creating a sequence of related transformations on data. In RStudio, you can insert the pipe by pressing Ctrl+Shift+M. 6.2 Adding/modifying columns (mutate) The mutate() function creates a new column in a data frame. For example, the total length of a lizard is defined as its snout-vent length (SVL) plus it’s tail length. mutate(.data = lizards, total_length = SVL + Tail) %&gt;% View() # Use View to look at the results in RStudio Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type total_length A Green 14.3 6.46 8 164 61.8 43.9 Other 105.7 A Brown 12.3 5.82 18 151 57.1 42.2 Tree 99.3 A Blue 10.5 4.29 36 130 49.1 25.0 Building 74.1 A Brown 10.3 5.29 31 131 51.2 38.2 Tree 89.4 A Brown 10.9 5.69 20 138 51.5 46.9 Shrub 98.4 A Brown 10.4 5.84 25 137 45.3 59.0 Shrub 104.3 A Green 11.1 5.91 7 138 49.7 47.6 Building 97.3 A Brown 10.0 5.09 20 141 48.0 34.9 Tree 82.9 A Brown 12.3 7.20 19 129 54.9 61.0 Tree 115.9 A Brown 11.2 6.66 15 134 52.7 50.4 Tree 103.1 This uses the lizards data to create a new column, total_length. Within the mutate command, you can reference columns directly by their names (like you do for aes() in ggplot). Mutate can create multiple new columns in a single command. mutate(lizards, # generally, the .data argument is not named # All subsequent arguments refer to new columns total_length = SVL + Tail, rel_limb = Limb/SVL, log_total_length = log(total_length), # You can also change an existing column by saving something to its name Color_morph = paste(Color_morph, &quot;morph&quot;) # add &quot;morph&quot; after each color ) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type total_length rel_limb log_total_length A Green morph 14.3 6.46 8 164 61.8 43.9 Other 105.7 0.2313916 4.660605 A Brown morph 12.3 5.82 18 151 57.1 42.2 Tree 99.3 0.2154116 4.598146 A Blue morph 10.5 4.29 36 130 49.1 25.0 Building 74.1 0.2138493 4.305415 A Brown morph 10.3 5.29 31 131 51.2 38.2 Tree 89.4 0.2011719 4.493121 A Brown morph 10.9 5.69 20 138 51.5 46.9 Shrub 98.4 0.2116505 4.589041 A Brown morph 10.4 5.84 25 137 45.3 59.0 Shrub 104.3 0.2295806 4.647271 A Green morph 11.1 5.91 7 138 49.7 47.6 Building 97.3 0.2233400 4.577799 A Brown morph 10.0 5.09 20 141 48.0 34.9 Tree 82.9 0.2083333 4.417635 A Brown morph 12.3 7.20 19 129 54.9 61.0 Tree 115.9 0.2240437 4.752728 A Brown morph 11.2 6.66 15 134 52.7 50.4 Tree 103.1 0.2125237 4.635699 Note that this doesn’t modify the lizards dataset. It creates a new data frame that has an additional column. You’ll need to save it as a new variable to use it. lizards_full = lizards %&gt;% # It&#39;s also traditional to pipe the data argument in mutate(total_length = SVL + Tail, rel_limb = Limb/SVL, log_total_length = log(total_length)) Tidyverse functions are designed to be piped together. For example: lizards %&gt;% mutate(Total_length = SVL + Tail) %&gt;% ggplot(aes(x = Site, y = Total_length)) + geom_boxplot() Creating a quick plot at the end of a data manipulation step can be a good way to get a visual idea of what you’re doing. Here are a few other helpful things to do with mutate(): lizards %&gt;% mutate( intercept = 1, # Add a constant row_number = 1:n() # the n() function tells you how many rows are # in the current data frame (it only works in mutate &amp; related functions) ) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type intercept row_number A Green 14.3 6.46 8 164 61.8 43.9 Other 1 1 A Brown 12.3 5.82 18 151 57.1 42.2 Tree 1 2 A Blue 10.5 4.29 36 130 49.1 25.0 Building 1 3 A Brown 10.3 5.29 31 131 51.2 38.2 Tree 1 4 A Brown 10.9 5.69 20 138 51.5 46.9 Shrub 1 5 A Brown 10.4 5.84 25 137 45.3 59.0 Shrub 1 6 A Green 11.1 5.91 7 138 49.7 47.6 Building 1 7 A Brown 10.0 5.09 20 141 48.0 34.9 Tree 1 8 A Brown 12.3 7.20 19 129 54.9 61.0 Tree 1 9 A Brown 11.2 6.66 15 134 52.7 50.4 Tree 1 10 Here are a few exercises to try: Add a column to the lizards dataset that gives the lizard’s height relative to the maximum height of any lizard (hint: use max(Height) in a mutate command to find that value). Calculate perch circumference (Diameter * pi), then pipe that result into a scatter plot of relative limb length vs. circumference. Note that pi is a pre-defined variable in R. 6.3 Subsetting by row (filter) Let’s define “large lizards” as: lizards %&gt;% mutate(large = SVL &gt; 60) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type large A Green 14.3 6.46 8 164 61.8 43.9 Other TRUE A Brown 12.3 5.82 18 151 57.1 42.2 Tree FALSE A Blue 10.5 4.29 36 130 49.1 25.0 Building FALSE A Brown 10.3 5.29 31 131 51.2 38.2 Tree FALSE A Brown 10.9 5.69 20 138 51.5 46.9 Shrub FALSE A Brown 10.4 5.84 25 137 45.3 59.0 Shrub FALSE A Green 11.1 5.91 7 138 49.7 47.6 Building FALSE A Brown 10.0 5.09 20 141 48.0 34.9 Tree FALSE A Brown 12.3 7.20 19 129 54.9 61.0 Tree FALSE A Brown 11.2 6.66 15 134 52.7 50.4 Tree FALSE The large column is a logical vector, with TRUE &amp; FALSE values. We can use logical vectors to get a subset of the data frame where the vector is TRUE with the filter() function. lizards %&gt;% mutate(large = SVL &gt; 60) %&gt;% filter(large) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type large A Green 14.3 6.46 8 164 61.8 43.9 Other TRUE B Brown 13.7 7.57 23 162 67.0 73.8 Building TRUE B Green 14.4 7.75 8 174 68.8 65.4 Tree TRUE B Blue 13.8 7.61 35 163 63.5 69.7 Building TRUE B Green 15.2 8.27 14 188 67.0 50.6 Tree TRUE B Green 14.1 6.73 17 176 64.8 49.0 Tree TRUE B Blue 14.2 8.43 29 177 69.6 85.3 Tree TRUE B Green 14.3 13.30 9 179 68.3 74.0 Tree TRUE B Blue 14.4 7.71 33 182 65.5 59.6 Shrub TRUE B Brown 14.1 7.95 32 178 70.1 69.0 Tree TRUE Note that only TRUE values of large remain the the data frame. It’s not actually necessary to create a column before filtering: lizards %&gt;% filter(SVL &gt; 60) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type A Green 14.3 6.46 8 164 61.8 43.9 Other B Brown 13.7 7.57 23 162 67.0 73.8 Building B Green 14.4 7.75 8 174 68.8 65.4 Tree B Blue 13.8 7.61 35 163 63.5 69.7 Building B Green 15.2 8.27 14 188 67.0 50.6 Tree B Green 14.1 6.73 17 176 64.8 49.0 Tree B Blue 14.2 8.43 29 177 69.6 85.3 Tree B Green 14.3 13.30 9 179 68.3 74.0 Tree B Blue 14.4 7.71 33 182 65.5 59.6 Shrub B Brown 14.1 7.95 32 178 70.1 69.0 Tree The filter() command returns every row where its logical conditions are TRUE. Conditional statements that create logical statements include the following: x == y: TRUE if x equals y (This is not the same as x = y)! x != y: TRUE if x does not equal y x &gt; y: x &gt;= y; x &lt; y: x &lt;= y; between(x, y, z): TRUE if x &gt;= y AND x &lt;= z is.na(x): TRUE if x is a missing value (NA) x %in% y: TRUE if x is an element in y Note that all of these (except for x %in% y) are vectorized. c(1, 2) == c(2, 3) - 1 ## [1] TRUE TRUE c(1, 2, 3) == c(1, 4, 9) ## [1] TRUE FALSE FALSE c(1, 2) == c(2, 1) # positions don&#39;t match ## [1] FALSE FALSE c(1, 2, 3, 4, 5) %in% c(1, 2) # for %in%, position only matters for the left argument ## [1] TRUE TRUE FALSE FALSE FALSE You can also combine and modify logical values: x &amp; y: returns TRUE if both x and y are TRUE x | y: returns TRUE if either x or y are TRUE !x: returns the opposite of x; this one is particularly useful to combine with other logical functions; for example filter(data, !is.na(x)) will return all rows where x is not a missing value. If you give filter() more than one condition, it applies all of them by combining them with &amp;. lizards %&gt;% filter(Color_morph == &quot;Blue&quot;, Site %in% c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;)) %&gt;% ggplot(aes(x = SVL, y = Height, color = Site)) + geom_point() Exercises: Print a dataframe that shows only the lizards higher than 150 cm. How many are there (the console printout should tell you). How many lizards perching on trees or shrubs are not brown? Visualize the height to diameter relationship between them. Hint: you can use either %in% or a combination of == and | to meet the first condition. 6.4 Subsetting by column (select) You can subset certain columns with the select() function. There are several ways to do this. The simplest is by name: lizards %&gt;% select(Site, Color_morph, SVL) %&gt;% View() Site Color_morph SVL A Green 61.8 A Brown 57.1 A Blue 49.1 A Brown 51.2 A Brown 51.5 A Brown 45.3 A Green 49.7 A Brown 48.0 A Brown 54.9 A Brown 52.7 You can also select by position: lizards %&gt;% select(1, 2, 7) %&gt;% View() Site Color_morph SVL A Green 61.8 A Brown 57.1 A Blue 49.1 A Brown 51.2 A Brown 51.5 A Brown 45.3 A Green 49.7 A Brown 48.0 A Brown 54.9 A Brown 52.7 This is more useful for ranges of values: lizards %&gt;% select(1:4, 7) %&gt;% View() Site Color_morph Limb Mass SVL A Green 14.3 6.46 61.8 A Brown 12.3 5.82 57.1 A Blue 10.5 4.29 49.1 A Brown 10.3 5.29 51.2 A Brown 10.9 5.69 51.5 A Brown 10.4 5.84 45.3 A Green 11.1 5.91 49.7 A Brown 10.0 5.09 48.0 A Brown 12.3 7.20 54.9 A Brown 11.2 6.66 52.7 You can also use character vectors: lizards %&gt;% select(&quot;Site&quot;, &quot;Color_morph&quot;, &quot;SVL&quot;) %&gt;% View() Site Color_morph SVL A Green 61.8 A Brown 57.1 A Blue 49.1 A Brown 51.2 A Brown 51.5 A Brown 45.3 A Green 49.7 A Brown 48.0 A Brown 54.9 A Brown 52.7 Note that if you want to use a variable that has column names saved as a character vector, you’ll need to use a helper function (all_of) to tell select that you want to look for the contents of the variable, not the name of the variable: select_vars = c(&quot;Site&quot;, &quot;Color_morph&quot;, &quot;SVL&quot;) lizards %&gt;% select(all_of(select_vars)) %&gt;% # without all_of, it would try to look for a column called &quot;select_vars&quot; View() Site Color_morph SVL A Green 61.8 A Brown 57.1 A Blue 49.1 A Brown 51.2 A Brown 51.5 A Brown 45.3 A Green 49.7 A Brown 48.0 A Brown 54.9 A Brown 52.7 You can remove columns by using a negative sign. (Note that negative signs are ignored if you have any names without negative signs). lizards %&gt;% select(-Color_morph, -Limb) %&gt;% View() Site Mass Diameter Height SVL Tail Perch_type A 6.46 8 164 61.8 43.9 Other A 5.82 18 151 57.1 42.2 Tree A 4.29 36 130 49.1 25.0 Building A 5.29 31 131 51.2 38.2 Tree A 5.69 20 138 51.5 46.9 Shrub A 5.84 25 137 45.3 59.0 Shrub A 5.91 7 138 49.7 47.6 Building A 5.09 20 141 48.0 34.9 Tree A 7.20 19 129 54.9 61.0 Tree A 6.66 15 134 52.7 50.4 Tree lizards %&gt;% select(-(1:5)) %&gt;% View() Height SVL Tail Perch_type 164 61.8 43.9 Other 151 57.1 42.2 Tree 130 49.1 25.0 Building 131 51.2 38.2 Tree 138 51.5 46.9 Shrub 137 45.3 59.0 Shrub 138 49.7 47.6 Building 141 48.0 34.9 Tree 129 54.9 61.0 Tree 134 52.7 50.4 Tree You can also use the where helper function to select columns based on their characteristics. For example, the is.numeric function returns TRUE if its argument is a number; you can use it to select all numeric columns. lizards %&gt;% select(where(is.numeric)) %&gt;% View() Limb Mass Diameter Height SVL Tail 14.3 6.46 8 164 61.8 43.9 12.3 5.82 18 151 57.1 42.2 10.5 4.29 36 130 49.1 25.0 10.3 5.29 31 131 51.2 38.2 10.9 5.69 20 138 51.5 46.9 10.4 5.84 25 137 45.3 59.0 11.1 5.91 7 138 49.7 47.6 10.0 5.09 20 141 48.0 34.9 12.3 7.20 19 129 54.9 61.0 11.2 6.66 15 134 52.7 50.4 You could do the same for text or logical vectors with is.character or is.logical, respectively. Note that there aren’t parentheses after is.numeric in the above code. that’s because we aren’t calling it on any particular value; instead, the where function calls it on every column of the data frame, and we’re just telling it what function to use. There’s a lot more you can do with this if you want to get fancy; the documentation is available at ?tidyselect::language. 6.5 Sorting by columns (arrange) You can use arrange() to sort by one or more column values. To sort lizards from lowest to highest mass: lizards %&gt;% arrange(Mass) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type A Blue 10.5 4.29 36 130 49.1 25.0 Building L Brown 9.5 4.33 22 209 40.5 34.7 Other H Blue 9.4 4.42 28 161 40.3 41.5 Tree H Green 9.3 4.82 14 150 44.5 43.7 Tree L Blue 9.2 4.82 31 191 42.6 44.5 Tree L Blue 10.5 4.82 31 215 44.6 39.9 Shrub L Green 10.2 4.85 15 214 45.2 35.6 Tree K Green 9.7 4.89 18 58 47.7 23.7 Other H Blue 10.4 4.96 37 174 43.3 40.0 Shrub H Green 10.8 4.99 6 166 47.8 33.0 Tree If you wish to sort from highest to lowest, use the desc() helper function: lizards %&gt;% arrange(desc(Mass)) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type B Green 14.3 13.30 9 179 68.3 74.0 Tree J Brown 16.7 11.83 31 145 80.4 69.2 Other N Brown 15.8 10.13 25 130 73.2 90.0 Tree M Brown 11.9 9.79 24 210 56.0 70.7 Tree P Blue 15.4 9.74 41 221 76.3 95.7 Tree O Brown 16.4 9.63 24 217 74.3 65.7 Tree P Brown 15.4 9.58 29 216 70.4 81.6 Tree N Blue 14.9 9.54 38 128 68.4 67.5 Tree J Green 17.2 9.35 0 166 79.1 79.9 Tree O Blue 13.9 9.35 27 203 67.8 77.8 Shrub When you have categorical variables, you’ll often have ties: lizards %&gt;% arrange(Site) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type A Green 14.3 6.46 8 164 61.8 43.9 Other A Brown 12.3 5.82 18 151 57.1 42.2 Tree A Blue 10.5 4.29 36 130 49.1 25.0 Building A Brown 10.3 5.29 31 131 51.2 38.2 Tree A Brown 10.9 5.69 20 138 51.5 46.9 Shrub A Brown 10.4 5.84 25 137 45.3 59.0 Shrub A Green 11.1 5.91 7 138 49.7 47.6 Building A Brown 10.0 5.09 20 141 48.0 34.9 Tree A Brown 12.3 7.20 19 129 54.9 61.0 Tree A Brown 11.2 6.66 15 134 52.7 50.4 Tree In this case, it’s helpful to sort by multiple variables; the following code orders by Site, then by color morph within site, then by SVL. lizards %&gt;% arrange(Site, Color_morph, SVL) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type A Blue 10.6 5.53 36 134 46.1 50.3 Other A Blue 10.9 5.73 29 146 47.0 56.5 Other A Blue 10.1 5.40 27 133 48.2 45.7 Tree A Blue 10.5 4.29 36 130 49.1 25.0 Building A Blue 10.8 6.02 30 148 50.1 57.9 Tree A Blue 11.4 5.72 32 134 50.7 48.8 Tree A Blue 12.1 5.67 35 150 50.8 51.7 Other A Blue 10.8 5.27 30 141 51.2 43.3 Tree A Blue 12.5 6.18 28 140 52.9 48.4 Tree A Blue 11.0 6.68 31 143 53.8 49.5 Shrub One particularly useful thing you can do with this is create rankings. lizards %&gt;% arrange(desc(SVL)) %&gt;% mutate(size_rank = 1:n()) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type size_rank O Blue 18.7 9.33 43 230 84.5 88.9 Tree 1 J Green 18.2 8.65 2 169 84.3 76.3 Tree 2 J Brown 16.4 9.21 30 147 81.0 86.8 Shrub 3 J Brown 16.7 11.83 31 145 80.4 69.2 Other 4 O Brown 17.3 8.04 23 223 80.2 56.6 Other 5 R Green 17.1 8.83 6 231 80.0 71.1 Tree 6 O Blue 16.1 8.50 36 221 79.3 73.8 Tree 7 J Green 17.2 9.35 0 166 79.1 79.9 Tree 8 J Blue 17.0 8.31 41 164 78.6 74.4 Tree 9 R Brown 17.1 8.30 23 217 78.5 50.3 Building 10 6.6 Summarizing data Summarize is like mutate, but it generally produces columns that are shorter than the input. It’s typically used for summary stats. For example, this calculates several characteristics of SVL. lizards %&gt;% summarize(mean_SVL = mean(SVL), sd_SVL = sd(SVL), med_SVL = median(SVL), count = n()) %&gt;% View() mean_SVL sd_SVL med_SVL count 60.75282 8.708924 59.6 657 A useful trick for summarize is to take the mean of a logical vector; TRUE and FALSE are interpreted as 1 and 0, so this gives you a frequency. For example, if you wanted to get the proportion of color morphs: lizards %&gt;% summarize(freq_Blue = mean(Color_morph == &quot;Blue&quot;), freq_Brown = mean(Color_morph == &quot;Brown&quot;), freq_Green = mean(Color_morph == &quot;Green&quot;) ) ## # A tibble: 1 x 3 ## freq_Blue freq_Brown freq_Green ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.327 0.336 0.336 You can use the across helper function to apply the same summary function to multiple rows. lizards %&gt;% summarize( across(.cols = c(SVL, Tail), .fns = mean) ) %&gt;% View() SVL Tail 60.75282 57.55205 The .cols argument identifies the columns to use for the summary, using the same methods as select(), the .fns should be one or more functions to apply to each column. If you wish to use more than one summary function, you need to create a named vector: lizards %&gt;% summarize( across(.cols = where(is.numeric), # apply to all numeric functions .fns = c(Mean = mean, StDev = sd)) # named vector (Mean and StDev) ) %&gt;% View() Limb_Mean Limb_StDev Mass_Mean Mass_StDev Diameter_Mean Diameter_StDev Height_Mean Height_StDev SVL_Mean SVL_StDev Tail_Mean Tail_StDev 13.16088 1.83096 7.024368 1.088521 22.73364 10.13449 168.7382 42.69773 60.75282 8.708924 57.55205 12.12895 This applies the functions mean and sd to all numeric columns; The results have the names \"Mean\" and \"StDev\" that we gave each function applied to the end of the column. 6.7 Group Operations The real power of the dplyr package comes from being able to apply all of the above functions to grouped subsets of a data frame. To create a grouped table use the group_by function: lizards %&gt;% group_by(Site) ## # A tibble: 657 x 9 ## # Groups: Site [19] ## Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 A Green 14.3 6.46 8 164 61.8 43.9 Other ## 2 A Brown 12.3 5.82 18 151 57.1 42.2 Tree ## 3 A Blue 10.5 4.29 36 130 49.1 25 Building ## 4 A Brown 10.3 5.29 31 131 51.2 38.2 Tree ## 5 A Brown 10.9 5.69 20 138 51.5 46.9 Shrub ## 6 A Brown 10.4 5.84 25 137 45.3 59 Shrub ## 7 A Green 11.1 5.91 7 138 49.7 47.6 Building ## 8 A Brown 10 5.09 20 141 48 34.9 Tree ## 9 A Brown 12.3 7.2 19 129 54.9 61 Tree ## 10 A Brown 11.2 6.66 15 134 52.7 50.4 Tree ## # … with 647 more rows This doesn’t appear to do much on its own; however, look what happens when you combine it with summarize: lizards %&gt;% group_by(Site) %&gt;% summarize(mean_SVL = mean(SVL), sd_SVL = sd(SVL), count = n()) %&gt;% View() Site mean_SVL sd_SVL count A 51.69615 3.679944 26 B 66.92222 2.182673 36 C 58.09722 5.576250 36 D 70.70000 3.058280 27 E 53.17727 2.776887 44 F 58.77955 2.734583 44 G 63.87308 6.027507 26 H 52.18571 5.101008 42 I 57.04412 4.973639 34 J 74.34857 3.625512 35 This calculates the mean, SD of SVL for each site. You can group by multiple factors lizards %&gt;% group_by(Site, Color_morph) %&gt;% summarize(mean_SVL = mean(SVL), count = n()) %&gt;% ungroup() %&gt;% # Removes grouping; usually a good idea at the end unless you want surprises View() Site Color_morph mean_SVL count A Blue 49.99000 10 A Brown 52.01538 13 A Green 56.00000 3 B Blue 67.54000 10 B Brown 66.74667 15 B Green 66.60000 11 C Blue 58.96250 8 C Brown 57.03125 16 C Green 58.94167 12 D Blue 70.43750 8 Grouping doesn’t just work with summarize; for example, you can use it with mutate to find the relative height of each lizard within its site: lizards %&gt;% group_by(Site) %&gt;% mutate( rel_height = Height/max(Height)) %&gt;% # max(Height) returns the max height in each site ungroup() %&gt;% ggplot(aes(x = Site, y = rel_height)) + geom_jitter(width = .2, height = 0) You can also use this to easily calculate frequencies: An alternate way to do this would be to combine summarise and mutate. lizards %&gt;% group_by(Site, Color_morph) %&gt;% summarize(count = n()) %&gt;% # count is the total number of each morph at each site group_by(Site) %&gt;% # Calculate color morph frequency at each site mutate(site_frequency = count / sum(count)) %&gt;% View() Site Color_morph count site_frequency A Blue 10 0.3846154 A Brown 13 0.5000000 A Green 3 0.1153846 B Blue 10 0.2777778 B Brown 15 0.4166667 B Green 11 0.3055556 C Blue 8 0.2222222 C Brown 16 0.4444444 C Green 12 0.3333333 D Blue 8 0.2962963 Some Exercises: Visualize the relationship between the maximum height at a site and the average limb length. Use this to help: lizards %&gt;% # Put your summarize() code here # You should name your new columns max_height and mean_limb ggplot(aes(x = max_height, y = mean_limb)) + geom_smooth(method = &quot;lm&quot;) + geom_point() For each site, what’s the mean limb length of the five largest individuals by SVL? What proportion of these individuals is blue? "],["r-analysis-tutorial.html", "Chapter 7 Performing some useful analyses in R 7.1 A note on factors 7.2 Comparing categorical frequencies (Contingency Tables &amp; related analyses) 7.3 Linear Models: Regression, ANOVA, and t-tests", " Chapter 7 Performing some useful analyses in R I’m going to give some examples of how to do common analyses you’ll need for this class. I won’t be spending much time on the statistical assumptions or diagnostics. library(tidyverse) library(cowplot) theme_set(theme_cowplot()) lizards &lt;- read_csv(&quot;example_data/anoles.csv&quot;) # See Appendix A if you don&#39;t have this data 7.1 A note on factors R has two ways of representing textual data: character vectors (also called strings) and factors. Character vectors are just text; they have no inherent underlying meaning. Factors are a data type with a specific number of levels; they’re often used to represent different experimental treatments. Examples could include {low, medium, high} or {control, treatment}. Each level of a factor is associated with a number. For the most part, it’s easier and safer to work with character vectors. Most functions we’ll be using know how to convert them when it’s necessary. One important thing to note is that ggplot arranges character vectors alphabetically on its categorical scales, but orders factors by their level number. Thus, to change the order of categorical x-axes (and other scales), you need to make your categories into a factor. This is done with the fct_inorder, fct_infreq, and related functions, which are part of the forcats package and loaded with tidyverse. The easiest one to use is fct_inorder, which changes the level values to be in the order of your data; when combined with arrange() and other dplyr functions, this is quite flexible and powerful. For more information on these and other factor functions, take a look at the forcats website. If you want to manually create a factor, you can use the factor command, which is in base R (no package). color_levels = c(&quot;Red&quot;,&quot;Green&quot;,&quot;Blue&quot;) # Randomly select 20 colors from color_levels color_example = sample(color_levels, size = 20, replace = TRUE) color_example ## [1] &quot;Blue&quot; &quot;Blue&quot; &quot;Blue&quot; &quot;Red&quot; &quot;Red&quot; &quot;Green&quot; &quot;Red&quot; &quot;Blue&quot; &quot;Green&quot; ## [10] &quot;Blue&quot; &quot;Blue&quot; &quot;Blue&quot; &quot;Blue&quot; &quot;Green&quot; &quot;Green&quot; &quot;Red&quot; &quot;Green&quot; &quot;Blue&quot; ## [19] &quot;Red&quot; &quot;Green&quot; # Convert it into a factor color_as_factor = factor(color_example, levels = color_levels) color_as_factor ## [1] Blue Blue Blue Red Red Green Red Blue Green Blue Blue Blue ## [13] Blue Green Green Red Green Blue Red Green ## Levels: Red Green Blue 7.2 Comparing categorical frequencies (Contingency Tables &amp; related analyses) These tests generally compare the frequencies of count data. 7.2.1 Contingency Tables The easiest way to make a contingency table is from a data frame where each column is a categorical variable you want in the table &amp; each row is an observation. Let’s say we wanted to create a color morph by perch type contingency with our lizard data. color_by_perch_tbl &lt;- lizards %&gt;% select(Color_morph, Perch_type) %&gt;% # select only the columns you want table() # feed them into the table command color_by_perch_tbl ## Perch_type ## Color_morph Building Other Shrub Tree ## Blue 17 41 27 130 ## Brown 31 25 25 140 ## Green 30 25 32 134 If you want to switch your contingency table from counts to frequencies, just divide it by its sum: color_by_perch_tbl / sum(color_by_perch_tbl) ## Perch_type ## Color_morph Building Other Shrub Tree ## Blue 0.02587519 0.06240487 0.04109589 0.19786910 ## Brown 0.04718417 0.03805175 0.03805175 0.21308980 ## Green 0.04566210 0.03805175 0.04870624 0.20395738 7.2.2 Chi-squared &amp; Fisher’s Exact Tests Once you have a contingency table, you can test for independence between the rows and columns. This provides you with your test statistic (X-squared), degrees of freedom, and p-value. chisq.test(color_by_perch_tbl) ## ## Pearson&#39;s Chi-squared test ## ## data: color_by_perch_tbl ## X-squared = 11.603, df = 6, p-value = 0.07143 Chi-squared tests assume that there’s at least five observations in each cell of the contingency table. If this fails, then the resulting values aren’t accurate. For example: site_a_contingency &lt;- lizards %&gt;% filter(Site == &quot;A&quot;) %&gt;% # cut down the data size select(Color_morph, Perch_type) %&gt;% # select only the columns you want table() # feed them into the table command print(site_a_contingency) ## Perch_type ## Color_morph Building Other Shrub Tree ## Blue 1 3 1 5 ## Brown 0 0 2 11 ## Green 1 1 0 1 chisq.test(site_a_contingency) ## Warning in chisq.test(site_a_contingency): Chi-squared approximation may be ## incorrect ## ## Pearson&#39;s Chi-squared test ## ## data: site_a_contingency ## X-squared = 9.752, df = 6, p-value = 0.1355 Note the warning that “Chi-squared approximation may be incorrect.” In this case, it’s a good idea to run the Fisher’s exact test, which investigates the same null hypotheses, but works with low counts. Fisher’s test is less powerful than the Chi-squared test, so it should only be used when it’s the only option. fisher.test(site_a_contingency) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: site_a_contingency ## p-value = 0.06251 ## alternative hypothesis: two.sided You can also run a chi-squared or Fisher’s exact test directly on two vectors or data frame columns: chisq.test(lizards$Color_morph, lizards$Perch_type) ## ## Pearson&#39;s Chi-squared test ## ## data: lizards$Color_morph and lizards$Perch_type ## X-squared = 11.603, df = 6, p-value = 0.07143 7.3 Linear Models: Regression, ANOVA, and t-tests Linear regression and Analysis of Variance (ANOVA) are both special cases of the general linear model (LM), which fits a continuous response (y) to one or more predictors (x). You specify linear models in R with a formula syntax, which generally follows as: response ~ predictor. Combining this formula with the lm() function and a datset gives you the basis of a linear model. 7.3.1 Regression Lets say we wanted to see how snout-vent length (SVL) affects mass: simple_reg &lt;- lm(Mass ~ SVL, data = lizards) simple_reg ## ## Call: ## lm(formula = Mass ~ SVL, data = lizards) ## ## Coefficients: ## (Intercept) SVL ## 1.62577 0.08886 By default, this creates an LM object, which tells us the regression coefficients. For a linear regression (continuous response), these tell us the regression equation; in this case, that for every \\(1 \\text{ mm}\\) increase in SVL, mass increases by \\(0.089 \\text{ g}\\). Note that in this case, it may make sense to re-scale SVL to be in cm, so that the coefficient would be easier to interpret (e.g., use lizards %&gt;% mutate(SVL_cm = SVL/10). To extract the coeficients directly, use: coef(simple_reg) ## (Intercept) SVL ## 1.6257700 0.0888617 For more information, use the summary function: summary(simple_reg) ## ## Call: ## lm(formula = Mass ~ SVL, data = lizards) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.2672 -0.4699 -0.0530 0.3959 5.6050 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.625770 0.210781 7.713 4.59e-14 *** ## SVL 0.088862 0.003434 25.874 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7661 on 655 degrees of freedom ## Multiple R-squared: 0.5055, Adjusted R-squared: 0.5047 ## F-statistic: 669.5 on 1 and 655 DF, p-value: &lt; 2.2e-16 The most important components of this are the \\(R^2\\) (which is listed as Multiple R-squared), the standard errors and p-values for each of your coefficients (Coefficients section), and the overall F-statistic and p-value (the last line). A quick note on p-values: Don’t base all of your interpretation on p-values; the \\(R^2\\) and adjusted \\(R^2\\) of a model are more important. The overall p-value relates to how the whole model explains the variance in the data; the coefficient p-value relates to whether the specific coefficient is different from zero. Coefficient-level p-values tend to be rather fragile, and shouldn’t be used. 7.3.1.1 Plotting linear regressions For a simple linear regression, ggplot can automatically plot the trendline (a.k.a., fitted values) and confidence intervals with geom_smooth(). lizards %&gt;% ggplot() + aes(x = SVL, y = Mass) + geom_point() + geom_smooth(method = &quot;lm&quot;, # use a linear regression se = TRUE, # Include a confidence interval around the line level = .95) # the level of the confidence interval; default = 95% For more complicated models, this approach may not work very well; it can be helpful to calculate the fitted values &amp; confidence intervals from the model object and plot them directly. You can get these values directly with the predict() function. The code below calculates the trendline and 95% confidence interval for the regression, and adds them to a data frame with the original data. simple_reg_predictions &lt;- simple_reg %&gt;% # Predict fitted values wish 95% confidence intervals predict(interval = &quot;confidence&quot;, level = .95) %&gt;% # The output of predict() is a matrix; that&#39;s hard to work with, so... as_tibble() # we convert the output of predict() to a data frame (tibble) simple_reg_plot_data &lt;- lizards %&gt;% select(SVL, Mass) %&gt;% # we only need these columns bind_cols(simple_reg_predictions) # adds columns of simple_reg_preds to our lizards View(simple_reg_plot_data) SVL Mass fit lwr upr 61.8 6.46 7.117423 7.058313 7.176533 57.1 5.82 6.699773 6.636126 6.763420 49.1 4.29 5.988879 5.890800 6.086959 51.2 5.29 6.175489 6.088343 6.262634 51.5 5.69 6.202147 6.116487 6.287808 45.3 5.84 5.651205 5.531606 5.770804 49.7 5.91 6.042196 5.947328 6.137065 48.0 5.09 5.891132 5.787013 5.995249 54.9 7.20 6.504277 6.433552 6.575002 52.7 6.66 6.308782 6.228823 6.388740 To plot this, you’d use a combination of geom_line() for the fitted values and geom_ribbon(), which would create the confidence interval region. ggplot(simple_reg_plot_data) + aes(x = SVL) + geom_point(aes(y = Mass), color = &quot;cornflowerblue&quot;) + geom_ribbon(aes(ymin = lwr, ymax = upr), fill = alpha(&quot;black&quot;, .2), # dark fill with 80% transparency (alpha) color = grey(.4), # dark-ish grey border line linetype = 2) + # dotted border line geom_line(aes(y = fit)) You can also use predict() to calculate the respected value of your response variable given new predictor(s); this is useful for interpolation and extrapolation. # Create a data frame with new predictors svl_predictors = tibble(SVL = c(20, 150, 600)) # New predictors mass_predictions &lt;- predict(simple_reg, newdata = svl_predictors) # The newdata argument is key here # If unspecified, it uses the original data svl_predictors %&gt;% mutate(Mass_estimate = mass_predictions) ## # A tibble: 3 x 2 ## SVL Mass_estimate ## &lt;dbl&gt; &lt;dbl&gt; ## 1 20 3.40 ## 2 150 15.0 ## 3 600 54.9 For more information, see the help page ?predict.lm. 7.3.2 ANOVA Analysis of variance (ANOVA) is a special case of linear model where all of the predictors are all categorical. However, ANOVAs are usually treated differently from regressions for historical reasons. In R, you fit an ANOVA in the same way as a regression (with the lm() command); however, it’s common to use the aov() command on the lm’s output to reformat the results into a more traditional style. For the simple (one-way) ANOVA follows: # Fit the model wtih a regression simple_anova_lm &lt;- lm(Diameter ~ Color_morph, data = lizards) # Reformat into traditional ANOVA style; this is usually done with a pipe as part of the previous step simple_anova &lt;- aov(simple_anova_lm) # Look at the ANOVA table simple_anova %&gt;% summary() ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Color_morph 2 50586 25293 985.2 &lt;2e-16 *** ## Residuals 654 16790 26 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The ANOVA table gives us estimates of variation explained by the predictor and the residuals. Note how different the output is from the summary of a regression, even though the underlying math is the same: summary(simple_anova_lm) ## ## Call: ## lm(formula = Diameter ~ Color_morph, data = lizards) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.8837 -3.1176 -0.1176 3.1163 18.1163 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 32.8837 0.3456 95.16 &lt;2e-16 *** ## Color_morphBrown -8.7661 0.4854 -18.06 &lt;2e-16 *** ## Color_morphGreen -21.4086 0.4854 -44.11 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.067 on 654 degrees of freedom ## Multiple R-squared: 0.7508, Adjusted R-squared: 0.75 ## F-statistic: 985.2 on 2 and 654 DF, p-value: &lt; 2.2e-16 Two quick notes about this: While \\(R^2\\) isn’t included in the aov() summary, it can be calculated as the total sum of squares of your predictors (in this case, Color_morph) divided by the total sum of squares including the residual; For this example, we have \\(5.0586239\\times 10^{4} / (5.0586239\\times 10^{4} + 1.6790147\\times 10^{4}) = 0.7508007\\). The aov() table provides a line for each predicting factor and the residuals; the lm() summary includes estimates for the intercept and the specific levels of the factors (e.g., Color_morphBrown). These represent the dummy coded variables that R uses under the hood; you don’t need to worry about this, but I’ve got an explanation for them below if you’re interested. Dummy coding: R converts an ANOVA into a (multiple) regression model by changing a categorical predictor with \\(n\\) levels into \\(n-1\\) predictor variables that can have values of 0 or 1. The first level of the factor doesn’t get a dummy variable; its mean is represented by the regression’s intercept. The other dummy coefficients represent the mean difference between the reference level and the level they represent. In our example, the reference category is Blue, so the regression’s intercept is the mean Diameter for blue lizards. The average value for brown lizards would be the intercept plus the Color_morphBrown coefficient (and similarly for green). The aov() function reinterprets the dummy coded results as a traditionally categorical analysis. 7.3.2.1 ANOVA means &amp; confidence intervals # make a data frame with just your predictors (distinct removes duplicates) color_levels &lt;- lizards %&gt;% distinct(Color_morph) color_levels ## # A tibble: 3 x 1 ## Color_morph ## &lt;chr&gt; ## 1 Green ## 2 Brown ## 3 Blue simple_anova_means &lt;- # Calculate means &amp; 95% CI predict(simple_anova, newdata = color_levels, interval = &quot;confidence&quot;, level = 0.95) %&gt;% as_tibble() %&gt;% # Convert to data frame bind_cols(color_levels) # add the prediction data as more columns simple_anova_means ## # A tibble: 3 x 4 ## fit lwr upr Color_morph ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 11.5 10.8 12.1 Green ## 2 24.1 23.4 24.8 Brown ## 3 32.9 32.2 33.6 Blue 7.3.2.2 Post-hoc tests In general, the ANOVA tests whether a factor (such as color morph) explains a significant amount of variation in the response. To test whether there are significant differences between specific levels of a factor, you need to run post-hoc tests on your ANOVA. A common post-hoc is Tukey’s HSD (honest significant difference). simple_anova %&gt;% TukeyHSD() ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = simple_anova_lm) ## ## $Color_morph ## diff lwr upr p adj ## Brown-Blue -8.766074 -9.906219 -7.625929 0 ## Green-Blue -21.408608 -22.548753 -20.268463 0 ## Green-Brown -12.642534 -13.774806 -11.510261 0 You can use the witch argument to specify specific level comparisons, but by default it compares all of them. A traditional way of summarizing post-hoc tests is to assign one or more letters to significantly different levels, where levels with different letters are significantly different from each other. For example, the letter grouping c(\"A\", \"AB\", \"B\", \"C\") would indicate that group 1 and group 3 are different from each other, but not from group 2; group 4 is different from everything. In the above example, everything is different, so we could assign the letters A through C. # We&#39;ll store these in a data frame for later use anova_means_letters &lt;- simple_anova_means %&gt;% arrange(Color_morph) %&gt;% # These will be plotted alphabetically, so we&#39;ll sort them that way to keep things easy mutate(anova_labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)) anova_means_letters ## # A tibble: 3 x 5 ## fit lwr upr Color_morph anova_labels ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 32.9 32.2 33.6 Blue A ## 2 24.1 23.4 24.8 Brown B ## 3 11.5 10.8 12.1 Green C 7.3.2.3 Plotting ANOVAs The basics of plotting ANOVA results was covered in the last part of Section @ref(ggp_discx_conty), but we’ll refine them a bit here. The main additions are the use of geom_text() to include the labels above each category and scale_y_continuous, which we use to customize the y axis a bit so that it doesn’t cut off the labels. Be sure to indicate in your figure captions what the letters mean. library(ggforce) # for geom_sina() # We&#39;re going to add post-hoc letters to this plot letter_y_position &lt;- max(lizards$Diameter) * 1.05 # Put letters at the top anova_plot &lt;- ggplot(lizards) + aes(x = Color_morph) + # Color_morph column is in both lizards AND anova_means_letters # Show the raw data geom_sina(aes(y = Diameter), # Diameter column is in lizards data frame color = alpha(&quot;blue&quot;, .2)) + # semi-transparent points geom_errorbar( aes(ymin = lwr, ymax = upr), # columns lwr and upr are in anova_means_letters data = anova_means_letters, # Use the summary data frame instead of lizards color = &quot;black&quot;, width = .3 # How wide the error bars are ) + geom_point(aes(y = fit), # fit column is in anova_means_letters color = &quot;black&quot;, size = 2, data = anova_means_letters) + geom_text(aes(label = anova_labels), # label is the aesthetic used to indicate text y = letter_y_position, # This is a fixed spot, not an aesthetic fontface = &quot;bold&quot;, size = 6, # font size data = anova_means_letters) + scale_y_continuous( # insure the letters aren&#39;t cut off at the top limits = c(NA, letter_y_position), # This is the same as ylim() breaks = seq(from = 0, to = 50, by = 10), # set axis ticks every 10 points name = c(&quot;Perch Diameter (mm)&quot;) # this is the same as ylab() ) + xlab(&quot;Color Morph&quot;) anova_plot 7.3.3 Comparing two means (t-tests) While it’s perfectly valid to use an ANOVA to compare the means of two samples, the t-test is a more traditional approach. You can do this with the t-test() function. First, let’s create a 2-level categorical variable to work with. Normally, this would be done during data collection, but there aren’t any in this data source. Let’s define lizards as big (SVL &gt;= 65 mm) or small (SVL &lt;= 55 mm) and remove the intermediates. lizards_by_size &lt;- lizards %&gt;% filter(SVL &lt;= 55 | SVL &gt;= 65) %&gt;% # Remove the lizards of intermediate size mutate(Size_class = if_else (SVL &gt;= 65, &quot;big&quot;, &quot;small&quot;) )# Define Size_class as big or small, based on SVL Next, let’s use a t-test to see if limb length differs between big and small lizards. First, we should look at the mean and standard deviation of each group. The classic t-test requires that the variances of the two groups are equal; if not, an adjustment will need to be applied. In practice, this adjustment has no ill effect if the variances are equal, so you may as well apply it. In any case, it’s a good idea to look at data summaries before running a test. lizard_size_sumary_table &lt;- lizards_by_size %&gt;% group_by(Size_class) %&gt;% # We want to summarize each size class summarize(mean = mean(Limb), sd = sd(Limb), var = var(Limb), n = n()) %&gt;% ungroup() lizard_size_sumary_table ## # A tibble: 2 x 5 ## Size_class mean sd var n ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 big 15.1 0.984 0.969 240 ## 2 small 11.2 0.800 0.641 206 In this case, the standard deviations are somewhat different, but not particularly. In any case, we’ll run the test without assuming for equal variances. lizard_t_test &lt;- t.test(Limb ~ Size_class, # formula specifies response (on left) and predictor (on right) data = lizards_by_size, var.equal = FALSE) # Assume unequal variances; this is the default option. print(lizard_t_test) ## ## Welch Two Sample t-test ## ## data: Limb by Size_class ## t = 45.668, df = 442.74, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means between group big and group small is not equal to 0 ## 95 percent confidence interval: ## 3.694599 4.026898 ## sample estimates: ## mean in group big mean in group small ## 15.09958 11.23883 When reporting a t-test, you should t, the degrees of freedom, the p-value, the effect size (Cohen’s d). The effect size isnt’ provided for you directly, so you’ll need to calculate it yourself. 7.3.3.1 Effect size: Cohen’s d Cohen’s d is essentially a standardized way of measuring the difference between two groups. Conceptually, it’s the number of standard deviations of difference between the two groups. You can calculate it by taking the difference in the group means and dividing by the pooled standard deviation. To get the pooled standard deviation, calculate the weighted average of the variance (weighted by population size) and take the square root. lizard_size_sumary_table %&gt;% summarize(mean_diff = diff(mean), pooled_variance = sum(var * n) / sum(n) ) %&gt;% #weighted mean of variance mutate(cohen_d = abs(mean_diff) / sqrt(pooled_variance) ) # COhen&#39;s d is always positive, so take abs() of mean_diff ## # A tibble: 1 x 3 ## mean_diff pooled_variance cohen_d ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -3.86 0.817 4.27 You could report your results as follows (assuming that figure 1 compared the two groups): Big lizards have significantly longer limbs than small lizards (d = 4.27, t = 45.7, df = 442.7, p &lt; 0.0001; Figure 1) "],["vegan-tutorial.html", "Chapter 8 Community ecology analyses with vegan 8.1 Setting up the data 8.2 Jaccard similarity 8.3 Species Accumulation Curves 8.4 Rank Abundance Curves 8.5 Shannon Index &amp; Diversity", " Chapter 8 Community ecology analyses with vegan This appendix is a companion to the ant community ecology lab. If you haven’t already, please install the vegan package with install.packages(\"vegan\") and put the ant_data_F18.csv file in your example_data directory. # Load packages &amp; data library(tidyverse) # install.packages(&quot;vegan&quot;) # uncomment if necessary library(vegan) library(cowplot) theme_set(theme_cowplot()) 8.1 Setting up the data Read in the new dataset. wide_ant_data = read_csv(&quot;example_data/ant_data_F19.csv&quot;) View(wide_ant_data) Habitat Site Canopy_cover Ground_cover Nearest_canopy_spp Disturbance Drought Phorids Notes GPS_Easting GPS_Northing name Acre Total_ants S_invicta_present Solenopsis_invicta Pheidole_floridana Pheidole_tetra Solenopsis_texana Camponotus_texanus Aphenogaster_texana Brachymyermex Crematogaster_laeviuscula Forelius_mccooki Forelius_pruinosis Monomorium_minimum Odontomachus_clarus Paratrechina_terricola Pheidole_bicarinata Pheidole_dentata Pheidole_lamia Pheidole_metallescens Pheidole_pelor Pheilode_hyati Pseudomyrmex_brunneus Solenopsis_geminata Atta_texana Camponotus_sansabeaneus Pachycondyla_harpax Other_species R 1 3 0 American Elm high 1 1 NA 105 815 student_1 52 250 1 250 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 R 2 3 1 pecan high 0 0 yellow jackets 96 826 student_1 52 5 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 R 3 2 0 hackberry high 1 0 yellow jackets 86 848 student_1 52 5 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 R 4 2 0 pecan high 1 1 yellow jackets 76 848 student_1 52 10 0 0 0 10 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 R 5 3 1 pecan low 1 1 NA 87 862 student_1 52 62 1 62 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 R 6 1 3 pecan high 0 1 NA 104 842 student_1 52 20 0 0 0 5 15 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 R 7 0 2 pecan high 2 0 NA 109 836 student_1 52 175 1 175 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 R 8 3 0 hackberry high 1 0 NA 97 858 student_1 52 350 1 350 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 R 9 3 0 hackberry high 1 0 flies 107 859 student_1 52 31 0 0 30 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 R 10 3 0 pecan high 1 1 NA 108 877 student_1 52 200 1 200 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Looking at the dataset, there’s a bunch of columns that indicate the number of species present. Let’s make a tidy version of this dataset, which will be easier to work with for some of the functions we’re using. We’ll be using the pivot_longer() function from the tidyr package. tidy_ant_data = wide_ant_data %&gt;% pivot_longer(cols = Solenopsis_invicta:Other_species, # These are the species columns names_to = &quot;Species&quot;, # Put the column name in a &quot;Species&quot; column values_to = &quot;N&quot;) %&gt;% # Cell values are counts, so make that an N column # replace the underscores in species names with a space: mutate(Species = str_replace(Species, &quot;_&quot;, &quot; &quot;)) %&gt;% # str_replace is in the stringr package, which is part of tidyverse filter(N &gt; 0) # Remove species that aren&#39;t present View(tidy_ant_data) Habitat Site Canopy_cover Ground_cover Nearest_canopy_spp Disturbance Drought Phorids Notes GPS_Easting GPS_Northing name Acre Total_ants S_invicta_present Species N R 1 3 0 American Elm high 1 1 NA 105 815 student_1 52 250 1 Solenopsis invicta 250 R 2 3 1 pecan high 0 0 yellow jackets 96 826 student_1 52 5 0 Pheidole floridana 5 R 3 2 0 hackberry high 1 0 yellow jackets 86 848 student_1 52 5 0 Pheidole tetra 5 R 4 2 0 pecan high 1 1 yellow jackets 76 848 student_1 52 10 0 Pheidole tetra 10 R 5 3 1 pecan low 1 1 NA 87 862 student_1 52 62 1 Solenopsis invicta 62 R 6 1 3 pecan high 0 1 NA 104 842 student_1 52 20 0 Pheidole tetra 5 R 6 1 3 pecan high 0 1 NA 104 842 student_1 52 20 0 Solenopsis texana 15 R 7 0 2 pecan high 2 0 NA 109 836 student_1 52 175 1 Solenopsis invicta 175 R 8 3 0 hackberry high 1 0 NA 97 858 student_1 52 350 1 Solenopsis invicta 350 R 9 3 0 hackberry high 1 0 flies 107 859 student_1 52 31 0 Pheidole floridana 30 8.2 Jaccard similarity To calculate the Jaccard similarity of two communities, you need to divide the number of shared species by the total number of species. This can be done with a combination of the intersect(), union(), and length() functions. # Let&#39;s say these are the species in our two communities: com_a = LETTERS[1:5] com_b = LETTERS[3:8] print(com_a); print(com_b) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; ## [1] &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; # Species in common: intersect(com_a, com_b) ## [1] &quot;C&quot; &quot;D&quot; &quot;E&quot; # Species present in either: union(com_a, com_b) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; # Total number of species present: length(union(com_a, com_b)) ## [1] 8 # Jaccard similarity: length(intersect(com_a, com_b)) / length(union(com_a, com_b)) ## [1] 0.375 Since you’ll be doing this for several groups, it’s a good idea to write a function that will do this for us. jaccard_similarity = function(com_1, com_2) { # com_1 and com_2 are the arguments of the function, # they should be the names in different communities # Create local variables for the intersection and union; common_spp = intersect(com_1, com_2) total_spp = union(com_1, com_2) # these variables are created while the function runs &amp; destroyed when it ends # The last value of the function is its output (a.k.a., return value) length(common_spp) / length(total_spp) # return this } jaccard_similarity(com_1 = com_a, com_2 = com_b) ## [1] 0.375 How would we make this work with the dataset? Here’s one possibility: # Define the community comparison as disturbed river terrace vs undisturbed river terrace com_r_lo = tidy_ant_data %&gt;% # Subset the data to get the &quot;community&quot; you want filter(Habitat == &quot;R&quot;, Disturbance == &quot;low&quot;) %&gt;% # Get the list of species as a vector pull(Species) %&gt;% unique() com_r_hi = tidy_ant_data %&gt;% filter(Habitat == &quot;R&quot;, Disturbance == &quot;high&quot;) %&gt;% pull(Species) %&gt;% unique() com_r_lo ## [1] &quot;Solenopsis invicta&quot; &quot;Pheidole floridana&quot; &quot;Pheidole tetra&quot; ## [4] &quot;Pheidole pelor&quot; &quot;Pheidole dentata&quot; &quot;Other species&quot; com_r_hi ## [1] &quot;Solenopsis invicta&quot; &quot;Pheidole floridana&quot; &quot;Pheidole tetra&quot; ## [4] &quot;Solenopsis texana&quot; &quot;Camponotus texanus&quot; &quot;Pheidole dentata&quot; ## [7] &quot;Pheidole bicarinata&quot; &quot;Other species&quot; jaccard_similarity(com_r_lo, com_r_hi) ## [1] 0.5555556 There are more elegant &amp; efficient ways to do this, but they rely on some R techniques we haven’t talked about yet; I’ll be updating this chapter once I get the appropriate information into the book. 8.3 Species Accumulation Curves Species accumulation curves are calculated by the specaccum() function in vegan. This function requires a data set where each column is a species, each_row is a site, and each cell is a 1 (indicating presence) or 0 (indicating absence). Let’s create a function that will format the data for this: # Create a function that converts a number to presence-absense to_presence_absense = function(x) if_else(x &lt;= 0 | is.na(x), 0, 1) # Recodes data as 0 if it&#39;s 0 or missing or 1 otherwise # Format data for the species accumulation curve format_sac_data = function(wide_data) { wide_data %&gt;% # Select only species columns select(Solenopsis_invicta:Other_species) %&gt;% # We don&#39;t want to include this &quot;other species&quot; select(-Other_species) %&gt;% # use to_presence_absense() on all columns mutate(across(everything(), to_presence_absense)) } # Test it on quarry data: wide_ant_data %&gt;% filter(Habitat == &quot;Q&quot;) %&gt;% # Note: depending on the dataset, the Habitat variable may be recoded # as &quot;Quarry&quot;, &quot;River Terrace&quot;, etc instead of &quot;Q&quot;, &quot;R&quot; # You&#39;ll need to change the previous line of code so that it matches # what&#39;s in the dataset. format_sac_data() %&gt;% View() Solenopsis_invicta Pheidole_floridana Pheidole_tetra Solenopsis_texana Camponotus_texanus Aphenogaster_texana Brachymyermex Crematogaster_laeviuscula Forelius_mccooki Forelius_pruinosis Monomorium_minimum Odontomachus_clarus Paratrechina_terricola Pheidole_bicarinata Pheidole_dentata Pheidole_lamia Pheidole_metallescens Pheidole_pelor Pheilode_hyati Pseudomyrmex_brunneus Solenopsis_geminata Atta_texana Camponotus_sansabeaneus Pachycondyla_harpax 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 From here, you can sac_r = wide_ant_data %&gt;% filter(Habitat == &quot;R&quot;) %&gt;% format_sac_data() %&gt;% specaccum(method = &quot;random&quot;, permutations = 500) # Use these argument options Use print(sac_r) to look at the output. The results are basically a tidy data frame turned on its side: one row for the number of sites sampled, one for the estimated richness, and one for the error around the richness estimate. To plot this, we need to re-format the output. sac_r_tidy = tibble( sites = sac_r$sites, richness = sac_r$richness, se = sac_r$sd # the &quot;SD&quot; column is actually a standard error measure ) View(sac_r_tidy) sites richness se 1 0.946 0.3511847 2 1.708 0.5543922 3 2.326 0.7381149 4 2.794 0.8654838 5 3.188 0.9243185 6 3.516 0.9796241 7 3.810 0.9979438 8 4.074 1.0191179 9 4.302 1.0103651 10 4.546 1.0089201 From this, it’s relatively simple to create the actual plot: sac_r_plot = sac_r_tidy %&gt;% # Define the confidence intervals based on mean richness &amp; standard errors mutate(lower_ci = richness - se * 1.96, upper_ci = richness + se * 1.96) %&gt;% ggplot() + aes(x = sites, y = richness) + geom_line(size = 1) + # line for richness # The lines below add in confidence intervals geom_line(aes(y = lower_ci), linetype = 2, alpha = .7) + geom_line(aes(y = upper_ci), linetype = 2, alpha = .7) + # alpha adds a bit of transparency xlab(&quot;Sampling intensity (number of sites)&quot;) + ylab(&quot;Number of ant species&quot;) sac_r_plot Let’s combine these last few steps into a pair of functions, for re-use with different data sub-sets: get_sac = function(wide_data) { # wide_data is data in the wide format, probably subset or filtered sac = format_sac_data(wide_data) %&gt;% # Convert to SAC format specaccum(method = &quot;random&quot;, permutations = 500) # calculate SAC tibble( # Tidy output sites = sac$sites, richness = sac$richness, se = sac$sd ) %&gt;% mutate(lower_ci = richness - se * 1.96, upper_ci = richness + se * 1.96) } plot_sac = function(sac_data) { # sac_data is the output of get_sac() sac_data %&gt;% ggplot() + aes(x = sites, y = richness) + geom_line(size = 1) + # line for richness # The lines below add in confidence intervals geom_line(aes(y = lower_ci), linetype = 2, alpha = .7) + geom_line(aes(y = upper_ci), linetype = 2, alpha = .7) + # alpha adds a bit of transparency xlab(&quot;Sampling intensity (number of sites)&quot;) + ylab(&quot;Number of ant species&quot;) } From here, we easily try different combinations wide_ant_data %&gt;% filter(Habitat == &quot;P&quot;) %&gt;% get_sac() %&gt;% plot_sac() When comparing multiple groups, it’s best to put them together in a single plot. The easiest way to do that is to calculate the SAC data, then combine the resulting data frames # Create the SAC data frames for each group in your comparison sac_dist_hi = wide_ant_data %&gt;% filter(Disturbance == &quot;high&quot;) %&gt;% get_sac() %&gt;% mutate(Disturbance = &quot;high&quot;) # Use the Mutate Add disturbance column to sac results sac_dist_low = wide_ant_data %&gt;% filter(Disturbance == &quot;low&quot;) %&gt;% get_sac() %&gt;% mutate(Disturbance = &quot;low&quot;) # Add disturbance column back to sac results sac_dist_combined = # Combine them into one data frame bind_rows(sac_dist_hi, sac_dist_low) # Note that bind_rows() can combine more than two data frames, if you&#39;re doing a 3+ part comparison plot_sac(sac_dist_combined) + # Creates a standard SAC Plot aes(color=Disturbance) + # Separates out the lines by color based on the Disturbance column scale_color_viridis_d() # Make the colors look nice 8.4 Rank Abundance Curves This is really just an exercise in data manipulation: we want to get the total number of individuals of each species, then display them in decreasing frequency. You need to summarize your data frame so that there’s one row per species, with columns Species and N (which is the species-level sum of the already existing N column in tidy_ant_data). I’m not providing the code for this; you should be able to piece it together from the dplyr and/or ggplot appendices. I would recommend creating a function that does the work, so that you can reuse it. To make the plot itself, you can use this function: plot_rank_abundance = function(summarized_data, right_margin = 2.8) { # Make the rank abundance plot # The right_margin argument is used to make sure that # the angled axis labels don&#39;t go of the page # make it larger or smaller to suit your tastes ggplot(summarized_data, aes(x = Species, y = N)) + geom_line(group = 1) + # Create a descending line scale_y_log10() + # puts y axis on log scale theme(axis.text.x = # cleans up appearance of x axis labels element_text(angle = -20, hjust = 0.05, # angled, justified text vjust = 1, face = &quot;italic&quot;), # also in italics # makes sure that the axis labels don&#39;t go off the page plot.margin = unit(c(0,right_margin,0,0)+.1, &quot;cm&quot;)) # Be sure sure that Species has been coded as a factor, in decreasing order of N! } Your resulting plot should look something like this: 8.5 Shannon Index &amp; Diversity Let’s make a function that calculates the Shannon index of a community: shannon_diversity = function(species, count) { # species: vector of species names; # count: how many of each species are present # Create p, a vector of relative frequencies p = tibble(species, count) %&gt;% # Merge duplicate species group_by(species) %&gt;% summarize(count = sum(count)) %&gt;% ungroup() %&gt;% # Remove zeroes filter(count &gt; 0) %&gt;% # Convert to frequencies mutate(p = count / sum(count)) %&gt;% # Extract column p pull(p) if(length(p) &lt; 2) return(0) # one or 0 species has an H of 0 exp( -sum(p * log(p)) ) # exponential of shannon index } # Calculate the shannon diversity shannon_diversity(LETTERS[1:5], # Species names, A : E c(100, 5, 30, 22, 140)) # Species counts ## [1] 3.367463 This function should work well with a grouped summarize function: tidy_ant_data %&gt;% group_by(Acre, Habitat) %&gt;% # group by Acre &amp; habitat summarize(shannon = shannon_diversity(Species, N)) %&gt;% View() ## `summarise()` has grouped output by &#39;Acre&#39;. You can override using the `.groups` argument. Acre Habitat shannon 1 P 3.205639 4 P 3.485273 9 Q 3.552628 10 P 2.924111 13 P 1.894624 14 P 1.825931 15 P 3.726142 19 P 2.769997 20 P 2.017839 34 NA 3.359807 "],["tidyr-tutorial.html", "Chapter 9 Wrangling, reshaping, and tidying data with tidyr 9.1 Tidy data 9.2 Going from many columns to many rows: pivot_longer() 9.3 Splitting and merging columns: separate() and unite() 9.4 Pivoting multiple columns", " Chapter 9 Wrangling, reshaping, and tidying data with tidyr 9.1 Tidy data Most of the previous appendices have required you to have your data in a tidy format. Tidy data consist of data frames with the following characteristics: Each column is a different variable Each row is a single observation Each cell is a single value The packages in the tidyverse are generally designed to operate on tidy data; however, other functions may require the data to be in a different shape. It’s also frequently convenient to record field data in a non-tidy format. The tidyr package is designed to reshape your data. For more information on tidy data, please see this article. We’re going to be using some new datasets for this chapter; if you don’t have them already, download them here and put them in your “example_data” directory. library(tidyverse) library(cowplot) theme_set(theme_cowplot()) lizards &lt;- read_csv(&quot;example_data/anoles.csv&quot;) # See Appendix A if you don&#39;t have this data succession_data_wide &lt;- read_csv(&quot;example_data/succession_wide.csv&quot;) yeast_data &lt;- read_csv(&quot;example_data/yeast_data_partial.csv&quot;) 9.2 Going from many columns to many rows: pivot_longer() Let’s look at the succession data file; this is slightly modified data from Fall 2018, which was collected as part of the first lab (Section @ref(#lab1)). View(succession_data_wide) Type Team Sample Quadrant Distance DBH Acer negundo (Boxwood elder) Bumelia lanuginosa (Gum elastic) Carya illinoiensis (Pecan) Celtis spp. (Hackberry) Fraxinus texana (Texas ash) Juniperus spp. (Juniper) Melia azederach (Chinaberry) Morus rubra (Red mulberry) Populus deltoides (Cottonwood) Prunus caroliniana (Laurel cherry) Quercus buckleyi (Spanish oak) Quercus fusiformis (Live oak) Quercus stellata (Post Oak) Triadica sebifera (Chinese Tallow) Ulmus americana (American elm) Ulmus crassifolia (Cedar elm) P-C A 1 a 4 15.0 NA NA NA NA NA 1 NA NA NA NA NA NA NA NA NA NA P-U A 1 a 4 NA NA NA NA NA NA NA NA NA NA NA NA 1 NA NA NA NA P-C A 1 b 5 16.5 NA NA NA NA NA 1 NA NA NA NA NA NA NA NA NA NA P-U A 1 b 3 NA NA NA NA NA NA NA NA NA NA NA NA 1 NA NA NA NA P-C A 1 c 2 15.0 NA NA NA NA NA 1 NA NA NA NA NA NA NA NA NA NA P-U A 1 c 4 NA NA NA NA NA NA 1 NA NA NA NA NA NA NA NA NA NA P-C A 1 d 4 14.0 NA NA NA 1 NA NA NA NA NA NA NA NA NA NA NA NA P-U A 1 d 2 NA NA NA NA 1 NA NA NA NA NA NA NA NA NA NA NA NA P-C A 2 a 2 21.5 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 1 P-U A 2 a 3 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 1 A quick description of the columns: Type: Contains information on both the habitat type and Canopy/Understory Team, Sample, Quadrant: identifiers for where the data were collected Distance: Distance in meters fromt the central point to the tree DBH: Diameter at breast height for canopy trees 16 species columns: These indicate whether the named species is present with a 1; there should only be a single 1 per row. This clearly does not meet the definition of tidy data; the “Species” variable is split between columns, and the habitat type and tree type are both combined into a single “type” column. The first step to tidying this data is consolidate the last sixteen columns; we’re going to use pivot_longer() for that. In its simplest form, pivot_longer() converts several columns into two: one with the original column names, and the other with the original column values. This will result in a data frame with more rows than the original (hence, “longer”). succession_data_wide %&gt;% pivot_longer( # The first argument is the column names you want to reshape # This uses the same syntax of select() and across() from dplyr cols = -c(Type:DBH), # minus sign grabs everything NOT between Type &amp; DBH: names_to = &quot;Species&quot;, # Name of the column that stores the old column names values_to = &quot;is_present&quot;) %&gt;% # Name of the oclumn that stores old cell values View() Type Team Sample Quadrant Distance DBH Species is_present P-C A 1 a 4 15 Acer negundo (Boxwood elder) NA P-C A 1 a 4 15 Bumelia lanuginosa (Gum elastic) NA P-C A 1 a 4 15 Carya illinoiensis (Pecan) NA P-C A 1 a 4 15 Celtis spp. (Hackberry) NA P-C A 1 a 4 15 Fraxinus texana (Texas ash) NA P-C A 1 a 4 15 Juniperus spp. (Juniper) 1 P-C A 1 a 4 15 Melia azederach (Chinaberry) NA P-C A 1 a 4 15 Morus rubra (Red mulberry) NA P-C A 1 a 4 15 Populus deltoides (Cottonwood) NA P-C A 1 a 4 15 Prunus caroliniana (Laurel cherry) NA If you’ll notice, the first 16 rows are identical in the Type:DBH columns, while Species and is_present vary. A few alternative ways to do the same thing: # The only difference between these is the .cols argument succession_data_wide %&gt;% pivot_longer( .cols = 7:22, # positions of the columns to pivot names_to = &quot;Species&quot;, values_to = &quot;is_present&quot;) succession_data_wide %&gt;% pivot_longer( -c(Type, Team, Sample, Quadrant, Distance, DBH), # explicitly list names names_to = &quot;Species&quot;, values_to = &quot;is_present&quot;) succession_data_wide %&gt;% pivot_longer( # You can use ranges of column names to keep, though that&#39;s not practical here `Acer negundo (Boxwood elder)`:`Ulmus crassifolia (Cedar elm)`, names_to = &quot;Species&quot;, values_to = &quot;is_present&quot;) succession_data_wide %&gt;% pivot_longer( .cols = contains(&quot;(&quot;), # graps all columns with an open parentheses in them names_to = &quot;Species&quot;, values_to = &quot;is_present&quot;) Note that the .cols argument generally doesn’t have quotations around its column names, while the names_to and values_to do. The simplest explanation for it is that the .cols columns already exist in the data, so R knows how to find them; the others don’t, so we use quotes to create the names (This isn’t entirely true, but the full details are quite complicated and it’s a useful rule of thumb for tidyverse functions). One thing to note about our output is that there’s a lot of NA values in is_present, indicating species that were not found at each point. We don’t really care about those, so let’s get rid of them. succession_longer = succession_data_wide %&gt;% pivot_longer( cols = -c(Type:DBH), names_to = &quot;Species&quot;, values_to = &quot;is_present&quot;) %&gt;% filter(!is.na(is_present)) %&gt;% # Remove missing values select(-is_present) # This column is no longer useful View(succession_longer) Type Team Sample Quadrant Distance DBH Species P-C A 1 a 4 15.0 Juniperus spp. (Juniper) P-U A 1 a 4 NA Quercus fusiformis (Live oak) P-C A 1 b 5 16.5 Juniperus spp. (Juniper) P-U A 1 b 3 NA Quercus fusiformis (Live oak) P-C A 1 c 2 15.0 Juniperus spp. (Juniper) P-U A 1 c 4 NA Juniperus spp. (Juniper) P-C A 1 d 4 14.0 Celtis spp. (Hackberry) P-U A 1 d 2 NA Celtis spp. (Hackberry) P-C A 2 a 2 21.5 Ulmus crassifolia (Cedar elm) P-U A 2 a 3 NA Ulmus crassifolia (Cedar elm) (( Add example to practice with genotype data)) 9.3 Splitting and merging columns: separate() and unite() To fully tidy this, we need to split the “Type” column into habitat type and tree type columns. The separate() function is useful for this. succession_sep = succession_longer %&gt;% separate(col = Type, # Column to separate; note that the arg is col, not .col into = c(&quot;Habitat&quot;, &quot;Tree_type&quot;), # Names of the new columns to separate into sep = &quot;-&quot;) # the character used to mark the separation View(succession_sep) Habitat Tree_type Team Sample Quadrant Distance DBH Species P C A 1 a 4 15.0 Juniperus spp. (Juniper) P U A 1 a 4 NA Quercus fusiformis (Live oak) P C A 1 b 5 16.5 Juniperus spp. (Juniper) P U A 1 b 3 NA Quercus fusiformis (Live oak) P C A 1 c 2 15.0 Juniperus spp. (Juniper) P U A 1 c 4 NA Juniperus spp. (Juniper) P C A 1 d 4 14.0 Celtis spp. (Hackberry) P U A 1 d 2 NA Celtis spp. (Hackberry) P C A 2 a 2 21.5 Ulmus crassifolia (Cedar elm) P U A 2 a 3 NA Ulmus crassifolia (Cedar elm) Note that the sep argument can be either text or a integer(s); if it’s a character vector, the character(s) are removed during the split (as with above). If sep is an integer (or integer vector), then the split is made after that/those position(s) in the text without removing anything. It would also be useful to have a column that specifically identifies the each sample point; currenlty, that information is split between the Habitat, Team, and Sample columns. The unite() function does this (it’s the complement of separate). succession_tidy = succession_sep %&gt;% unite(col = &quot;sample_point&quot;, # Name of new colum Habitat, Team, Sample, # columns to unite (note; these are all seaprate args) sep = &quot;-&quot;, # separate the columns with a dash remove = FALSE # by default, unite() removes the columns to separate; this disables that because we want to keep Habitat ) %&gt;% select(-Team, -Sample) succession_tidy %&gt;% View() sample_point Habitat Tree_type Quadrant Distance DBH Species P-A-1 P C a 4 15.0 Juniperus spp. (Juniper) P-A-1 P U a 4 NA Quercus fusiformis (Live oak) P-A-1 P C b 5 16.5 Juniperus spp. (Juniper) P-A-1 P U b 3 NA Quercus fusiformis (Live oak) P-A-1 P C c 2 15.0 Juniperus spp. (Juniper) P-A-1 P U c 4 NA Juniperus spp. (Juniper) P-A-1 P C d 4 14.0 Celtis spp. (Hackberry) P-A-1 P U d 2 NA Celtis spp. (Hackberry) P-A-2 P C a 2 21.5 Ulmus crassifolia (Cedar elm) P-A-2 P U a 3 NA Ulmus crassifolia (Cedar elm) An alternative option to unite() is to use a combination of mutate() and paste(): succession_sep %&gt;% mutate(sample_point = paste(Habitat, Team, Sample, sep = &quot;-&quot;)) %&gt;% select(-Team, -Sample) %&gt;% View() # The column order will be different, but otherwise it&#39;s the same. 9.4 Pivoting multiple columns We’re going to take a look a dataset from Brauer et al (2008). The experiment tested yeast gene expression under nutrient limitation (for several different nutrients &amp; several different concentrations). View(yeast_data) gene_name bio_process mol_func syst_id G0.05 G0.1 G0.15 G0.2 G0.25 G0.3 N0.05 N0.1 N0.15 N0.2 N0.25 N0.3 P0.05 P0.1 P0.15 P0.2 P0.25 P0.3 S0.05 S0.1 S0.15 S0.2 S0.25 S0.3 L0.05 L0.1 L0.15 L0.2 L0.25 L0.3 U0.05 U0.1 U0.15 U0.2 U0.25 U0.3 SFB2 ER to Golgi transport molecular function unknown YNL049C -0.24 -0.13 -0.21 -0.15 -0.05 -0.05 0.20 0.24 -0.20 -0.42 -0.14 0.09 -0.26 -0.20 -0.22 -0.31 0.04 0.34 -0.51 -0.12 0.09 0.09 0.20 0.08 0.18 0.18 0.13 0.20 0.17 0.11 -0.06 -0.26 -0.05 -0.28 -0.19 0.09 NA biological process unknown molecular function unknown YNL095C 0.28 0.13 -0.40 -0.48 -0.11 0.17 0.31 0.00 -0.63 -0.44 -0.26 0.21 -0.09 -0.04 -0.10 0.15 0.20 0.63 0.53 0.15 -0.01 0.12 -0.15 0.32 0.16 0.09 0.02 0.04 0.03 0.01 -1.02 -0.91 -0.59 -0.61 -0.17 0.18 QRI7 proteolysis and peptidolysis metalloendopeptidase activity YDL104C -0.02 -0.27 -0.27 -0.02 0.24 0.25 0.23 0.06 -0.66 -0.40 -0.46 -0.43 0.18 0.22 0.33 0.34 0.13 0.44 1.29 -0.32 -0.47 -0.50 -0.42 -0.33 -0.30 0.02 -0.07 -0.05 -0.13 -0.04 -0.91 -0.94 -0.42 -0.36 -0.49 -0.47 CFT2 mRNA polyadenylylation* RNA binding YLR115W -0.33 -0.41 -0.24 -0.03 -0.03 0.00 0.20 -0.25 -0.49 -0.49 -0.43 -0.26 0.05 0.04 0.03 -0.04 0.08 0.21 0.41 -0.43 -0.21 -0.33 -0.05 -0.24 -0.27 -0.28 -0.05 0.02 0.00 0.08 -0.53 -0.51 -0.26 0.05 -0.14 -0.01 SSO2 vesicle fusion* t-SNARE activity YMR183C 0.05 0.02 0.40 0.34 -0.13 -0.14 -0.35 -0.09 -0.08 -0.58 -0.14 -0.12 -0.16 0.18 0.21 0.08 0.23 -0.29 -0.70 0.05 0.10 -0.07 -0.10 -0.32 -0.59 -0.13 0.00 -0.11 0.04 0.01 -0.45 -0.09 -0.13 0.02 -0.09 -0.03 PSP2 biological process unknown molecular function unknown YML017W -0.69 -0.03 0.23 0.20 0.00 -0.27 0.17 -0.40 -0.54 -1.19 -0.42 1.89 -0.32 -0.06 -0.62 -0.50 -0.37 NA NA -0.20 -0.09 0.06 -0.19 -0.14 -0.17 -0.07 0.25 -0.21 0.12 -0.11 NA -0.65 0.09 0.06 -0.07 -0.10 RIB2 riboflavin biosynthesis pseudouridylate synthase activity* YOL066C -0.55 -0.30 -0.12 -0.03 -0.16 -0.11 0.04 0.00 -0.63 -0.51 -0.37 -0.24 -0.35 -0.32 -0.39 -0.60 -0.29 -0.25 -0.14 -0.50 -0.19 -0.13 -0.01 -0.04 -0.02 -0.05 0.27 0.24 0.05 0.19 0.07 -0.31 -0.08 0.12 0.05 0.06 VMA13 vacuolar acidification hydrogen-transporting ATPase activity, rotational mechanism YPR036W -0.75 -0.12 -0.07 0.02 -0.32 -0.41 0.11 -0.16 -0.26 -0.42 0.18 0.13 -0.19 -0.25 -0.25 -0.47 -0.24 -0.49 0.09 0.13 0.15 -0.02 0.24 -0.08 -0.11 -0.01 0.15 0.15 0.00 0.03 -0.40 -0.02 0.26 0.31 0.14 0.11 EDC3 deadenylylation-independent decapping molecular function unknown YEL015W -0.24 -0.22 0.14 0.06 0.00 -0.13 0.30 0.07 -0.30 -0.01 0.15 0.13 -0.26 -0.20 -0.22 -0.17 -0.23 -0.38 -0.35 -0.14 0.10 -0.04 0.22 0.02 0.12 -0.01 0.17 0.07 0.10 0.11 0.01 -0.16 0.07 0.20 0.02 0.10 VPS5 protein retention in Golgi* protein transporter activity YOR069W -0.16 -0.38 0.05 0.14 -0.04 -0.01 0.39 0.20 0.27 0.19 0.20 0.06 -0.23 -0.20 -0.07 -0.13 -0.14 -0.42 -0.38 -0.14 0.00 -0.06 0.16 -0.15 -0.20 -0.18 0.11 0.00 0.02 0.09 -0.26 -0.13 -0.10 0.07 -0.04 -0.12 The first four columns are single variables (gene name, biological process, molecular function, and systematic_id). The remaining columns (G0.05 through U0.3) contain TWO variables in their name: the nutrient that was added to the substrate (first letter) and rate at which it was added (the rest). The values in these columns is the gene expression level. To tidy the data, we need to convert these into three columns: Substrate Concentration Gene expression While we could do this with a combination of pivot_longer() and separate(), pivot_longer() can do both tasks at once with a few extra arguments. yeast_data %&gt;% pivot_longer(G0.05:U0.3, names_to = c(&quot;Substrate&quot;, &quot;Concentration&quot;), # The names will go into these columns names_sep = 1, # separate the names between columns after the first character values_to = &quot;Gene_expression&quot;) %&gt;% glimpse() ## Rows: 199,332 ## Columns: 7 ## $ gene_name &lt;chr&gt; &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;… ## $ bio_process &lt;chr&gt; &quot;ER to Golgi transport&quot;, &quot;ER to Golgi transport&quot;, &quot;ER … ## $ mol_func &lt;chr&gt; &quot;molecular function unknown&quot;, &quot;molecular function unkn… ## $ syst_id &lt;chr&gt; &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;,… ## $ Substrate &lt;chr&gt; &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;,… ## $ Concentration &lt;chr&gt; &quot;0.05&quot;, &quot;0.1&quot;, &quot;0.15&quot;, &quot;0.2&quot;, &quot;0.25&quot;, &quot;0.3&quot;, &quot;0.05&quot;, &quot;… ## $ Gene_expression &lt;dbl&gt; -0.24, -0.13, -0.21, -0.15, -0.05, -0.05, 0.20, 0.24, … The names_sep argument works exactly like sep in separate(). Notice that Concentration is listed as a character vector (&lt;chr&gt;). It’s probably a good idea to have it as a numeric vector instead. The names_transform argument lets you specify a function that can be applied to the names column(s) after they’re re-shaped. In this case, we’re going to use as.numeric() to convert it into a number. # We&#39;re going to create a list that tells pivot_longer to use the # as.numeric() function on Concentration # a list() is basically a big box you can put any other kind of data structure into # Each item in a list is called an elements; elements can be named or not # This list has one named element; if we wanted to transform more columns, we could include them here as well convert_concentration = list( Concentration = as.numeric # Note there&#39;s no parentheses; this is because we&#39;re identifying the function, not calling it. ) # We&#39;ll talk more about lists later tidy_yeast = yeast_data %&gt;% pivot_longer(G0.05:U0.3, names_to = c(&quot;Substrate&quot;, &quot;Concentration&quot;), names_sep = 1, names_transform = convert_concentration, # We could also have defined the list here values_to = &quot;Gene_expression&quot;) tidy_yeast %&gt;% glimpse() ## Rows: 199,332 ## Columns: 7 ## $ gene_name &lt;chr&gt; &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;… ## $ bio_process &lt;chr&gt; &quot;ER to Golgi transport&quot;, &quot;ER to Golgi transport&quot;, &quot;ER … ## $ mol_func &lt;chr&gt; &quot;molecular function unknown&quot;, &quot;molecular function unkn… ## $ syst_id &lt;chr&gt; &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;,… ## $ Substrate &lt;chr&gt; &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;,… ## $ Concentration &lt;dbl&gt; 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.05, 0.10, 0.15, … ## $ Gene_expression &lt;dbl&gt; -0.24, -0.13, -0.21, -0.15, -0.05, -0.05, 0.20, 0.24, … 9.4.1 Combining pivot_longer() with summarise() Here’s a particularly powerful combination of tidyverse() functions you can use when you’re exploring a new dataset: calculate summary statistics on all of your variables with summarise(across(...)), tidy the results with pivot_longer(), then create a faceted ggplot. lizard_smry_by_color = lizards %&gt;% # Group the data by color morph group_by(Color_morph) %&gt;% summarize( across(where(is.numeric), # For all numeric columns... list(Mean = mean, Med = median, SD = sd) # run mean(), meidan(), and sd() on each group &amp; variable # Note that the list elements follows the pattern Name = function ),N = n() ) # This is outside of across, since it&#39;s only run once per group glimpse(lizard_smry_by_color) ## Rows: 3 ## Columns: 20 ## $ Color_morph &lt;chr&gt; &quot;Blue&quot;, &quot;Brown&quot;, &quot;Green&quot; ## $ Limb_Mean &lt;dbl&gt; 13.08791, 13.27692, 13.11584 ## $ Limb_Med &lt;dbl&gt; 13.1, 13.1, 12.8 ## $ Limb_SD &lt;dbl&gt; 1.802216, 1.778345, 1.911442 ## $ Mass_Mean &lt;dbl&gt; 6.955116, 7.118371, 6.997738 ## $ Mass_Med &lt;dbl&gt; 6.92, 7.09, 6.99 ## $ Mass_SD &lt;dbl&gt; 1.067424, 1.097275, 1.098401 ## $ Diameter_Mean &lt;dbl&gt; 32.88372, 24.11765, 11.47511 ## $ Diameter_Med &lt;dbl&gt; 33, 24, 11 ## $ Diameter_SD &lt;dbl&gt; 5.495152, 4.539194, 5.132390 ## $ Height_Mean &lt;dbl&gt; 171.2744, 167.2534, 167.7557 ## $ Height_Med &lt;dbl&gt; 184, 172, 175 ## $ Height_SD &lt;dbl&gt; 43.11129, 41.40915, 43.63552 ## $ SVL_Mean &lt;dbl&gt; 60.28000, 61.55928, 60.40633 ## $ SVL_Med &lt;dbl&gt; 59.5, 60.9, 57.9 ## $ SVL_SD &lt;dbl&gt; 8.741475, 8.349435, 9.006788 ## $ Tail_Mean &lt;dbl&gt; 56.90837, 57.97647, 57.75385 ## $ Tail_Med &lt;dbl&gt; 56.3, 58.0, 58.2 ## $ Tail_SD &lt;dbl&gt; 12.46141, 11.69319, 12.25767 ## $ N &lt;int&gt; 215, 221, 221 This creates a data frame with columns for the color, the sample size, and a bunch that follow the pattern Trait_statistic. An ideal way to tidy these data would be reduce these columns into Trait, Mean, Median, and SD. We can do that like this: lizard_smry_tidy = lizard_smry_by_color %&gt;% pivot_longer(-c(Color_morph, N), # exclude the columns names_to = c(&quot;Trait&quot;, &quot;.value&quot;), names_sep = &quot;_&quot;) %&gt;% mutate(SE = SD/sqrt(N)) # may as well calculate standard error while we&#39;re here View(lizard_smry_tidy) Color_morph N Trait Mean Med SD SE Blue 215 Limb 13.087907 13.10 1.802216 0.1229101 Blue 215 Mass 6.955116 6.92 1.067424 0.0727977 Blue 215 Diameter 32.883721 33.00 5.495152 0.3747663 Blue 215 Height 171.274419 184.00 43.111289 2.9401655 Blue 215 SVL 60.280000 59.50 8.741475 0.5961636 Blue 215 Tail 56.908372 56.30 12.461410 0.8498611 Brown 221 Limb 13.276923 13.10 1.778345 0.1196244 Brown 221 Mass 7.118371 7.09 1.097275 0.0738107 Brown 221 Diameter 24.117647 24.00 4.539193 0.3053392 Brown 221 Height 167.253394 172.00 41.409145 2.7854805 This call didn’t have a values_to argument in it; instead, one of the names_to was listed as \".value\". This is a special indicator that tells pivot_longer to create one column for each matching name and place the corresponding values into it. From here, you can make a nice little summary statistic plot: lizard_smry_tidy %&gt;% ggplot(aes(x = Color_morph)) + facet_wrap(~Trait, scales = &quot;free_y&quot;) + # SD: geom_linerange(aes(ymin = Mean - SD, ymax = Mean + SD), color = &quot;cornflowerblue&quot;) + # Confidence Interval: geom_errorbar(aes(ymin = Mean - SE * 1.96, ymax = Mean + SE * 1.96), color = &quot;red&quot;, width = .3) + # Mean geom_point(aes(y = Mean), size = 2) + ylab(&quot;Trait Mean, SD, and 95% CI&quot;) "],["lab-succession.html", "Chapter 10 Succession Lab 10.1 Introduction to the lab 10.2 Materials and Methods 10.3 Analysis to perform 10.4 Discussion 10.5 General Comments (Post-Review)", " Chapter 10 Succession Lab 10.1 Introduction to the lab Several habitat types can be discerned during a walk through BFL, each representing the integration of biotic and environmental factors with disturbance history. Here we look at species composition and age structure of trees that characterize some of these habitats. The relative abundance of different size classes of various tree species in a forest can provide clues about the history and future status of those species in that forest. For example, even if a tree species is abundant, yet represented only by large, older individuals, it is likely that the requirements for seed production or seedling establishment in the area have not been present in recent times. In order to predict the future status of that tree species in a given area we would need to find out about its requirements for regeneration and determine the likelihood that such conditions will be repeated during specified time periods. For example, for a species that requires a fire to germinate and establish, we would need to predict when fires are likely. In contrast, a tree species represented by a large population of saplings (presumed from their size) must have recently enjoyed favorable conditions for reproduction and establishment. Will such a species therefore dominate a future forest on the site? Possibly, but this may be difficult to answer since factors like disease, herbivory, fire, and/or shading by faster growing competitors may affect the survivorship of this cohort over time. Studying the size or age structure of a population helps ecologists make such projections. (Note that we generally assume that big trees are older than smaller individuals of the same species, but keep in mind that individuals of the same size may differ in age and vice versa. Local variation in microclimate edaphic factors (having to do with the soil) and light environment may result in rather different trajectories of growth for identical seedlings germinating the same year.) The goal of this project is to acquaint you with some of the kinds of data ecologists collect in attempting to answer questions about population trends. This exercise will also expose you to the always-messy issue of how to collect field data, and to give you insight and experience in statistical analyses appropriate for testing hypotheses about differences between species within different habitats in the age/size structure of trees. We will observe and quantify the distribution, abundance and size structure of dominant tree species at BFL. However, in collecting data to describe densities and size structures of these species at BFL, we are in position to test whether species have responded differently to major variations in the habitat at BFL. Once we have collected data on the trees with respect to variations in habitat at BFL, the patterns observed may stimulate additional questions and hypotheses. 10.2 Materials and Methods 10.2.1 BFL habitat regions To collect data we will establish transects in three areas of interest: the lower river terrace, the old pastures (experimental plots) and the quarry zone (see figure 10.1 for a map). Figure 10.1: Habitat map of BFL; for the purposes of this lab, the river terrace corresponds to the pecan terrace and flood deposited terrace (near the bottom), the old pasture is the central area, and the old quarry is near the top. 10.2.2 Data Collection Given the brief time allowed by the class period, we don’t count absolute numbers, but instead use sampling techniques for describing tree populations and habitats. We will use the Point-Quarter Technique to collect data (Cox p. 66). The beauty of this method is that it allows us to quickly estimate the density of selected species in the community while gathering information on their relative abundances. Each team will perform a survey in each of 3 apparently distinctive habitats. 10.2.2.1 Point-quarter for quarry and river terrace habitats Sample Point selection: Starting with an existing transect marker in the zone your team is assigned, flip a coin (or use a random number generator) to determine direction (left or right) that you will take perpendicular to the trail. Use a random number generator app to pick a number between 10 and 39 (alternatively, have one team member think of a number between 1 and 3 and another between 0 and 9). Your first point will this many meters from the trail in the predetermined direction. Repeat this process at the next transect tag, but in the opposite direction. Repeat it a third time for a total of 3 sample points in the habitat. Note: Areas recently cleared or plowed should be excluded. Each sample point is to be temporarily marked with a flag (do not leave any flags behind!!). The 3 sample points along each transect represent the center of four quadrants with sides along and perpendicular to the transect line. In each quadrant, you will determine the nearest canopy tree and sapling to the center point. Canopy trees are defined as having a crown that is exposed directly to sunlight and forms part of the overhead canopy. Saplings occur under the crown of canopy and are assumed to be potential canopy replacements when the canopy tree dies. Data to collect from each point: Location (with UTM) Species of nearest canopy trees &amp; saplings Distance of these trees from the center point Diameter at breast height (dbh) of canopy trees Note signs of drought stress (leaves are wilted or dead/brown) 10.2.2.2 Point quarter for old pasture habitat (pond enclosures) Sample Point selection: Because there are edge effects around enclosure walls and there is a pond in the center, we are primarily concerned with the forest that came into the sapce between the path around the wall and the pond dam, replacing the pasture that Dr. Gilbert saw as a student in 1964. Divide the enclosure into 12 sections (like an analog clock face). Randomly choose 6 of these sections; your sample point will be along the path near the enclosure wall. For each of the six points, you will sample two quarters (facing away from the enclosure wall), not four; this will give you the same overall amount of data as the other two habitats. Otherwise, the procedure is the same as that of the other two habitats. 10.3 Analysis to perform You should provide data and analyses to address the following questions: What are the qualitative trends and characteristics of each habitat? How does the total density of canopy trees differ between habitats? Does relative abundance of each species differ between canopy and sapling trees? How consistent is this among habitats? Remember: describe what analyses you did in the method section, present what your found in the results section, and talk about what it means in the discussion. 10.3.1 Canopy tree density You can use the point-quarter method to estimate tree density at each site with a bit of math. Let \\(x_i\\) be the distance from your point to a sampled canopy tree. If you sampled 4 trees at a point, then the density in trees per square meters would be \\(\\frac{4}{x_1^2 + x_2^2 + x_3^2 + x_4^2}\\). More generally, the density is \\(1 / \\text{mean}(x^2)\\). Calculate density for each sample point, and convert it to hectares (multiply by \\(10,000 \\text{ m}^2/\\text{ha}\\)). How do densities compare between habitat types? Create a figure and compare the averages. Note that you won’t be able to claim that one group is different unless you use statistical tests, such as a one-way ANOVA (this is optional). 10.3.2 Species by habitat and life stage For each habitat, you will want to calculate the relative abundance of each tree species for canopy and sapling trees (i.e., number of Canopy species x in habitat y divided by total number of observed Canopy trees in y). Visualize the result for each habitat (a three-panel frequency plot would be the best way to go, with categories ordered by canopy abundance). To test if the relative proportions in canopy and saplings are equivalent, you should construct contingency tables for each habitat (See Table 10.1 for an example). Restrict each table to the five most common species in each habitat. Contingency tables can be constructed with pivot tables in Excel or the table() function in R. Use chi-square tests to see if the proportions of species are different between canopy and saplings for each habitat. Table 10.1: Abundance of most common canopy and sapling trees in the BFL old pasture habitat, Fall 2018. Carya illinoiensis Celtis spp. Juniperus spp. Quercus buckleyi Quercus fusiformis Ulmus crassifolia Canopy 7 2 17 3 2 9 Sapling 0 6 7 3 6 11 10.4 Discussion Some suggestions for discussion topics: How could differences in sapling/canopy relative abundances inform possible successional trends? Based on your results, what would you predict about future dominant species in the habitats? Did you observe anything else about the ecology or natural history of these areas that may help account for your results (e.g., drought stress, dead trees, invasive species, disease, etc)? What may be driving the differences in the habitat types? Considering the history of BFL may be helpful in explaining some of this. Develop a likely scenario for the past and future decades of tree population dynamics in the woodlands of BFL. How has drought and oak wilt affected the tree community at BFL? How might a scenario for succession based on currently healthy trees be changed if we include the information on stressed/dead trees? How could this line of research be expanded upon in future work? 10.5 General Comments (Post-Review) These were some general comments I had on a previous year’s reports; I’d recommend reading them, since they’re common mistakes that it would be good to avoid. 10.5.1 Figures Review the guidelines in the Figures chapter. Specifically: Don’t use figure titles; anything that could go there should be in the caption instead. Use colors that will work in black and white, Number figures in the order they’re cited in the main text; they should also be arranged in this order (e.g., figure 2 shouldn’t be placed before figure 1). If the figure contains new data (which all of these should), it should be cited in the results. Figure numbers shouldn’t have decimals in them (e.g., no Figures 1.1, 2.3, etc). If you have a multi-panel figure, refer to specific panels as Figure 1a, 1b, etc. If you have a multi-panel figure, there should be a single caption that explains what each of the panels are. Don’t use bar plots for group means; boxplots or violin plots are usually better. This is a very inefficient way to present 3 data points, and it provides no information about the data’s variability. Boxplots or violin plots are better options. (Note that bar plots are still fine for counts or proportions). No gridlines (see below) To remove gridlines in excel, just click on them and delete them. Base plots in R (with the plot() function) shouldn’t have them by default. To remove them with ggplot2 figures, put this near the top of the code: install.packages(&quot;cowplot&quot;) # if you don&#39;t have this installed; run once library(cowplot) theme_set(theme_cowplot()) # this makes your ggplots look nicer until you restart R # ggplot commands here 10.5.2 Write this like you’re trying to publish it You should write these reports as if you were writing a manuscript for a journal. Pretend it’s not a class paper; don’t say “For this lab, our assignment was…” or “the other students…” Write like it’s a research project; you came up with the hypotheses and methods and the other students in the class are your collaborators. When describing the data collection, you need to describe how all of this year’s data was collected, for all groups. Instead of saying “we sampled three points in per habitat,” say “five groups each sampled three points per habitat.” As part of this, don’t talk about combining your group’s data with the rest. Finally, you need to have a real title. 10.5.3 Describe the habitats Since the different habitat types are an important part of this paper, you should describe them in a reasonable amount of detail; this could go in the intro or methods section, depending on how you wrote it. 10.5.4 The Analysis Formally, the chi-squared test evaluates whether the rows and columns of a contingency table are independent of each other. In the context of this project, that’s equivalent to testing whether the Canopy:Sapling ratio was equal for each species OR if the prevalence of each species was the same for canopy and sapling trees. Several people misinterpreted the analysis as examining if there were more canopy or sapling trees. This wouldn’t work, because the chi-square test cannot tell you anything about the actual number of trees and because the way you collected the data (a fixed number of trees per point) was not set up to answer this question. The Chi-square analysis was often described incorrectly in the methods; an unfamiliar reader would not know what you were testing. When you’re describing the test, you don’t necessarily need to state the null/alternative hypotheses, but you need to make it clear what question you’re answering with it. It’s also worth remembering that the data we collect is generally not incredibly high precision. Our measurements generally don’t have the ability to distinguish between a mean density of 437.11 and 437.14; depending on the sample size, we may not even be able to distinguish between 437 and 442. Being overly precise doesn’t help. If your p-values are less than 0.0001, just report “p &lt; 0.0001.” 10.5.5 Keeping things in the right sections Many people restated the methods used for their statistical analyses in the results. For example: “I ran chi-squared tests, and they showed significant differences in the old quarry (chi-square = …, df = …, p = …), the old pasture (…) and the river terrace (…).” Don’t do this; instead, only provide the result. A better re-work of the above sentence would be: “Species composition was significantly different between canopy and sapling trees in the old quarry (…), the old pasture (…), and the river terrace (…).” Don’t put anything in the intro or methods that is actually a result. Many people listed the most common species found in each habitat in their “study area” sections. Since this was a major part of this lab, listing the dominant species should be accompanied by a citation to show evidence that this is already known. In general, if you find yourself saying that the most common species “were” something, then it sounds like you are talking about your own observations; if you say that they “are” or “have been” something, then it sounds like you’re talking about more general patterns. 10.5.6 Basic style and format rules Don’t capitalize things that don’t need capitalization (e.g., the point-quarter technique). Most acronyms should be defined before their first use (though there are a few exceptions, like ANOVA). Don’t say (p-value = x), say (p = x). If a paper has more than two authors, cite it as “(Smith et al., 2009),” not “(Smith, Johnson, Franks, and Brown, 2009). 10.5.7 Other Comments The “fisher test” is properly called Fisher’s exact test (with “Fisher” capitalized). If you used a stats program for a bunch of different things (as you usually do w/ R or Excel), mention it at the end of the section, not the beginning. RStudio is an interface for doing analysis with R; if you used it, you should say you did your analysis in R. Make sure to explain that sample points were selected differently in pond/old pasture than in other habitats. In the discussion, if you are listing several possible interpretations of your results, it’s a good idea to put the most interesting one(s) ahead of the “this is all random noise” option. "],["mark-release-recapture-mrr-lab.html", "Chapter 11 Mark-Release-Recapture (MRR) Lab 11.1 Introduction 11.2 Questions and hypotheses 11.3 Field Methods 11.4 Analysis 11.5 Discussion", " Chapter 11 Mark-Release-Recapture (MRR) Lab 11.1 Introduction The size of an animal population is an important quantity to measure if we wish to understand its ecological and evolutionary interactions. How population size varies with respect to weather, resources, or competing populations provides clues about which factors are significant in the distribution and abundance of a species. While plants and sessile animals are relatively easy to census, the mobility of most animals makes population studies very difficult. Therefore when one attempts to estimate the size of such populations it is necessary to use indirect methods such as Mark-Release-Recapture (MRR). 11.1.1 The Lincoln-Petersen model The basic method, from which most modern population size estimation procedures have evolved (Lincoln-Petersen), involves at least two sampling periods. During the first period, all animals captured are given marks. If the population size is \\(N\\) and \\(M_1\\) animals were caught and marked during the first period, then the fraction \\((M_1 / N)\\) represents the proportion of the population actually marked. Ideally, the marked animals will have mixed randomly with the remaining unmarked population before the second sample is taken (first assumption). During this second capture period, it is also assumed that the chance of catching any marked animal is equal to the chance of catching any unmarked member of the population (this assumption is violated if, for example, marked animals are more wary and harder to catch, or if the marks make detection substantially easier). Simple methods also assume no gains or losses in the populations between sample periods. If the assumptions of random mixing and capture hold, the following should be true: Some animals caught on the second sampling period (total number caught in second sample \\(= S_2\\)) will be re-captures of those marked on period one; the number of recaptures is represented by \\(R_2\\). \\(\\frac{R_2}{S_2} = \\frac{M_1}{N}\\). Thus, we can estimate the population size as: \\[\\hat{N} = \\frac{S_2 M_1}{R_2}\\] In other words, \\(R_2/M_1\\) estimates the fraction of \\(N\\) marked on the first day. This can be shown graphically as follows (\\(N\\) is the entire box, \\(M_1\\) is the blue row, \\(S_2\\) is the red column, and \\(R_2\\) is their purple intersection): MRR Diagram Assumptions of the Lincoln-Petersen method: Marks do not affect animals. Marked animals are mixed in the population. Marked and unmarked animals have the same probability of capture The population is closed (no birth/death/migration) Marks are not lost between samples Although we can never be sure that the estimated population size \\((\\hat{N})\\) equals the true value, \\(\\hat{N}\\) should approach \\(N\\) as \\(M_1\\) and \\(S_2\\) get larger. Even though intense enough sampling could allow direct measure of \\(N\\), real habitats are too complex and mobile animals too elusive. In this exercise, we will study a hybrid population of Heliconius butterflies. 11.1.2 Heliconius butterflies Our main focus for this exercise will be an enclosed hybrid population of Heliconius melopomene x Heliconius cydno. The exercise sits at the interface of population ecology and genetics since the study population is polymorphic for wing patterns reflecting a naturally occurring phenomenon in South America. It is known that males of Heliconius melpomene mate with females of Heliconius cydno in nature to yield species called H. heurippa, H. timareta, and likely others. Heliconius timareta displays a variety of color pattern types in different parts of its range. Such races are locally monomorphic (i.e. only one pattern exists in a particular place) However, genomic studies confirm that these populations share cydno mitochondrial haplotypes and a common mode of origination, in spite of diverse phenotypes. In the 1980s, Dr. Gilbert carried out studies of hybridization in H. cydno and H. melpomene in UT greenhouses and hypothesized the likely hybrid origin of species like H. timerata. Now that genomic studies verify his hypotheses on the origin of such species, Dr. Gilbert has recreated a hybrid population according to the likely mode of origin of H. timareta. This population is large and diverse in color pattern phenotypes for which we know the genetics of major pattern elements. Distribution of some Heliconius species With the hybrid H. cydno X H. melpomene population, you will be able to combine ecology and population genetics by applying Hardy-Weinberg law to test whether a force like selection or non-random mating is acting on wing pattern genes. Larry will photograph each numbered butterfly and post in a web album so that you can record the proportion of phenotypes and determine whether they are in Hardy-Weinberg equilibrium. Optix phenotypes We will score the orange/red/brown patterns for which the link between phenotype and genotype is now known. The mimetic phenotypes generated are key to the diversification of the genus, to predator protection niches, and to mutualism between sympatric species (Mullerian mimicry). A supergene locus controls expression of a transcription factor called Optix; this locus exhibits incomplete dominance, so the genotype can be directly determined from the phenotype. One allele (F) accounts for the red, orange, red or brown scales in the discal forewing band (beyond the large wing cell). Another allele (H) controls the presence of such scales on the hind wing and/or on the proximal FW in the cell region. We will use these genotypes to estimate whether the population is in Hardy-Weinberg Equilbirum 11.1.3 Hardy-Weinberg Equilbrium A few definitions are in order: Allele: one variant of a gene. For example, the Optix gene has the alleles \\(F\\) and \\(H\\). Genotype: in a diploid organism like Heliconius butterflies, there are two copies of most genes; the genotype is the combination of the alleles. For Optix, genotypes can be \\(FF\\), \\(FH\\), or \\(HH\\). An individual with 2 of the same alleles (\\(FF\\) or \\(HH\\)) is a homozygote, while an individual with different alleles (\\(FH\\)) is a heterozygote. Allele frequency: the proportion of each allele of a gene within a population. For 2-allele systems, we usually note these frequencies as \\(p\\) and \\(q\\), where \\(p + q = 1\\). In Optix, \\(p\\) is the frequency of \\(F\\) and \\(q\\) is the frequency of \\(H\\). Genotype frequency: the proportion of each genotype within a population. For Optix, we will be noting these as \\(f_{FF}\\), \\(f_{FH}\\), and \\(f_{HH}\\). Genotype frequencies will also sum to 1. Allele frequencies can be directly calculated from genotype frequencies \\((p=f_{FF}+0.5*f_{FH}\\), \\(q=1-p)\\). However, the reverse is not necessarily true. There are many possible genotype frequencies that can correspond to the same allele frequencies; as an extreme example, a population with 100 heterozygotes (\\(FH\\) genotypes) would have the same allele frequencies as one with 50 \\(FF\\) and \\(50\\) HH homozygotes. However, the two populations would look quite different. The relation between allele and genotype frequencies can help us understand a population’s biology. 11.1.3.1 Genotype frequencies at equilbrium If genotype frequencies are stable and unchanging from one generation to the next, then we can expect a certain relationship between genotype and allele frequencies: \\[f_{FF}=p^{2};\\,\\,\\,\\,\\,\\,\\,f_{FH}=2pq;\\,\\,\\,\\,\\,\\,\\,f_{HH}=q^{2}\\] This is called Hardy-Weinberg Equilibrium (HWE). An easy way to remember this is that genotypes take two alleles, so expanding the equation \\((p+q)^{2}=1\\) will give you these ratios. HWE only applies for a population that is not changing. What can affect allele or genotype frequencies? Natural selection: If one allele or genotype provides an advantage in the current environment, individuals with this allele are likely to produce more offspring, which will increase the allele frequency over time. Migration: Allele frequencies tend to vary between populations of the same species; individuals moving from one population to another will make the allele frequencies more similar to each other. Genetic drift: Variation in individual mating success will cause random changes in allele frequencies, in large populations, these are so small that they usually average out; however, small populations can have substantial change between generations. Mutation: Random events can introduce new alleles; while this is rare and most mutations disappear through drift shortly after popping up, mutation is ultimately the source of all genetic variation. Non-random mating: If individuals prefer to mate with like individuals, this can increase the frequencies of homozygous genotypes; conversely, a preference for different individuals can increase heterozygote frequencies. Unlike the previous four, non-random mating changes genotype frequencies without changing allele frequencies. Pretty much any natural population will violate at least one of these conditions. So why is HWE useful? It gives us a baseline expectation to compare our observed genotype frequencies to. If our data are significantly different from the HWE values, we can conclude that one of these processes is playing an important role in the population. If not, then these processes are minor enough that we can ignore them. 11.1.3.2 Detecting violations of HWE To test whether our genotype data is in Hardy-Weinberg equilibrium, we can use a chi-squared test of goodness-of-fit. First, we’ll need to calculate a chi-squared test statistic, which measures how strongly our observed data \\((O)\\) deviates from the HWE expectations \\((E)\\). \\[\\chi^{2}=\\sum_{i}\\frac{\\left(O_{i}-E_{i}\\right)^{2}}{E_{i}}\\] In terms of our data, this is equal to \\[\\chi^{2}=\\frac{\\left(f_{FF}-p^{2}\\right)^{2}}{p^{2}}+\\frac{\\left(f_{FH}-2pq\\right)^{2}}{2pq}+\\frac{\\left(f_{HH}-q^{2}\\right)^{2}}{q^{2}}\\] This is somewhat different from the chi-squared tests we’ve done in previous labs (which are chi-squared tests of independence). I’ll be providing some code that shows how to do this. 11.2 Questions and hypotheses Primary Questions: How does sampling intensity improve mark-release-recapture (MRR) population size estimates? Does separating animals by sex alter our estimate of population size? What’s the sex ratio? How does the Lincoln-Petersen model compare with alternate MRR methods? Are the Heliconius populations in Hardy-Weinberg equilbrium for the Optix gene? 11.3 Field Methods For the MRR exercise, your team will enter the greenhouse capture butterflies for two distinct periods. For the first period, your group will capture 5 different butterflies. re-mixes with the population. At least thirty minutes after you’ve completed the first period, return to the greenhouse for the second period and capture five more. The delay should give the butterflies time to mix with the population. Space yourselves out and move slowly around your area of the greenhouse when searching. For each butterfly, record its number (or bring it to Dr. Gilbert if it doesn’t have one). Butterflies often land and sit after capture; don’t resample these. Instead, scare them into flight (by gently waving your hand) to insure mixing of individuals in the population. After you’ve completed your data collection, you will be given a photo album of the marked butterflies; you will need to identify the genotype and sex of the butterflies in the images for the Hardy-Weinberg exercise. 11.4 Analysis The Lincoln-Petersen model: If \\(S_2\\) is the number of individuals collected in a sample period, \\(M_1\\) is total number of previously marked individuals, and \\(R_2\\) is the number of marked individuals who were recaptured, then you can estimate population size: \\[\\hat{N} = \\frac{S_2 M_1}{R_2}\\] 11.4.1 Effect of sampling intensity on Lincoln-Petersen \\(\\hat{N}\\) estimates We’re going to simulate increased sampling estimates by pooling together estimates from each team. I’ll be combining the data from each group in all possible team combinations (i.e., one team: A, B, C, …; two teams: AB, AC, AD, …; three teams: ABC, ABD, BCD, …). For each combination, you’ll need to calculate the Lincoln-Petersen population size estimate \\((\\hat{N})\\). Create a figure showing the effect of sample size on \\(\\hat{N}\\). 11.4.2 Sex ratios Using the combined data from all teams, estimate \\(\\hat{N}\\) separately for male and female butterflies. How does the sum of these estimates compare with the estimate when the sexes are lumped together? What is the sex ratio of the population? Does it differ from 50:50? Use a chi-square test to test this. 11.4.3 Comparison of Lincoln-Petersen with alternative method In 1970-71, Larry Gilbert collected data on a natural population of Heliconius in Trinidad (recall his paper spreadsheet from lecture with cells colored in to represent individuals). We will use this method to estimate population sizes. For each of the three sample periods, use a regression to model the relationship between the daily recapture proportion \\((x)\\) and the cumulative number of individuals marked \\((y)\\). Intuitively, a recapture rate of 1.0 would suggest that you’ve sampled the entire population; you could thus use this regression equation to estimate \\((\\hat{N})\\) by evaluating it when \\(x=1\\). Create a multi-panel regression plot to go along with these methods. Compare these estimates with the Lincoln-Petersen estimate from the day with the highest proportion of recaptures in the sampling period. Note that for each row of the Trinidad data, \\(S_2\\) = total_captured, \\(R_2\\) = recaptures, and \\(M_1\\) = (cumulative_m - new_captures). 11.4.4 Hardy-Weinberg First, you’ll want to get the observed numbers for each genotype; we’ll call these \\(N_{FF}\\), \\(N_{FH}\\), and \\(N_{HH}\\); the total sample size \\(N\\) is the sum of these. You can use the table command in R to calculate this. From these observed genotypes, you can calculate the genotype frequency of F, which is just \\(\\frac{N_{FF} + 0.5 N_{FH} }{N}\\)l let’s call this \\(p\\). You can get your HWE expected genotypes by using \\(p\\) and \\(q=1-p\\) to get your expected genotype frequencies; From here, you can run a chi-squared test. 11.5 Discussion You should address the following in your discussion: How well did we meet the assumptions of MRR? Our MRR data came from a closed population; briefly speculate about some of the potential problems with these estimates in an open, natural population (how would emigration/immigration or birth/death affect the estimates)? How might our study compare with data from a natural population? How well does the Lincoln-Petersen model compare with fractional recapture estimation in a natural population? How different were your population estimates? What factors could help explain them? Think of some creative ways you could improve sampling in an MRR project (beyond just increasing the sample size). Don’t forget to discuss your results from the sex ratio and genotype analyses. "],["Lab-heterogeneity.html", "Chapter 12 Heterogeneity Lab: 12.1 Introduction &amp; background 12.2 Questions and Hypotheses 12.3 Field Methods 12.4 Analyses", " Chapter 12 Heterogeneity Lab: 12.1 Introduction &amp; background Apparent uniformity of grassland and woodland phases of a natural landscape as viewed from high altitudes (e.g., as seen on Google Earth images) typically disappears as we travel at ground level. Close observation reveals variation in plant form and stature as well as in species association that can create a mosaic of definable alternatives within basic woodland / shrub land / grassland themes. For example, within in a forest there is heterogeneity vertically in the density of foliage. As a student, ecologist Robert MacArthur predicted that habitats that are highly variable in the structure of foliage should would provide more distinctive niches, which would support more bird species like warblers that forage for insects moving about in forest understory bushes, small trees and canopy trees. He proceeded to show that bird species diversity is correlated with an arbitrary index termed “foliage height diversity” (FHD). MacArthur and MacArthur (1961) calculated FHD using estimates of the proportion of total foliage in the ground, shrub and canopy in eastern deciduous forests. This is an example of being creative in developing ways to quantify habitat variation in to test ecological hypotheses. The structural heterogeneity present in an undisturbed forest can be greatly increased by disturbance. A common form of natural disturbance in forested habitat is the death or removal of canopy trees creating “light gaps.” These gaps drive changes (and increase heterogeneity) in previously shaded understory plant populations. An example of how and why ecologists study forest gaps is seen in Lertzman et al. (1996). Note: This author and colleagues later developed the technology we apply in this exercise. Different plants and animals specialize on or rely on particular microhabitats and/or relationships generated by habitat disturbances like treefalls, landslides, fire, and herbivory. Thus some degree of disruption is promotes the diversity of species. Check out the controversy surrounding the “intermediate disturbance hypothesis”. Since the first 373L classes took these kinds of data in the early 2000’s, there have been major changes in shrub cover in several areas of BFL. In 2002, deer density had peaked at 68 animals and browsing in the forest understory for just 10 years had reduced shrub cover (anecdotal observations). Meanwhile light availability in the understory has increased due to tree disease and drought-caused mortality. Thus in the last 17 years many large live oaks have died from oak wilt and in the past 9 years severe drought has killed large hackberry, elm and juniper trees across BFL. Between 2007 and 2015 coyote predation reduced the BFL deer population from 25 to 4 individuals. As of early 2016 deer are extinct within BFL for the first time since 1991, by which time the impact of this large herbivore on vegetative structure was in steep decline=. The cumulative effect of losing deer browsing appears to be a dramatic increase in the density of tree saplings (e.g., laurel cherry, Texas Ash) and invasive shrubs (e.g., Chinese privet) in the forest understory. In this week’s project, we will attempt to classify and characterize the heterogeneity of habitat at BFL based upon the density of vegetation at the ground, shrub and canopy levels. In addition to learning some methods to describe degree of canopy disturbance, we will use digital cameras and gap light analysis software to test our ability to subjectively categorize canopy cover in an ecologically meaningful way. For this project, we define “canopy” as that part of the vegetation that shades understory vegetation. This exercise will teach methods for rapid assessment of vegetative structure. 12.2 Questions and Hypotheses What are the relationships between canopy, shrub, and ground cover? How do the relative abundances of Canopy, Shrub, and Ground cover compare with historical observations? You’ll also be doing to other things that aren’t specifically hypothesis or question driven, but should be presented in the results. Examining the spatial mosaic of canopy heterogeneity. Calibrating your subjective estimates of canopy estimates with the Gap Light Analyzer calculations. This in particular isn’t a biological hypothesis, but comparing different methods for addressing the same question is a common feature of biological research. 12.3 Field Methods After a review of the variety of ground covers, shrub covers and canopy covers encountered at BFL, we will utilize simple, easily distinguished categories for degree of coverage at each layer ranging from 0 (minimum cover) to 3 (maximum cover). At each site, we will score ground cover (0-3) and enter an estimate of percent dicots score shrub cover (0-3) and enter an estimate of percent evergreen shrubs score canopy cover (0-3) and enter an estimate of percent evergreens and note the tree species above. The shrub layer will be scored only below eye level. This level roughly corresponds with the top of the browse line when deer were present. We will compare present shrub layer scores with those in a similar drought year when deer were still a forces at BFL. Each team will walk along 3-4 of the ten permanent transects at BFL, taking a reading of canopy cover (0-3) at each of the numbered transect markers that occur at 20 m intervals. The cumulative data will include readings at approximately 140 sites across BFL. We will calibrate our subjective estimates of canopy cover using digital cameras and fish-eye lenses to record actual canopy cover and shrub layer density using Gap Light Analyzer (FRAZER 1999), a software package that can calculate the percent canopy openness in the hemisphere above each sample point. Make sure that you take the fish eye photo exactly where the estimate of canopy cover was taken. If a team member takes the photo after others made the visual estimates, a flag should be left as a reference for the photographer. To take the picture, the long axis of the camera should be oriented north south with the photographer’s right hand on the south side, i.e. you should face due east, then turn the camera toward the sky. This will ensure that the bottom of the picture points east. Make sure that the camera is on a full wide angle (no zoom) and with the flash suppressed. Those taking photos need to carry a compass. 12.4 Analyses 12.4.1 Calibrating canopy estimates Since most of our analyses rely on subjective measurements, it would be good to calibrate how well the subjective categories predict light measurements estimated by Gap Light Analyzer. Use linear regression on this class’s dataset, with subjective score as the predictor and percent openness as the response. Note that the structure of the data will almost certainly violate some of the assumptions of a linear regression test. We can still do this because this isn’t a hypothesis-driven analysis, but a prediction-driven one; provide the \\(R^2\\) and fit equation, but not the p-values. To run a regression in R, modify this code: regression = lm(y ~ x, data = your_data_set) # adjust this for your regression regression # this gives you the coefficients summary(regression) # This includes R2 values # Note that you should go with the &quot;Multiple R-squared,&quot; not &quot;Adjusted R-squared&quot; Create a figure for this analysis, including the data points and trend line. If you’re using Excel, please remember that the equation that appears after you add the trendline shouldn’t be included in the resulting graph (it belongs in the caption and main text). If you’re using ggplot in R, you can add a regression line to the graph by adding the following line to your figure code: geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;grey&quot;) # feel free to change color One other thing I’d recommend is spreading out the points on your x axis a little, since otherwise they will just be four vertical lines. In ggplot, you can do this by replacing geom_point with: geom_jitter(height = 0, width = .25) # changing width will spread the dots out more; just don&#39;t change height 12.4.2 Relationship between canopy and ground cover Create four contingency tables examining the ground &amp; shrub cover relationship; one for each level of canopy cover. Note that the cells of the tables should be a count (number of plots), not a relative proportion. Run chi-squared tests on each table. This is rather similar to what you did for the previous lab. Re-create these tables with the relative number of plots per canopy cover type for each ground/shrub combination. You need to visually present this information in some way; you could try making a graph of some sort, or you could color the cells of the table to indicate the strength of the proportion. Note that adding color information to a table would turn it into a figure, and it should be referred to as such. 12.4.3 Quantifying the spatial mosaic Use a map of BFL and number/color the canopy level at each point. Connect adjacent areas of the same number. Note whether any spatial patterns in cover vales can be associated with main habitat types based on past land use, substrate types, and history of natural disturbances. If you do this by hand, scan or photograph it and include it in the Canvas submission. 12.4.4 Historical comparison How are the current levels of shrub, canopy, and ground cover different from previous years? We will be comparing current data with fall 2004, when deer populations were high. For each cover type (canopy, shrub, and ground), make a contingency table comparing present cover levels vs. those in 2004 and run a chi-squared test. "],["Lab-ants.html", "Chapter 13 Ant Lab: Ant Community Ecology and the Effects of Invasive Fire Ants 13.1 Background 13.2 Questions and hypotheses 13.3 Methods 13.4 Analysis", " Chapter 13 Ant Lab: Ant Community Ecology and the Effects of Invasive Fire Ants 13.1 Background Ants are an important component of most terrestrial ecosystems both in terms of biomass and diversity. They are reliably present and easily sampled in most habitats. Ants have been selected as a focal baseline group for monitoring of biological diversity responses to global climate changes in the coming decades. See Antbase for available PDFs on specific aspects. Several of the authors have worked at BFL as students or post docs. Ant sampling at BFL started in the 1970s (Feener, 1978), a few years prior to the invasion of imported fire ants. BFL at the time had a diverse ant fauna of about 56 species, (as indicated on the list you are provided). Baits placed around the area in the mid 1970’s attracted a variety of ants throughout BFL. After the invasion of the red imported fire ant, Solenopsis invicta, in 1981, the ant and arthropod community changed rapidly, decreasing in diversity and abundance. The initial spread of S. invicta was carefully documented between 1983 and 1987 (Porter et al. 1988). In 1987, researchers at BFL sampled ants and other arthropods with baits, pitfalls and sifting leaf litter both inside and outside of invasion zones (Porter and Savignano, 1990). They found that ant species richness within the invasion zone was only 50% that of the un-invaded habitat (16:32). Overall ant abundances were much greater in infested areas (by 10-30 fold) and S. invicta workers accounted for 99% of the increase. Species diversity indices, which take both species numbers and relative abundance into account, decreased by an order of magnitude between non-infested and infested sites. Hook and Porter (1990) soon documented that the demise of harvester ants (Pogonomyrmex) was due to direct effects of S. invicta as it invaded BFL. Cheshire (1995) conducted a follow-up study along part of the quarry trail where Feener had conducted his 1978 study of leaf litter ants. The wooded area sampled in these two studies is not favored by S. invicta, although they are present there. Cheshire (1995) found 13 ant species where Feener earlier had recorded 17. In 1978, the native fire ant, S. geminata had been 2% of the 2509 ants collected by Feener. In 1995, the red imported fire ant was 55% of the 1986 ants collected in the same spot by Cheshire and the native fire ant was missing along with several other species. Overall, abundance and diversity of native ants decreased in 1995 but not as much as we had feared would be the case in the mid 1980’s. In 1999, Morrison (2002) conducted a replica of the Porter and Savignano study, using the same exact sites and methods. After 12 years there was evidence of recovery by the native ant community and a diminishing of the dominance of S. invicta seen early in the invasion. In fact, abundance and species richness of native ants were back to levels seen in non-invaded areas in 1987. BFL fire ant researchers believe that the drought of 1995-2001, contributed to the native ant resurgence against the red imported fire ant, and that the situation is now ideal for phorid flies, parasitoids of imported fire ants, and pathogens to impose negative impacts on imported fire ants, since the effects of these enemies are compounded by the presence of competing ants ready to fill the void. Remarkably, when last checked about 2005, the urban areas of Austin near BFL were still dominated by native ants, including native fire ants. S. invicta was rare to absent over an area of several square kilometers in the old neighborhoods near BFL (Plowes et al. 2007). In the last 6 years many old homes in the area have been torn down and new houses built. Sites were disturbed and horticultural plants introduced by landscapers. Such disturbance may have increased S. invicta in the area. A follow up study is overdue. Ant communities (like plants) are often associated with particular habitats and disturbance regimes. We know that BFL has undergone considerable succession in plant communities during the past 100 years, and these changes may play a role in ant community dynamics, as do periodic droughts. Tree mortality in the old quarry from the 2009-2012 droughts opened the ground level there to sunlight and higher temperatures. Such changes favor increases in S. invicta abundance. 13.2 Questions and hypotheses There are two primary topics we’ll be investigating in this lab: What are the habitat preferences of imported fire ants (Solenposis invicta), and do fire ants have an effect on ant diversity. How does the diversity and composition of ant communities differ across habitats (wooded or open) and disturbalnce levels (high and low)? 13.3 Methods You will be surveying ants in your acres, then identifying them in the lab. There is a key for BFL ants available on Canvas; additionally, you can find identification help on AntWeb (from the California Academy of Science) and Discover Life (from the University of Georgia and others). 13.3.1 Bait Survey You will create a 4 by 4 grid of baits (hot dog pieces), with bait sites at roughly 15 meter intervals. At each point, scuff the ground to clear a small area of 10x10 cm of bare soil (ants respond to small disturbances). Write the sample number on a small paper square &amp; on a flag; place the flag at the site. Record the GPS coordinates, to as high an accuracy as you can. If possible, record a few items in your acre that have a known position so that we can use them to correct for errors. 13.4 Analysis We’ll be doing examining habitat differences with a couple of contrasts with our various methods: Open (canopy cover 0 or 1) vs. Closed (canopy cover 2 or 3) canopies. Sparse (0/1) vs. dense (2/3) ground cover. Low vs. high disturbance Habitat types (Q/R/P) 13.4.1 S. invicta habitat preference Compare the presence/absense of S. invicta for each contrast. For each, create a contingency table and run a chi-squared test. The columns should be the different habitat conditions; the table should have two rows (fire ants present, fire ants absent), and the cell contents should be the number of baits that meet those conditions. You should also test if fire ant presence is affected by an interaction between canopy openness and disturbance. This should also be tested with a chi-square test, with the contingency table’s columns being the four combinations of openness and disturbance and the rows being the presence and absence of fire ants; the values in the contingency tables will be the number of sample points that meet the criteria. 13.4.2 Ant community differences We’ll be using four methods to estimate and compare diversity of ants in different habitats at BFL: Jaccard’s index of similarity, Cumulative curves of species, Rank abundance curves and Shannon’s index of diversity. You can read about these methods in the Ecology Laboratory Manual by G.W. Cox or any other ecology book. In general, you should use these methods to compare the above habitat characteristics. You don’t have to do all of them for each method (that would be excessive), but I’d recommend using them to explore the data and report on some contrasts that you find interesting. For everything but the Jaccard, you should also look at the entire dataset as a whole. 13.4.2.1 Jaccard’s index of similarity This index provides an estimation of how similar species composition is between two communities (e.g., two places or times). \\[J = \\frac{W}{A + B - W}\\] \\(A\\) and \\(B\\) are the richness (number of species present) of the two communities in question, and \\(W\\) is the number of species in common in both communities. \\(J\\) varies from 0 (nothing in common) to 1 (identical communities). You can also interpret \\(J\\) as the proportion of total species that are shared. For these analyses, you should treat the “community” as the habitat condition you’re testing. 13.4.2.2 Species Accumulation Curve These curves show the amount of time/effort spent sampling for species against the total number of species observed. They provide information about the actual and potential species richness of a community, as well as a sense of how well a place has been sampled. The details of how to calculate this are a bit complicated, and are explained in the attached R script. Plot each curve (for related curves, you should include them in the same figure). Does it appear that the habitat was fully sampled? Estimate the likely number of species in the habitat by extrapolating the curve. 13.4.2.3 Rank Abundance Curve Rank abundance curves compare the abundance of each species to the rank-order of that abundance. These give you a visual representation of species richness and species evenness (measure of comparative relative abundance of species). Species evenness is derived from the slope of the line that fits the graph. A steep drop-off indicates low evenness as the high ranking species have much higher abundances than the low ranking species. A more gradual slope indicates high evenness as the abundances of different species are similar. To create these, plot the number of ants found in each species with log10 scale on Y-axis. Organize the species along the x-axis from most to least abundant (See more in Cox pg 197). 13.4.2.4 Shannon Index This index estimates the diversity of a species in a single place, combining information about the richness and relative abundance. The Shannon index \\((H^\\prime)\\) is calculated as: \\[H^{\\prime} = -\\sum_{i=1}^n p_i \\ln(p_i)\\] where \\(p_i\\) is the relative abundance of species \\(i\\). The larger \\(H^{\\prime}\\), the higher the diversity. The exponential of the Shannon index is called the true Shannon diversity \\((D_H = \\exp(H^\\prime))\\); it can be interpreted as the number of species you’d expect in an equally diverse community that was perfectly even. "],["Lab-phorid.html", "Chapter 14 Phorid Lab: Parasitoid impacts on host foraging behavior with Phorid flies and fire ants 14.1 Background 14.2 Objectives 14.3 Methods 14.4 Analysis 14.5 Discussion 14.6 Some questions from previou semesters:", " Chapter 14 Phorid Lab: Parasitoid impacts on host foraging behavior with Phorid flies and fire ants 14.1 Background Although this course does not focus on behavioral ecology, this laboratory exposes you to one aspect of that field which directly relates to population and community ecology. We take advantage of ongoing research on fire ant biological control at Brackenridge Field Laboratory to develop this project for the course. 14.1.1 Fire ants and phorid flies The imported fire ant, Solenopsis invicta was introduced into the Southern US about 7 decades ago. Since that time, this insect has spread across the entire Southeastern US and in the last two decades has established in Arizona and California. It is now known that U.S. Gulf Coast populations of this ant are the source for recent global expansion (Ascunce et al. 2011). Ecologists believe that the lack of natural enemies in the introduced range is a major reason this species can increase its populations faster than native counterparts such as the native fire ants, S. geminata, S. xyloni, and other native ants. Candidates for controlling fire ant populations include tiny parasitoid flies called the ant-decapitating flies, of the family Phoridae. This family of &gt;20,000 species is generally characterized by scavengers and fungus feeders. However, a few genera focus on ants, and some (such as the genus Pseudacteon) specialize on a single species or a small species group of within a genus. In the late 1970’s, Don Feener, a graduate student working at BFL (now Professor at University of Utah) discovered that phorid fly females have an amazing effect on their host species as they attempt to inject eggs into worker ants (Feener, 1981). Although Feener studied ants in the genus Pheidole and not fire ants, the observation that food foraging in ants could be inhibited by the mere presence of a tiny fly immediately suggested that one reason for the imported fire ant’s success relative to the native Texas fire ant could be that it is free of such things as phorid fly attack in its introduced range. The native fire ants, S. geminata and S. xyloni, are attacked by several species of Pseudacteon phorids, which show no interest in S. invicta. With these facts in mind, Dr. Gilbert and his colleagues have been studying 16 species of Pseudacteon from Brazil and Argentina in the hopes of introducing one or more species for the control of S. invicta. One aspect of such studies involves the documentation of how these flies alter fire ant food gathering behavior in S. invicta, since it is thought that the “control” of fire ant populations may be via reducing food to offspring rather than via direct mortality (See Orr et al 1995, 1997). 14.1.2 Fire ants natural history Fire ant workers, like those of all ants, are sterile females who assist their queen (or queens, in the case of polygynous species or genotypes) in raising more workers or winged reproductive ants called alates. Fire ants are very effective competitors because they possess many sizes of workers and thus can compete well for many sizes of food particles. We term this attribute caste polymorphism. Most ants have one size of worker and are termed monomorphic. Note that “polygynous” in the context of ants refers to colonies with multiple queens, not to a polygamous form of mating. An ant colony that is well supplied with food will eventually reach a size at which it can “afford” to produce winged alates for a mating flight. The number of alates produced and the frequency with which a colony of a species can produce mating flights determines the rate at which that species increases its density in an area. Phorids are thought to reduce the reproductive rate of fire ant colonies through several related effects on food foraging ability: When phorids begin to attack, workers attempt to avoid attack by hiding under leaves or other cover or by staying in the nest (a.k.a., the “ecology of fear”). Since phorids prefer larger workers and fire ants appear to sense this, caste ratios may change once attacks are underway, thus reducing the numbers of larger workers available to defend or transport food. With either or both of these responses, less food will be taken to the mound than would occur in the absence of phorids. How will this decrease in food gathered due to parasite avoidance affect colony size and the ability of the colony to reproduce itself (i.e. start another colony)? 14.2 Objectives The goal of the exercise is to give you insight into the types of questions and approaches that define behavioral ecology. Measure the effects of attacking females of Pseudacteon obtusus phorids on the foraging activity of S. invicta at food items. As we observe foraging rate responses, we will take temperature data at each site using automated dataloggers (HOBOs). Observe the host specificity of Pseudacteon in an arenas with native and imported fire ants (This depends on availability of native ant colony). Since introduced phorids are currently emerging at BFL after recent rains we will place trays of S. geminata and S. invicta adjacent to one another in a shaded spot and observe differences in phorid response. 14.3 Methods 14.3.1 Phorid impact on fire ant foraging The basic set-up consists of white tiles or cards upon which we ant bait. Worker fire ants will recruit from a nearby colony and begin harvesting the food. Once fire ants have recruited and formed a stable foraging line, we will cover the bait with a clear plastic shell that will allow you to control the exposure of each foraging trail to phorid flies. This is necessary to contain flies and to exclude other species naturalized and present outdoors at BFL. This setup forms our “arenas.” Each group will monitor two arenas: experimental and control. Phorids will be introduced to experimental area once ant numbers have become stable for a five-minute interval. Paired control arenas will be identical but not contain phorids. The two arenas should be within about two to three meters of each other. If there are too many phorids arriving from the resident populations, we will actively remove them from controls and add to experimental arenas. A tiny species, P. curvatus, is currently present at BFL along with P. obtusus. A circle drawn on the tile or card around the bait is one good way to count foraging workers (number of ants crossing the line / unit time) but you can devise equally effective methods. The white tile or bait card helps the observer visualize the tiny, fast-flying phorids. It also helps if you can find a neat foraging trail so that most or all ants coming and going can be easily counted. On the previous day, Dr. Gilbert will choose likely sites and clear obstructing grass and weeds and to improve visibility of ants and flies. Baits will be placed out about 45 minutes prior to initiating the experiment. Hand counters and stop watches will be needed for these timed counts. Temperature, light, and humidity might vary considerably between sites. You will record temperatures near the baits with HOBO data loggers. Shade cloth will be used to reduce solar heating of covers exposed to full sun (because fire ants cease foraging at high body temperatures). These covers will be gently removed to make observations. Try to make conditions in the experimental and control as similar as possible. The effects of attacking female phorids on the foraging rates of S. invicta at food items will be assessed as follows: Once foraging trails seem well established, count ants for two minutes by counting the number of ants leaving with pieces of food (number crossing the circle or other landmark in the arena during a two-minute time frame) at the site assigned to your team. You’ll do this three times, with three-minute intervals between your counts; together, these will form your baseline data. After the third count, phorids will be released by Dr. Gilbert into the experimental arena. Watch closely for the first attack and reset the time to zero immediately after the first attack. Make five more two-minute counts at five-minute intervals after the first attack – (i.e., one at five minutes after the first attack, the next at ten minutes after the first attack, etc. There will be 3 minutes between counts). Partners should rotate between control and experimental sites so that each person has a chance to observe phorid attacks. Make sure that counts are made simultaneously in control and experimental arenas. 14.3.2 Using the HOBO MX2303 data logger For initial setup: Download the HOBOConnect app onto your phone Press the button on the logger to wake it up. In the app, press the “devices” tab at the bottom, then select the logger that matches your serial number. Tap the edit (pencil) button to configure the device. Edit the name to add your group name (be sure that the serial number is still there, though). Change the logging interval to 0 Minutes, 15 Seconds. Under “Stop Logging”, check “On Button Push” and save. For the two temperature channels, enter “Control” or “Experimental” under the Sensor/Channel name (depending on which arena the channel is measuring). Tap the save button at the bottom. To view the data that’s been collected, click the “Live Data” tab at the top. Exporting your data: From the device configuration, click the export button at the bottom (it’s the one that isn’t a pencil). Once the readout is complete, go back to the app’s main screen, then tap to the HOBO Files tab on the bottom. Tap the three dot menu in the upper right corner, then tap the export button (it has the arrow pointing up and right). Click “Export to CSV.” Upload the file to Canvas. One way to do this is to click “Share” in the app, then email the file to yourself &amp; upload it from there. In your methods section, be sure to identify the model of HOBO logger used (MX2303), manufacturer, and the interval at which the data were collected. For example, “We collected the temperature of each arena every 15 seconds with HOBO MX2303 data loggers (Onset Computer Corporation).” 14.4 Analysis 14.4.1 Effect of phorids on ant foraging Your first question is whether phorids flies affect the rate of foraging in S. invicta. The goal is to compare ant activity before and after the introduction of the phorid parasitoid. We’ll use the rate at which ants left tile as our measure of activity. If you inspect the data, you will likely find that different groups had different recruitment rates to start with. Accounting for this is one challenge of the analysis (this is a methodological choice that may be worth talking about in your discussion). One solution to the problem is to standardize your counts. Each count (per time step, group, and treatment) needs to be divided by some baseline value. Since you should have three baseline values per area, you could choose to either standardize by the average of all three or by the final baseline value. This can be done with pivot tables, Excel formulas, or through R. This will express your data as a proportion of original “leaving” rates. This standardization will allow you to compare “leaving” rates between controls and experimentals across colonies. There are a number of ways to test this statistically: You can do five two-sample t-tests, comparing the proportion of ants leaving at each time point. You could do an analysis of covariance (ANCOVA), which tests whether the regression between time and proportion of ants differs between the two treatments. (Details on this below). You can calculate the difference between the standardized leaving rates of each paired control and experimental arena. This would essentially be the effect of phorid flies. You can then use a regression to see if this changes over time. Create a figure comparing changes in activity over time between the groups. Note that your figure should match up with your analysis: the t-test tests option treat each time point as a discrete value, while the ANCOVA and regression options treat time continuously. 14.4.1.1 A note on running an ANCOVA An ANCOVA is essentially a regression that also allows the slope and/or intercept of the fit line to vary between levels of a categorical variable. To run one in R, you can use the lm() function with a formula like ant_activity ~ time * treatment. The * indicates we want to look at the effects of time, the treatment (control vs. experimental), and the interaction of the two (i.e., if change over time has the same rate for both treatment groups). The summary of the ANCOVA will include terms for all three of these (the term that is something like time:treatmentExperimental is the interaction). If the interaction is small and not statistically significant, that means the two treatments change over time at the same rate. In this case, the treatmentExperimental effect is the difference in the average ant_activity value between the experimental and control groups. If the interaction is significant, then you essentially have two entirely separate regressions for the two treatments. The intercept and slope for the control group are simply given by the (Intercept) and time terms. The experimental equations can be found by adding treatmentExperimental and time:treatmentExperimental to (Intercept) and time, respectively. Alternatively, you can just fit separate simple regression on time for only the data from each group and use their equations; they should be almost identical. I have no idea how to do an ANCOVA in Excel, and I think it’s generally a bad idea to try. 14.4.2 Effects of environmental conditions Do temperature or relative humidity affect foraging behavior? Do these effects change based on the presence of phorid flies? Create a scatter plot with temperature on the x-axis and number of ants leaving on the y-axis; separate control and experimental data into different panels. Repeat this with Relative Humidity instead of temperature. For all four of these, run a linear regression; be sure to include the regression line in the plots and report the appropriate statistics 14.5 Discussion Your discussion should address the following points &amp; questions: Interpret your results of your analyses. How might a decrease in food gathered due to parasite avoidance affect colony size and the ability of the colony to reproduce itself (i.e. start another colony)? Phorid flies are parasitoids of individual worker ants (i.e., they kill the host individual by feeding internally in the host). However, from a population ecology perspective they are better viewed as parasites of ant colonies. Why? What are some problems with the experimental design for this week’s lab? How might having the study be non-blind affect the results? How would you improve these experiments? 14.6 Some questions from previou semesters: I’ve been looking at the data and trying to begin the Analysis, but I don’t understand what you mean about standardizing counts. What number would I divide by and would it be the same number for all groups, or do I have to analyze the data of each group individually and compare it? Each colony (team/group * treatment combo) should be standardized by a different number, which represents the number of ants present before the treatment began. There are a number of ways to do this, but I would recommend either standardizing by the colony’s number at baseline 3 (i.e., right before fly introduction), or by the average count for all three baselines at that colony. Once you have done this, you can then compare the relative counts across different colonies. Once the leaving rate values are calculated after dividing by baseline values, what are the units? I’m a little confused. Is it ants/time step, ants/second, ants/minute? I know each time step is 2 minutes long, so saying 1.14 ants/time step seems incorrect. Is there something I’m totally missing? Also I noticed that some of the data is very asymmetrical, so would you rather us talk about its median/range when describing asymmetrical center and spread (in the results), or would you still prefer mean and standard deviation? It’s a relative value, so it would be unitless. If you decide to avoid mean/sd (which is your choice), I would recommend inter-quartile range over range, since it’s a more robust measure. FRAZER, GW. 1999. “Gap Light Analyzer (GLA), Version 2.0 Imaging Software to Xtract Canopy Structure and Gap Light Transmission Indices from True-Colour Fisheye Photographs.” Users Manual and Program Documentation. https://ci.nii.ac.jp/naid/10011246415/. Lertzman, Kenneth P., Glenn D. Sutherland, Alex Inselberg, and Sari C. Saunders. 1996. “Canopy Gaps and the Landscape Mosaic in a Coastal Temperate Rain Forest.” Ecology 77 (4): 1254–70. https://doi.org/10.2307/2265594. MacArthur, Robert H., and John W. MacArthur. 1961. “On Bird Species Diversity.” Ecology 42 (3): 594–98. https://doi.org/10.2307/1932254. "]]
