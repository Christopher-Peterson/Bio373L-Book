[
["index.html", "Bio 373L Survival Guide Preface", " Bio 373L Survival Guide Christopher R. Peterson 2020-09-15 Preface This book contains advice for students in the University of Texas at Austin's Field Ecology course. It will be updated throughout the semester. The first three chapters contain general guidelines for writing lab reports. The subsequent chapters cover the details of specific field problems. The appendices are an extensive tutorial on working with and analyzing data using R. "],
["structure.html", "Chapter 1 Writing Lab Reports: Structure 1.1 Structure Overview 1.2 Abstract 1.3 Introduction 1.4 Methods 1.5 Results 1.6 Discussion 1.7 Literature Cited 1.8 Common Mistakes for particular sections", " Chapter 1 Writing Lab Reports: Structure 1.1 Structure Overview The main goal of scientific writing is to effectively communicate complicated concepts. Scientific manuscripts tend to follow a traditional structure that is intended to help an experienced reader navigate these concepts. Each section should answer a question: Abstract: Why should I read this? Introduction: Why did you do this? Methods: What did you do and where/with what did you do it? Results: What did you find? Discussion: What does it mean and why does it matter? Literature Cited: Doesn't really answer a question, but this is where you list the citations you used. Greater detail is provided in the following sections. 1.2 Abstract The abstract is a one paragraph summary that functions as an advertisement/elevator pitch for the rest of the paper. A reader should get a general idea about what you did and be interested in reading the rest of the paper. If it's more than 350 words, you need to shorten it. While this section should cover the intro, methods, results, and discussion, you shouldn't re-use any language from those sections here. Instead, write a sentence or two from each that hits the important points without going into all of the details. Don’t cite any figures, tables, or other literature in here. Generally, this section is written last. 1.3 Introduction The introduction section sets the stage for the work you are about to describe and should tell your reader why your research is interesting. You should begin by describing the broader ecological context that your research fits into, and review the relevant literature. It is a good idea to start generally and narrow the focus to the specific project you did. For example, let's say you're writing a paper about the temperature tolerance of the three-eyed sandslider (Trioptis cerastes), a fictional snake species we're going to pretend is native to southwestern deserts. A reasonable introduction could discuss the following: Climate change in general. Severity and effects of climate change in deserts. Effects of higher temperature on ectotherm behavior. How you're investigating temperature tolerance with three-eyed sandslider. Alternatively, you could introduce the same paper in a completely different context: The evolution of animal activity budgets. Effects of temperature on foraging and reproductive behavior in ectotherms. How you're investigating temperature tolerance with three-eyed sandslider. There are many more potential ways to write this paper. The take home message is to set your specific project within the bigger picture of a large-scale concept, phenomenon, or issue. The introduction should contain at least two paragraphs (with a minimum of three sentences each). At the end of the section, you should explicitly state your hypotheses and predictions. For example, going back to the temperature tolerance experiment, I could write, ‘Thus, I hypothesize that Trioptis cerastes will have a higher temperature tolerance in the summer than in the winter due to acclimation to higher temperatures in the warmer months”. You should cite at least two peer-reviewed papers in this section. Please ensure these papers are actually relevant to what you're talking about and aren't just tacked on to meet this requirement. 1.4 Methods This section includes detailed information on your experimental setup, data collection procedures, and the statistical analyses you used. If your project focused on specific species or sites (e.g., BFL), you should start by describing these. It is often useful to organize the methods section into sub-sections. For example, for the temperature tolerance example could have the following sub-sections: Study Region Study Organism Housing Conditions Experimental Design Statistical Analyses You should always include a description of all of the statistical methods you used in the methods section. This includes the test(s) performed, the predictor (independent) and response (dependent) variables, the alpha level, and the program used. Write each sub-section in chronological order. This and the results section are often the easiest to write first, so it's best to start with these two middle sections, and then work on the introduction and discussion. 1.5 Results This is where you describe your observations and the results of any analyses. Make sure you do not include new methods (including new statistical analyses) in this section; these belong in the previous section. The most important results should be presented as figures or tables. However, they must also be described in the paragraph. It is a good idea to organize this section into sub-sections as well, following the same system you used in the methods (some sub-sections from the methods may not need to be used in the results, but follow the organization as closely as possible). 1.5.1 Reporting statistics In general, you should begin by presenting the relevant summary statistics (such as means for measured data and frequencies for categorical data). For example, ‘The mean temperature tolerance was \\(39.2 \\pm 0.45 ºC\\) for males and \\(37.1 \\pm 0.25 ºC\\) for females.’ Notice that the temperature has units (degrees Celsius) and that I put the standard deviation after the mean. This is good practice when reporting means. When reporting statistical test results, state what they mean in words first, and then follow the statement with a parenthetical phrase containing the statistics. For example, ‘Males tolerated significantly higher temperatures than females (\\(t = 1.96\\), \\(df = 6\\), \\(p = 0.04\\))’. Notice that I included the computed t-statistic, the degrees of freedom and the p-value. All these should be reported when reporting t-test results. Note also that I indicated the direction of the difference, as well as its significance. Here is another example: ‘The number of escape behaviors performed increased significantly at high temperatures for all snakes (\\(\\chi^2 = 8.43\\), \\(df = 2\\), \\(p = 0.001\\))’. This is an example of how you would report chi-square test results. Again, the results are stated in words that have biological meaning and are followed by the calculated test statistic, the degrees of freedom and the p-value in parentheses. If your statistical analyses did not find a significant difference, you still need to report this. For example: ‘Although temperature tolerance was slightly higher for males than females, this difference was not statistically significant (\\(t = 0.657\\), \\(df = 6\\), \\(p = 0.14\\)).’ Do not use the word “insignificant” in this context. Be sure to state your results in a biologically meaningful manner. A common mistake is to write out the results in statistical terminology without any reference to their biological meaning. For example: ‘A t-test resulted in a p-value of 0.03 meaning that we can reject the null hypothesis and accept the alternative.’ While this is a correct statistical interpretation of the calculated p-value, it tells the reader nothing about the trees or ants or mushrooms that you were studying. Do not write up your results like this; it's unpleasant to read and you're just going to have to fix it in revisions. 1.5.2 Do not interpret your data here Do not interpret your data in the results. That belongs in the discussion. Do not consider explanations for your data in the results. That belongs in the discussion. Do not consider how your data relates to your hypothesis in the results. That belongs in the discussion. This is probably the most common mistake I've encountered in grading student lab reports. 1.6 Discussion The discussion is where you should interpret your data and draw conclusions by comparing your data to what is known from the published literature. The organization of this section is a mirror-image of the introduction in terms of its organization: start narrowly, by discussing how your results relate to your original hypotheses and questions. Follow it up with a wider discussion of how these results fit into the broad concept with which you introduced the paper. This should not be a restatement of what you wrote in the introduction or in the results, but should be an exploration of the meaning of all those numbers you just crunched and what they might signify. Be careful not to make unfounded statements. There are often many potential explanations for obtaining a particular result. One may seem more likely than the others, but this does not exclude the other explanations from being true if you haven't actually tested them. A good way to handle this is to mention the multiple alternative interpretations, express support for the one you think is most likely and explain why, then suggest a future experiment that could be done to test whether or not that is correct. An example: ‘Temperature tolerance was lower for females than for males. This could be due to the relative size of the two sexes. Females are the smaller sex, meaning that they would heat up faster than males due to a greater surface area:volume ratio (Loblaw and Bluth, 2005). Alternatively, the males could have a higher tolerance because their overall activity levels were elevated in the experimental enclosures. This may have caused them to begin with a higher internal temperature that acclimatized them to higher temperatures to start; however, this seems unlikely. Future work could address this by taking internal temperature readings before and after temperature tolerance trials.’ As in the introduction, you should cite at least two peer-reviewed papers in this section in a way that isn't obviously shoehorned in. 1.7 Literature Cited You must use a minimum of four primary literature sources in your report, with at least two sources in both the introduction and discussion (although some sources are suitable to use in both). Use the sources to provide background, to aid in justification of performing the project, support for your interpretation of results, etc. In some cases, you should also cite a reference in the methods section (e.g., for a non-standard data collection technique or to provide information on a study site/species). Do not cite papers in results. All thoughts, ideas, concepts, etc., that you didn't think up on your own must be cited in the text (failure to do this is considered plagiarism). If you want to cite general facts or information from a study, it's generally best to present those facts with a parenthetical citation. E.g., &quot;The point-quarter technique is an effective and reliable way to estimate canopy cover in the field (Smith et al., 2018).&quot; Sometimes, you may want to discuss the specific details of a previous paper. Generally, it's a bad idea to start a sentence with &quot;In one study, ... (Hernandez et al., 2007). Instead, cite them directly: &quot;Hernandez et al. (2007) discovered similar signs of succession in eastern hardwood forests...&quot;. If you have multiple sentences all drawn from the same source, just put the citation once at the end of the last of those sentences. Please note that while there is a minimum of four primary literature sources, you are encouraged to add more. Bringing in information from extra papers can really strengthen your introduction/discussion. There will be a weekly thread on Canvas to share literature relevant to the lab report; you are expected to contribute two citations to it each week. Please note that your sources need to be relevant to your lab report at more than just a surface level. For example, if your lab report is on the distribution of cottonwoods at BFL, a paper about the cottonwood’s genomic structure is probably not going to be relevant. 1.8 Common Mistakes for particular sections 1.8.1 Introduction and Discussion Null hypotheses are statistical tools used for certain tests (e.g., a null hypothesis for a chi-squared test would be that the groups are independent, or that there is no difference in the species proportions between the two age classes). These don't belong in the introduction or discussion. For these sections, you should present your biological hypotheses (e.g., &quot;BFL is undergoing succession&quot;). It is usually a good idea to include a concrete prediction of these hypotheses in the introduction as well (e.g., &quot;BFL is undergoing succession, which will be indicated by a difference in the relative abundances of canopy and sapling trees&quot;). 1.8.2 Results Don't cite papers in the results. You are presenting your results, not somebody else's. If you want to do this, it's probably something that should be in the discussion. Tables are best for highly structured data. If there isn't much data to present, the data can usually just be presented in the text of the results. If there's a lot of data, it is worth considering if a figure would be better. "],
["style.html", "Chapter 2 Writing Lab Reports: Style 2.1 Be Concise 2.2 Sentence Structure 2.3 Passive Voice 2.4 Word Choice 2.5 Scientific and Common Names 2.6 Other Grammar 2.7 Commonly Confused Definitions 2.8 Significant Digits 2.9 Tenses", " Chapter 2 Writing Lab Reports: Style It's easy to write a scientific report that confuses or bores the audience. Developing a style that keeps the reader following along can be a challenge, but it is a necessary one. This chapter contains a number of stylistic suggestions that can improve your lab reports. There isn't 'one true style' for scientific writing, but I've found that these guidelines can help when you're starting out. 2.1 Be Concise Parsimony is often held up as an ideal in science; if the evidence equally supports two explanations, we tend to prefer the simpler one. The same applies to scientific writing. When grading previous student lab reports, I’ve noted a bad tendency to over-explain every single detail (particularly in the methods section). Avoid providing information that is unnecessary to understand the project, and don't over-describe straightforward tasks. If you have a long repetitive section, think of a way to express the same information in a shorter space. Here's an example from a methods section that needs to be trimmed: &quot;We created imaginary lines passing through each sample point that were parallel and perpendicular to the transect and used these lines to create four quadrants. One member of our group would carefully pace towards the closest canopy tree in each quadrant. This was repeated by the same group member for each sapling tree. Later, we converted our pace counts into meters by measuring the number of paces that group member took to walk ten meters. A different group member measured the diameter at breast height (DBH) of each canopy tree by holding up a ruler to the side of the tree. The third group member recorded the data.&quot; The important information could be condensed into this: &quot;We divided the area around each point into four quadrants, which were parallel and perpendicular to the transect. For each quadrant, we estimated the distance to the nearest canopy and sapling trees and recorded the diameter at breast height (DBH) of the canopy tree.&quot; The same details apply for describing calculations or analyses. For standard or widely used procedures (such as a chi-squared test, or calculating relative abundance), you do not need to provide the formula that you used. In general, focus on what you did: &quot;We used a chi-squared test to determine whether the proportions of the five most abundant species differed between canopy and sapling trees.&quot; not the exact procedures you used to do it &quot;We created a contingency table in Excel using pivot tables by ..., then calculated the expected values by ... From this we calculated the chi-square test statistic with the formula..., determined the degrees of freedom from ..., and calculated the p-value with the Excel function...&quot;. A more specialized or non-standard calculation may need to be explained (&quot;The density at a point was estimated as \\(N / \\text{sum}(x^2)\\), where N was the number of quadrants with trees and x is the distance to the tree.&quot;), but should also not be over-explained. The same applies to the results. If you did three similar analyses to different data sets, you should try to describe the outcomes in parallel. Instead of doing this: &quot;Activity significantly increased with temperature in sample 1 (r = ..., t = ..., p = ...; Figure 1). ... Activity significantly increased with temperature in sample 2 (r = ..., t = ..., p = ...; Figure 2) ... Activity did not increase significantly in sample 3 (r = ..., t = ..., p = ...; Figure 3).&quot; You should consolidate: &quot;Activity significantly increased with temperature in sample 1 (r = ..., t = ..., p = ...; Figure 1A) and sample 2 (r = ..., t = ..., p = ...; Figure 1B), but not in sample 3 (r = ..., t = ..., p = ...; Figure 1C).&quot; Similar advice applies to figures. 2.2 Sentence Structure Your writing should flow. When moving between topics (or sub-topics), it is helpful to include transitional elements (words, phrases, or sometimes entire sentences) to help the reader follow your train of logic. This doesn't mean that you should start every few sentences in the Methods section with &quot;Then, we [did something] ...&quot;. Some good words and phrases to use include &quot;Following ___,&quot; &quot;Furthermore,&quot; &quot;However,&quot; &quot;Alternatively,&quot; and &quot;Yet,&quot; etc. Note that transitions aren't necessary when you are starting a new section (e.g., Methods) or labeled sub-section. Each sentence should serve a purpose (in terms of communicating information). If two or more sentences are doing the same job, try to combine them (or delete one). Conversely, sentences that are doing too much should be split. Avoid garden-path sentences and lengthy sentences that require multiple reads to understand. 2.3 Passive Voice While there are circumstances in which passive voice is useful, it is often misused in scientific writing. Many students feel that passive voice conveys a sense of objectivity. In many cases, it just obscures and adds unnecessary wordiness. This is particularly common in methods and results sections. You (in either the singular or plural sense) performed the observations or experiment; you did the calculations and analysis. You should take credit for it. If you are worried about starting every sentence with I/we, there are other ways to restructure your writing. For the record, I am not banning the use of passive voice. It can be effectively used alongside active voice when appropriate. However, I'd recommend taking a look at your passive sentences and considering if active voice would make them more straightforward. 2.4 Word Choice It's tempting to use longer, more technical sounding words when writing a scientific paper. This tends to make papers harder to read with no benefit. The same is doubly true for awkward multi-word phrases that can be replaced with one, simple word. Two common offenders: Utilize: In almost every case, &quot;use&quot; is the better choice. &quot;Utilize&quot; is really only applicable for situations in which the object being used was not designed for the task to which it is being put. Even in that situation, &quot;use&quot; is still preferable. There are a few minor areas of biology where &quot;utilize&quot; is correct, but for now, stick to &quot;use.&quot; Approximately: use &quot;about.&quot; 2.5 Scientific and Common Names Latin binomials should be italicized, with genus capitalized and specific epithet in lowercase (e.g., Ulmus crassifolia). Only write the full scientific name the first time it appears in a section; afterwards, you can abbreviate the genus (e.g., U. crassifolia). At that point, stick to the abbreviation; don't switch back and forth. Exception: You should never start a sentence with the abbreviated form. Don’t capitalize common names except for proper nouns e.g., American elm, cedar elm, Ashe's juniper, sugar hackberry. The first time a species is mentioned, its scientific name should be given. If after that you want to just use the common name, that is fine, as long as you also gave the common name the first time. E.g., first time – ‘…..cedar elm (Ulmus crassifolia) was found in all three habitats…..’ Later ‘….the prevalence of cedar elm could be due to….’ OR ‘….the prevalence of U. crassifolia could be due to…. 2.6 Other Grammar Put a comma after an introductory prepositional phrase. E.g., ‘In the pasture habitat, cedar elm was...’ or ‘During the most recent drought, laurel cherry has...’ I generally prefer Oxford commas. While you aren’t required to use them, be consistent. Please only capitalize proper nouns, acronyms, and the appropriate parts of scientific names. 2.7 Commonly Confused Definitions Population and Community: A population is a collection of individuals of the same species in a particular geographic area. E.g., all the cedar elm individuals at BFL A community is a collection of individuals of different species found in a particular geographic area. E.g., all the trees found at BFL Random and Haphazard Truly random points would be pre-selected in the lab before heading outside using a random number generator and using those randomly selected numbers as our coordinates. Haphazardly selected points follow the colloquial definition of 'random.' It's sort of like the scientific vs. common usage of the word &quot;theory.&quot; Affect and effect While there are nuances and exceptions, affect is generally a verb and effect is usually noun. 2.8 Significant Digits We generally aren't using high-precision instruments. As such, you should round numbers with a large number of decimal places to an appropriate extent (Note that ecologists usually don't follow significant figures rules quite as strictly as chemists and physicists). Generally, p-values should be rounded to four digits (and noted as &lt; 0.0001 if they're smaller than that), while test-statistics should probably have no more than two decimal places. For everything else, use your judgment. 2.9 Tenses Make sure to use the appropriate tense in each part of the report. If you're reporting what you did (e.g. in the Methods) or what someone did in another study (e.g. in the Introduction or Discussion) then use the past tense. Also use the past tense in the Results, because the results were recorded/found in the past. However, when discussing context and theory currently held to be true (in the Introduction and Discussion), make sure to use the present tense. Future tense will typically only be used when suggesting a potential future follow-up study/studies, usually in a small section at the end of the Discussion. "],
["figures.html", "Chapter 3 Figures and Tables 3.1 Captions 3.2 Figures 3.3 Some Example Figures 3.4 Tables", " Chapter 3 Figures and Tables Good figures are one of the most important parts of a manuscript. When learning to write scientific papers, some might view figures as an afterthought. This is a mistake. The figure should tell a fairly complete story. Combined with its caption, the reader should be able to look at the figure immediately after reading the abstract and have a general sense of what's going on. Tables are also an important part of a paper's results, but good figures are usually easier to interpret by the reader. 3.1 Captions Figures and tables require captions that explain what they represent. Captions should be below figures and above captions. The first &quot;sentence&quot; of a caption shouldn't actually be a sentence; it's more of a description. See the various examples in this chapter for more details. The caption should help the figure or table stand alone from everything else. If there are abbreviations or acronyms in the figure, they should be defined in the caption. If your figure is related to a statistical test, you should present the results of the test in the figure caption. If there's a line of best fit in a scatterplot figure, this means that a linear regression was performed behind the scenes; you should report the details. Note that figures in your manuscript should not have titles. This information belongs in the caption. 3.2 Figures Make sure the caption (and legend, if present) gives enough information that the reader can understand exactly what the figure/table represents without having to look at the text. DO refer to all tables/figures in the body of the text, and include them in order (i.e. the first table/figure the reader comes across should be called table 1/figure 1 and should be the first one referred to in the text). Note that in this chapter, the figures are numbered 3.1, 3.2, etc; this is appropriate for a multi-chapter book, but not for a paper/article/manuscript. Don't use decimals. Figures should communicate your results, not just present/summarize your data. A good figure tells a story. If there is a trend or pattern, it should be designed to emphasize it. 3.2.1 Specific Figure Guidelines Figure design is communication, so you want to make the result/message as obvious as you can. The longer a reader has to stare at your figure before &quot;getting it,&quot; the more likely they are to get bored or stop caring. Avoid large amounts of empty white space. For categorical data, you should remove categories that have no data unless their absence is somehow important and interesting. For example, if you are surveying trees and a species is not observed, there's no reason for it to be in the figure. Is your figure emphasizing what it should? If you're contrasting two groups, are they clearly contrasted? Could re-ordering the groups improve the contrast? If you're comparing groups of frequencies, you should order them from highest to lowest frequency. If you are trying to show a trend, is it being adequately emphasized? Please note that this doesn't mean cheating, or changing the data. The axes and legends should be clear. Often, the default axis or legend names will be the label of a specific cell or column. You can change these defaults. Consider how your figure will look to other people. How will it look if printed from a black and white printer? Hint: the default blue and orange colors in Excel are indistinguishable in gray scale; the same is true for the default ggplot2 palette in R. How would it look to someone with color blindness? -If using R, the Viridis color scales work nicely for this. Please remember that you should be writing your lab reports as if the reader (i.e., me) didn't know exactly what you did. 3.2.2 Be Concise If you have multiple figures that conceptually belong together (e.g., the same measurements taken in three years), you should turn them into a single multi-panel figure. Label your the panels with letters in the upper left corner; the caption should explain how the panels are different. 3.3 Some Example Figures 3.3.1 General Formatting Figure 3.1 is poorly formatted: The colors are hard to distinguish when printed and black and white; The axis and legend text are showing the default labels instead of informative values; There is a lot of white space, partially due to a bad y axis scale; The equation is in the figure instead of the caption; The caption is vague and uninformative; There is an unnecessary title; There are grid lines; Figure 3.1: Body mass (X variable) vs flipper length (Y variable). The regression is significant (\\(R^2 = 0.76\\); \\(p&lt;0.0001\\)). Figure 3.2 contains the same data, but has been reformatted to address these issues. Note the use of units in the axis labels, the formatting of scientific species names, the positioning of the legend to minimize whitespace, and the lack of a title and gridlines. This is also an example of how to plot data with a continuous response and a combination of continuous and categorical predictors. Figure 3.2: Association between body mass and flipper length in three species of penguin. Flipper length increases with body mass ((Flipper Length) = 13.7 + 1.5*(Body Mass); \\(R^2 = 0.76\\); \\(p&lt;0.0001\\)). Figure 3.3 is an example of a multi-panel figure; in the text, you should refer to parts of it as Figure 3.3A, 3.3B, etc. Figure 3.3: Association between bill length and bill depth for three species of penguins. The association is significant and different among species ((Bill Depth) = 10.6 + 0.2*(Bill Length) for Adelie, 5.5 + 0.2*(Bill Length) for Gentoo, and 8.7 + 0.2*(Bill Length) for Chinstrap; \\(R^2 = 0.77\\); \\(p_{\\text{species}} &lt; 0.0001\\); \\(p_{\\text{length}} &lt; 0.0001\\);) 3.3.2 Continuous response, categorical predictors There are a number of options for representing continuous data grouped into multiple categories. You should avoid &quot;dynamite&quot; plots (Figure 3.4), which use a bar with error lines to represent a mean and standard error; these figures use a lot of space to provide very little information. A better option is to use box plots (Figure 3.5), which show the median, quartiles, range, and outliers of each group. Equivalently, you could use a group of histograms (Figure 3.6). A particularly effective way to visualize this type of dataset shows the distribution of the data and the summary statistics (Figure 3.7). Figure 3.4: Mean body mass for three species of penguin, with standard errors. Body mass differs significantly among species \\((p &lt; 0.0001)\\). Figure 3.5: Distribution of body mass for three species of penguin. Body mass differs significantly among species \\((p &lt; 0.0001)\\). Figure 3.6: Distribution of body mass for three species of penguin. Body mass differs significantly among species \\((p &lt; 0.0001)\\). Figure 3.7: Distribution of body mass for three species of penguin, with mean and standard errors in red. Body mass differs significantly among species \\((p &lt; 0.0001)\\). 3.3.3 Categorical, count, or frequency responses These sorts of data usually involve examining how counts or frequencies differ among groups; they're often associated with \\(\\chi^2\\) tests. Generally, it's best to represent these sorts of data with bar graphs (avoid pie charts). When making a bar graph, it's a good idea to arrange your data to emphasize any trends. The species in Figure 3.8 are organized alphabetically, which obscures any trend. A better option is to organize by decreasing frequency of either total counts (like in Figure 3.9) or of one of the groups (Figure 3.10). These make it easier to detect patterns. Figure 3.8: Number of Anolis captured from canopy and trunk perches. Figure 3.9: Number of Anolis captured from canopy and trunk perches. Figure 3.10: Number of Anolis captured from canopy and trunk perches. An important consideration is whether to represent your data with counts or proportions (AKA frequencies -- vary from 0 to 1). There are pros and cons to both approaches, but frequencies are usually better if the number of observations differs among your groups (compare Figure 3.11 with Figure 3.10). Be careful when calculating frequencies, because you may inadvertently end up making a graph that isn't answering the question you're trying to ask. For example, Figure 3.11 shows how anole frequencies differ between perch types, but Figure 3.12 shows the frequency at which each species occupies the two perches. Figure 3.11: Frequency of Anolis species captured from canopy and trunk perches. Figure 3.12: Perch frequency for 9 species of Anolis. If there is some aspect of your data that you'd like to really emphasize, it can help to get more creative with your figures. For example, the most visually striking parts of Figure 3.13 are the colored sections of the bars, which correspond to the direction and magnitude of the difference between perches for each species. Do note that making more complicated figures may require extra explanation in the caption. Figure 3.13: Number of Anolis found at each perch position. The white bar indicates the count at the less frequent perch, the total height is the count at the more frequent perch, color indicates which perch the species was more common at, and the size of the colored regions indicates the difference between perches. The R code used to generate all of the figures in this chapter can be found here (along with some annotations). I've tried to explain what most of the components of each plot do, though I'd recommend learning some basic ggplot2 first. 3.4 Tables Tables are an effective addition to a manuscript when you have a lot of data in the text and want to present it to the reader in an organized fashion. They are particularly helpful when you have a lot of different kinds of data that would be hard to plot together. For example, see Table 3.1. Tables are best for highly structured data. If there isn't much data to present, the data can usually just be presented in the text of the results. If there's a lot of data, it is worth considering if a figure would be better. Table 3.1: Standard length of three populations of rainbow trout (Oncorhynchus mykiss) in Southern Appalachian streams. Group A was collected from the New River, group B from the Watauga River and group C from Winkler Creek. Group N Mean Std. Dev. Min. Max. A 10 35.33 3.53 30.74 37.02 B 15 42.61 4.62 36.36 49.17 C 12 22.00 2.97 17.99 26.38 "],
["lab1.html", "Chapter 4 Lab 1: Succession 4.1 Introduction to the lab 4.2 Materials and Methods 4.3 Analysis to perform 4.4 Discussion 4.5 General Comments (Post-Review)", " Chapter 4 Lab 1: Succession 4.1 Introduction to the lab Several habitat types can be discerned during a walk through BFL, each representing the integration of biotic and environmental factors with disturbance history. Here we look at species composition and age structure of trees that characterize some of these habitats. The relative abundance of different size classes of various tree species in a forest can provide clues about the history and future status of those species in that forest. For example, even if a tree species is abundant, yet represented only by large, older individuals, it is likely that the requirements for seed production or seedling establishment in the area have not been present in recent times. In order to predict the future status of that tree species in a given area we would need to find out about its requirements for regeneration and determine the likelihood that such conditions will be repeated during specified time periods. For example, for a species that requires a fire to germinate and establish, we would need to predict when fires are likely. In contrast, a tree species represented by a large population of saplings (presumed from their size) must have recently enjoyed favorable conditions for reproduction and establishment. Will such a species therefore dominate a future forest on the site? Possibly, but this may be difficult to answer since factors like disease, herbivory, fire, and/or shading by faster growing competitors may affect the survivorship of this cohort over time. Studying the size or age structure of a population helps ecologists make such projections. (Note that we generally assume that big trees are older than smaller individuals of the same species, but keep in mind that individuals of the same size may differ in age and vice versa. Local variation in microclimate edaphic factors (having to do with the soil) and light environment may result in rather different trajectories of growth for identical seedlings germinating the same year.) The goal of this project is to acquaint you with some of the kinds of data ecologists collect in attempting to answer questions about population trends. This exercise will also expose you to the always-messy issue of how to collect field data, and to give you insight and experience in statistical analyses appropriate for testing hypotheses about differences between species within different habitats in the age/size structure of trees. We will observe and quantify the distribution, abundance and size structure of dominant tree species at BFL. However, in collecting data to describe densities and size structures of these species at BFL, we are in position to test whether species have responded differently to major variations in the habitat at BFL. Once we have collected data on the trees with respect to variations in habitat at BFL, the patterns observed may stimulate additional questions and hypotheses. 4.2 Materials and Methods 4.2.1 BFL habitat regions To collect data we will establish transects in three areas of interest: the lower river terrace, the old pastures (experimental plots) and the quarry zone (see figure ?? for a map). Figure 4.1: Habitat map of BFL; for the purposes of this lab, the river terrace corresponds to the pecan terrace and flood deposited terrace (near the bottom), the old pasture is the central area, and the old quarry is near the top. 4.2.2 Data Collection Given the brief time allowed by the class period, we don’t count absolute numbers, but instead use sampling techniques for describing tree populations and habitats. We will use the Point-Quarter Technique to collect data (Cox p. 66). The beauty of this method is that it allows us to quickly estimate the density of selected species in the community while gathering information on their relative abundances. Each team will perform a survey in each of 3 apparently distinctive habitats. In each habitat, each team will establish 3 sample points which are randomly determined along a transect line. Transect lines will be set by the instructors. Note: Areas recently cleared or plowed will be excluded. Each sample point is to be temporarily marked with a flag (do not leave any flags behind!!). The 3 sample points along each transect represent the center of four quadrants with sides along and perpendicular to the transect line. In each quadrant, you will determine the nearest canopy tree and sapling to the center point. Canopy trees are defined as having a crown that is exposed directly to sunlight and forms part of the overhead canopy. Saplings occur under the crown of canopy and are assumed to be potential canopy replacements when the canopy tree dies. Data to collect from each point: Location (with GPS) Species of nearest canopy trees &amp; saplings Distance of these trees from the center point Diameter at breast height (dbh) of canopy trees Note signs of drought stress (leaves are wilted or dead/brown) 4.3 Analysis to perform You should provide data and analyses to address the following questions: What are the qualitative trends and characteristics of each habitat? How does the total density of canopy trees differ between habitats? Does relative abundance of each species differ between canopy and sapling trees? How consistent is this among habitats? Remember: describe what analyses you did in the method section, present what your found in the results section, and talk about what it means in the discussion. 4.3.1 Canopy tree density You can use the point-quarter method to estimate tree density at each site with a bit of math. Let \\(x_i\\) be the distance from your point to a sampled canopy tree. If you sampled 4 trees at a point, then the density in trees per square meters would be \\(\\frac{4}{x_1^2 + x_2^2 + x_3^2 + x_4^2}\\). More generally, the density is \\(1 / \\text{mean}(x^2)\\). Calculate density for each sample point, and convert it to hectares (multiply by \\(10,000 \\text{ m}^2/\\text{ha}\\)). How do densities compare between habitat types? Create a figure and compare the averages. Note that you won't be able to claim that one group is different unless you use statistical tests, such as a one-way ANOVA (this is optional). 4.3.2 Species by habitat and life stage For each habitat, you will want to calculate the relative abundance of each tree species for canopy and sapling trees (i.e., number of Canopy species x in habitat y divided by total number of observed Canopy trees in y). Visualize the result for each habitat (a three-panel frequency plot would be the best way to go, with categories ordered by canopy abundance). To test if the relative proportions in canopy and saplings are equivalent, you should construct contingency tables for each habitat (See Table 4.1 for an example). Restrict each table to the five most common species in each habitat. Contingency tables can be constructed with pivot tables in Excel or the table() function in R. Use chi-square tests to see if the proportions of species are different between canopy and saplings for each habitat. Table 4.1: Abundance of most common canopy and sapling trees in the BFL old pasture habitat, Fall 2018. Carya illinoiensis Celtis spp. Juniperus spp. Quercus buckleyi Quercus fusiformis Ulmus crassifolia Canopy 7 2 17 3 2 9 Sapling 0 6 7 3 6 11 4.4 Discussion Some suggestions for discussion topics: How could differences in sapling/canopy relative abundances inform possible successional trends? Based on your results, what would you predict about future dominant species in the habitats? Did you observe anything else about the ecology or natural history of these areas that may help account for your results (e.g., drought stress, dead trees, invasive species, disease, etc)? What may be driving the differences in the habitat types? Considering the history of BFL may be helpful in explaining some of this. Develop a likely scenario for the past and future decades of tree population dynamics in the woodlands of BFL. How has drought and oak wilt affected the tree community at BFL? How might a scenario for succession based on currently healthy trees be changed if we include the information on stressed/dead trees? How could this line of research be expanded upon in future work? 4.5 General Comments (Post-Review) These were some general comments I had on a previous year's reports; I'd recommend reading them, since they're common mistakes that it would be good to avoid. 4.5.1 Figures Review the guidelines in the Figures chapter. Specifically: Don't use figure titles; anything that could go there should be in the caption instead. Use colors that will work in black and white, Number figures in the order they're cited in the main text; they should also be arranged in this order (e.g., figure 2 shouldn't be placed before figure 1). If the figure contains new data (which all of these should), it should be cited in the results. Figure numbers shouldn't have decimals in them (e.g., no Figures 1.1, 2.3, etc). If you have a multi-panel figure, refer to specific panels as Figure 1a, 1b, etc. If you have a multi-panel figure, there should be a single caption that explains what each of the panels are. Don't use bar plots for group means; boxplots or violin plots are usually better. This is a very inefficient way to present 3 data points, and it provides no information about the data's variability. Boxplots or violin plots are better options. (Note that bar plots are still fine for counts or proportions). No gridlines (see below) To remove gridlines in excel, just click on them and delete them. Base plots in R (with the plot() function) shouldn't have them by default. To remove them with ggplot2 figures, put this near the top of the code: install.packages(&quot;cowplot&quot;) # if you don&#39;t have this installed; run once library(cowplot) theme_set(theme_cowplot()) # this makes your ggplots look nicer until you restart R # ggplot commands here 4.5.2 Write this like you're trying to publish it You should write these reports as if you were writing a manuscript for a journal. Pretend it's not a class paper; don't say &quot;For this lab, our assignment was...&quot; or &quot;the other students...&quot; Write like it's a research project; you came up with the hypotheses and methods and the other students in the class are your collaborators. When describing the data collection, you need to describe how all of this year's data was collected, for all groups. Instead of saying &quot;we sampled three points in per habitat,&quot; say &quot;five groups each sampled three points per habitat.&quot; As part of this, don't talk about combining your group's data with the rest. Finally, you need to have a real title. 4.5.3 Describe the habitats Since the different habitat types are an important part of this paper, you should describe them in a reasonable amount of detail; this could go in the intro or methods section, depending on how you wrote it. 4.5.4 The Analysis Formally, the chi-squared test evaluates whether the rows and columns of a contingency table are independent of each other. In the context of this project, that's equivalent to testing whether the Canopy:Sapling ratio was equal for each species OR if the prevalence of each species was the same for canopy and sapling trees. Several people misinterpreted the analysis as examining if there were more canopy or sapling trees. This wouldn't work, because the chi-square test cannot tell you anything about the actual number of trees and because the way you collected the data (a fixed number of trees per point) was not set up to answer this question. The Chi-square analysis was often described incorrectly in the methods; an unfamiliar reader would not know what you were testing. When you're describing the test, you don't necessarily need to state the null/alternative hypotheses, but you need to make it clear what question you're answering with it. It's also worth remembering that the data we collect is generally not incredibly high precision. Our measurements generally don't have the ability to distinguish between a mean density of 437.11 and 437.14; depending on the sample size, we may not even be able to distinguish between 437 and 442. Being overly precise doesn't help. If your p-values are less than 0.0001, just report &quot;p &lt; 0.0001.&quot; 4.5.5 Keeping things in the right sections Many people restated the methods used for their statistical analyses in the results. For example: &quot;I ran chi-squared tests, and they showed significant differences in the old quarry (chi-square = ..., df = ..., p = ...), the old pasture (...) and the river terrace (...).&quot; Don't do this; instead, only provide the result. A better re-work of the above sentence would be: &quot;Species composition was significantly different between canopy and sapling trees in the old quarry (...), the old pasture (...), and the river terrace (...).&quot; Don't put anything in the intro or methods that is actually a result. Many people listed the most common species found in each habitat in their &quot;study area&quot; sections. Since this was a major part of this lab, listing the dominant species should be accompanied by a citation to show evidence that this is already known. In general, if you find yourself saying that the most common species &quot;were&quot; something, then it sounds like you are talking about your own observations; if you say that they &quot;are&quot; or &quot;have been&quot; something, then it sounds like you're talking about more general patterns. 4.5.6 Basic style and format rules Don't capitalize things that don't need capitalization (e.g., the point-quarter technique). Most acronyms should be defined before their first use (though there are a few exceptions, like ANOVA). Don't say (p-value = x), say (p = x). If a paper has more than two authors, cite it as &quot;(Smith et al., 2009),&quot; not &quot;(Smith, Johnson, Franks, and Brown, 2009). 4.5.7 Other Comments The &quot;fisher test&quot; is properly called Fisher's exact test (with &quot;Fisher&quot; capitalized). If you used a stats program for a bunch of different things (as you usually do w/ R or Excel), mention it at the end of the section, not the beginning. RStudio is an interface for doing analysis with R; if you used it, you should say you did your analysis in R. Make sure to explain that sample points were selected differently in pond/old pasture than in other habitats. In the discussion, if you are listing several possible interpretations of your results, it's a good idea to put the most interesting one(s) ahead of the &quot;this is all random noise&quot; option. "],
["Lab2.html", "Chapter 5 Lab 2: Woodland Heterogeneity 5.1 Introduction &amp; background 5.2 Questions and Hypotheses 5.3 Field Methods 5.4 Analyses", " Chapter 5 Lab 2: Woodland Heterogeneity 5.1 Introduction &amp; background Apparent uniformity of grassland and woodland phases of a natural landscape as viewed from high altitudes (e.g., as seen on Google Earth images) typically disappears as we travel at ground level. Close observation reveals variation in plant form and stature as well as in species association that can create a mosaic of definable alternatives within basic woodland / shrub land / grassland themes. For example, within in a forest there is heterogeneity vertically in the density of foliage. As a student, ecologist Robert MacArthur predicted that habitats that are highly variable in the structure of foliage should would provide more distinctive niches, which would support more bird species like warblers that forage for insects moving about in forest understory bushes, small trees and canopy trees. He proceeded to show that bird species diversity is correlated with an arbitrary index termed “foliage height diversity” or F.H.D. MacArthur and MacArthur (1961) calculated F.H.D. using estimates of the proportion of total foliage in the ground, shrub and canopy in eastern deciduous forests. This is an example of being creative in developing ways to quantify habitat variation in to test ecological hypotheses. The structural heterogeneity present in an undisturbed forest can be greatly increased by disturbance. A common form of natural disturbance in forested habitat is the death or removal of canopy trees creating “light gaps.” These gaps drive changes (and increase heterogeneity) in previously shaded understory plant populations. An example of how and why ecologists study forest gaps is seen in Lertzman et.al (1996). Note: This author and colleagues later developed the technology we apply in this exercise. Different plants and animals specialize on or rely on particular microhabitats and/or relationships generated by habitat disturbances like treefalls, landslides, fire, and herbivory. Thus some degree of disruption is promotes the diversity of species. Check out the controversy surrounding the “intermediate disturbance hypothesis”. Since the first 373L classes took these kinds of data in the early 2000’s, there have been major changes in shrub cover in several areas of BFL. In 2002, deer density had peaked at 68 animals and browsing in the forest understory for just 10 years had reduced shrub cover (anecdotal observations). Meanwhile light availability in the understory has increased due to tree disease and drought-caused mortality. Thus in the last 17 years many large live oaks have died from oak wilt and in the past 9 years severe drought has killed large hackberry, elm and juniper trees across BFL. Between 2007 and 2015 coyote predation reduced the BFL deer population from 25 to 4 individuals. As of early 2016 deer are extinct within BFL for the first time since 1991, by which time the impact of this large herbivore on vegetative structure was in steep decline=. The cumulative effect of losing deer browsing appears to be a dramatic increase in the density of tree saplings (e.g., laurel cherry, Texas Ash) and invasive shrubs (e.g., Chinese privet) in the forest understory. In this week’s project, we will attempt to classify and characterize the heterogeneity of habitat at BFL based upon the density of vegetation at the ground, shrub and canopy levels. In addition to learning some methods to describe degree of canopy disturbance, we will use digital cameras and gap light analysis software to test our ability to subjectively categorize canopy cover in an ecologically meaningful way. For this project, we define “canopy” as that part of the vegetation that shades understory vegetation. This exercise will teach methods for rapid assessment of vegetative structure. 5.2 Questions and Hypotheses What are the relationships between canopy, shrub, and ground cover? How have the relative abundance of Canopy, Shrub, and Ground cover categories changed over time? You'll also be doing to other things that aren't specifically hypothesis or question driven, but should be presented in the results. Examining the spatial mosaic of canopy heterogeneity. Calibrating your subjective estimates of canopy estimates with the Gap Light Analyzer calculations. This in particular isn't a biological hypothesis, but comparing different methods for addressing the same question is a common feature of biological research. 5.3 Field Methods After a review of the variety of ground covers, shrub covers and canopy covers encountered at BFL, we will utilize simple, easily distinguished categories for degree of coverage at each layer ranging from 0 (minimum cover) to 3 (maximum cover). At each site, we will score ground cover (0-3) and enter an estimate of percent dicots score shrub cover (0-3) and enter an estimate of percent evergreen shrubs score canopy cover (0-3) and enter an estimate of percent evergreens and note the tree species above. The shrub layer will be scored only below eye level. This level roughly corresponds with the top of the browse line when deer were present. We will compare present shrub layer scores with those in a similar drought year when deer were still a forces at BFL. Each team will walk along 3-4 of the ten permanent transects at BFL, taking a reading of canopy cover (0-3) at each of the numbered transect markers that occur at 20 m intervals. The cumulative data will include readings at approximately 140 sites across BFL. We will calibrate our subjective estimates of canopy cover using digital cameras and fish-eye lenses to record actual canopy cover and shrub layer density. “Gap Light Analyzer” (Frazer et al 1999) software available on the computers will allow us to calculate the “percent openness” in the hemisphere above each sample point. Make sure that you take the fish eye photo exactly where the estimate of canopy cover was taken. If a team member takes the photo after others made the visual estimates, a flag should be left as a reference for the photographer. To take the picture, the long axis of the camera should be oriented north south with the photographer’s right hand on the south side, i.e. you should face due east, then turn the camera toward the sky. This will ensure that the bottom of the picture points east. Make sure that the camera is on a full wide angle (no zoom) and with the flash suppressed. Those taking photos need to carry a compass. (See GLA handout) We will also record instantaneous inputs of light wavelength needed for plant growth at a representative sample of points using an Apogee quantum meter (It measures micromoles of photons per square meter per second between the wavelengths at 400-700 nm). We will assign two people from different teams to collect these data. 5.4 Analyses 5.4.1 Calibrating canopy estimates Since most of our analyses rely on subjective measurements, it would be good to calibrate how well the subjective categories predict light measurements estimated by Gap Light Analyzer. Use linear regression on this class's dataset, with subjective score as the predictor and percent openness as the response. Note that the structure of the data will almost certainly violate some of the assumptions of a linear regression test. We can still do this because this isn’t a hypothesis-driven analysis, but a prediction-driven one; provide the \\(R^2\\) and fit equation, but not the p-values. To run a regression in R, modify this code: regression = lm(y ~ x, data = your_data_set) # adjust this for your regression regression # this gives you the coefficients summary(regression) # This includes R2 values # Note that you should go with the &quot;Multiple R-squared,&quot; not &quot;Adjusted R-squared&quot; Create a figure for this analysis, including the data points and trend line. If you're using Excel, please remember that the equation that appears after you add the trendline shouldn't be included in the resulting graph (it belongs in the caption and main text). If you're using ggplot in R, you can add a regression line to the graph by adding the following line to your figure code: geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;grey&quot;) # feel free to change color One other thing I'd recommend is spreading out the points on your x axis a little, since otherwise they will just be four vertical lines. In ggplot, you can do this by replacing geom_point with: geom_jitter(height = 0, width = .25) # changing width will spread the dots out more; just don&#39;t change height 5.4.2 Relationship between canopy and ground cover Create four contingency tables examining the ground &amp; shrub cover relationship; one for each level of canopy cover. Note that the cells of the tables should be a count (number of plots), not a relative proportion. Run chi-squared tests on each table. This is rather similar to what you did for the previous lab. Re-create these tables with the relative number of plots per canopy cover type for each ground/shrub combination. You need to visually present this information in some way; you could try making a graph of some sort, or you could color the cells of the table to indicate the strength of the proportion. Note that adding color information to a table would turn it into a figure, and it should be referred to as such. 5.4.3 Quantifying the spatial mosaic Use a map of BFL and number/color the canopy level at each point. Connect adjacent areas of the same number. Note whether any spatial patterns in cover vales can be associated with main habitat types based on past land use, substrate types, and history of natural disturbances. If you do this by hand, scan or photograph it and include it in the Canvas submission. 5.4.4 Historical Trends How have the relative abundances of each category within the three cover types changed over time? You don't need to do an analysis for this, but create a figure. Since this data changes over time, you should have time along the x axis of the figure. Line plots and stacked box plots are two possible options. Multiple panels may be warranted. "],
["working-with-r.html", "A Working with R A.1 Introduction to RStudio A.2 R basics", " A Working with R The appendices will include a tutorial on some data analysis topics that will be helpful for this class. Please make sure you've installed R and RStudio, and some essential packages according to this guide. You can skip installing git for now. A.1 Introduction to RStudio RStudio is organized into four panels: scripts &amp; documents (upper left), the console (lower left), and two utility palens on the right that have various helpful functions. You may not see a document window on the left; if so, hit Ctrl+Shift+N to create a blank script. (Note that on Macs, Ctrl should pretty much always be replaced with Cmd). Generally, you write all of your code in the document window, then hit Ctrl+Enter (Cmd+Return) to send the R statement your cursor is on to the console window. A.1.1 RStudio Projects RStudio's most useful feature is R projects, which automatically manage a lot of the tedious things that can normally cause problems when working with R. Most importantly, they make it easier to keep track of where your script, data, and output files are. Let's create a project for Bio 373L. In the upper right corner, click the down arrow next to Project: (None) (if it says something else, that's fine), then select New Project.... Select New Directory -&gt; New Project, then give it a name relevant to the class. I'd recommend making the project a subdirectory of where you keep the rest of your 373L files. Create the project; RStudio will take a moment to reset, then the upper-right corner of the screen should have the name of your project. Always make sure the project is loaded when you're working on material for this class; if it isn't, just click the project drop-down arrow and select it from the list. Now that your project is loaded, click the Files tab in one of the two utility panels; this shows everything in the project directory. All of the script &amp; data files you work should be put in this directory. I recommend creating a folder for each lab (click the New Folder button) to keep things organized. If you want to open the folder in Windows Explorer/Finder/whateverfile manager you use, click the More button, then Show Folder in New Window. A.1.2 Customizing RStudio I have a couple of recommendations for customizing RStudio to make it easier to use. Go to Tools -&gt; Global Options. Under the General tab, make sure that the Workspace options are unchecked and set to Never; this will make sure you start with a fresh slate every time you start up R and prevent some weird errors from cropping up. Under Appearance, I'd take a look at some of the Editor themes. I'm rather fond of Vibrant Ink. Under Pane Layout, you can reorganize your panels. I like to put the Console in the lower right, and make sure that the lower left pane contains only History, Connections, Packages, and Tutorial. I generally find those four functions to be generally useless, so I can keep that pane minimized and have a larger document window on the left. A.2 R basics A.2.1 Statements &amp; vectors Let's take a look at some R basics. First, R can be used as an excessively fancy calculator. The following block contains R expressions, followed by the results of running them in the console (preceded with ##). Try running it yourself. (4^2 + 8)/10 ## [1] 2.4 log(5) + 12 ## [1] 13.60944 sqrt(abs(-20)) ## [1] 4.472136 R works naturally with vectors of numbers (or text). 1:10 # Create a sequence of numbers ## [1] 1 2 3 4 5 6 7 8 9 10 c(1, 4, 9, 12, 98.7) # use c() to make a vector ## [1] 1.0 4.0 9.0 12.0 98.7 c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;) # Here&#39;s a character vector ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; # Most operations work with vectors (1:10) + 2 ## [1] 3 4 5 6 7 8 9 10 11 12 (1:5) + c(10, 20, 30, 40, 50) ## [1] 11 22 33 44 55 # Vectors can only be of one type; mixing numbers &amp; text will convert them all to text c(&quot;I have been at UT for &quot;, 5, &quot;Years&quot;) ## [1] &quot;I have been at UT for &quot; &quot;5&quot; &quot;Years&quot; Note that anything following a # is a comment, and ignored by R. I highly advise using comments to document your code. A.2.2 Variables You can save values &amp; objects by creating variables. # You can use either &lt;- or = to assign a variable first_ten &lt;- 1:10 second_ten = 11:20 # Run the variable&#39;s name to see it&#39;s value (this is callled printing) first_ten ## [1] 1 2 3 4 5 6 7 8 9 10 second_ten ## [1] 11 12 13 14 15 16 17 18 19 20 # You can use variables just like you would use their values first_ten + 1 ## [1] 2 3 4 5 6 7 8 9 10 11 first_ten + second_ten ## [1] 12 14 16 18 20 22 24 26 28 30 # Note that variable names are case-sensitive first_Ten # doesn&#39;t work ## Error in eval(expr, envir, enclos): object &#39;first_Ten&#39; not found A.2.3 Reading &amp; working with data frames Before we get started with this you'll need to download an example data file. From RStudio, create an example_data directory, then save this file in it (make sure the name is still anoles.csv). Note that you may need to go to go to **File -&gt; Save Page As...* (or some variant) in your web browser to save it. Now, let's load the data into R. To do that, we need to load the readr package, which is part of the tidyverse. Note: RStudio has some built-in ways to load datasets; I would strongly advise not using them, because it makes it harder to go back &amp; repeat your analysis if something changes. library(tidyverse) lizards &lt;- read_csv(&quot;example_data/anoles.csv&quot;) # Note that the path is relative to your project directory. This is a data frame (effectively a spreadsheet). Technically, it's a type of data frame called a tibble, which doesn't really matter for what we're doing right now. Let's take a look at it: # quick view of data frame; note that there&#39;s more columns and rows lizards # listed than are displayed ## # A tibble: 657 x 9 ## Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 A Green 14.3 6.46 8 164 61.8 43.9 Other ## 2 A Brown 12.3 5.82 18 151 57.1 42.2 Tree ## 3 A Blue 10.5 4.29 36 130 49.1 25 Building ## 4 A Brown 10.3 5.29 31 131 51.2 38.2 Tree ## 5 A Brown 10.9 5.69 20 138 51.5 46.9 Shrub ## 6 A Brown 10.4 5.84 25 137 45.3 59 Shrub ## 7 A Green 11.1 5.91 7 138 49.7 47.6 Building ## 8 A Brown 10 5.09 20 141 48 34.9 Tree ## 9 A Brown 12.3 7.2 19 129 54.9 61 Tree ## 10 A Brown 11.2 6.66 15 134 52.7 50.4 Tree ## # … with 647 more rows # Look at the first few rows of each column glimpse(lizards) ## Rows: 657 ## Columns: 9 ## $ Site &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A… ## $ Color_morph &lt;chr&gt; &quot;Green&quot;, &quot;Brown&quot;, &quot;Blue&quot;, &quot;Brown&quot;, &quot;Brown&quot;, &quot;Brown&quot;, &quot;Gre… ## $ Limb &lt;dbl&gt; 14.3, 12.3, 10.5, 10.3, 10.9, 10.4, 11.1, 10.0, 12.3, 11.… ## $ Mass &lt;dbl&gt; 6.46, 5.82, 4.29, 5.29, 5.69, 5.84, 5.91, 5.09, 7.20, 6.6… ## $ Diameter &lt;dbl&gt; 8, 18, 36, 31, 20, 25, 7, 20, 19, 15, 31, 35, 10, 19, 30,… ## $ Height &lt;dbl&gt; 164, 151, 130, 131, 138, 137, 138, 141, 129, 134, 143, 15… ## $ SVL &lt;dbl&gt; 61.8, 57.1, 49.1, 51.2, 51.5, 45.3, 49.7, 48.0, 54.9, 52.… ## $ Tail &lt;dbl&gt; 43.9, 42.2, 25.0, 38.2, 46.9, 59.0, 47.6, 34.9, 61.0, 50.… ## $ Perch_type &lt;chr&gt; &quot;Other&quot;, &quot;Tree&quot;, &quot;Building&quot;, &quot;Tree&quot;, &quot;Shrub&quot;, &quot;Shrub&quot;, &quot;B… # View the data in an RStudio pane View(lizards) Each column of the data frame is a vector of the same length. We can pull our columns and work with them directly: # Let&#39;s extract the color column lizards$Color_morph lizards[[&quot;Color_morph&quot;]] pull(lizards, Color_morph) # requires dplyr package, which is in the tidyverse # Note that some of these require quotes, some of them don&#39;t; this is # I haven&#39;t included output here, because it&#39;s rather long A.2.4 Functions Pretty much everything that isn't data is a function. Some of the examples we've used include log, abs, read_csv, and mean. Most functions have arguments, which tell the function what to work with. For example: mean(x = 1:5) # mean of 1 through 5 ## [1] 3 sd(x = lizards$Mass) # standard deviation of lizard mass ## [1] 1.088521 Functions can have multiple arguments; for example log has the arguments x and base. Arguments can be matched by name or by their position. Some arguments have default values that are used if the argument isn't provided. log(x = 1:5) # argument is matched by name; base uses it&#39;s default value ## [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379 log(1:5, base = 10) # specifies a base; this overrides the default ## [1] 0.0000000 0.3010300 0.4771213 0.6020600 0.6989700 log(1:5, 10) # same as above, but matched by position ## [1] 0.0000000 0.3010300 0.4771213 0.6020600 0.6989700 A.2.5 Getting Help R has a built-in help system to look up functions, their arguments, and what they do: ?read_csv ?mean ?log "],
["ggplot-tutorial.html", "B Making graphs in R with ggplot2 B.1 Components of a plot B.2 Aesthetics and scales B.3 Geometry B.4 Facets B.5 Changing the theme, axis titles, &amp; other visual elements B.6 More references", " B Making graphs in R with ggplot2 B.1 Components of a plot In this chapter, we discuss the basics of making figures with with the ggplot2 package in R (part of the tidyverse. The ggplot2 package assembles a graph from several components. The important components are: Data: You should have the data going into a plot organized into a data frame, where each row is an observation and each column is a different variable. This is called &quot;tidy data;&quot; we'll talk more about it later. Aesthetics: Which variables (columns) in the data connect to visual components of the plot? E.g., what goes on the X &amp; Y axes, what does color mean, etc? Scales: How do your aesthetics visually appear? For example, if your aesthetics say that &quot;Mass&quot; is represented by color, a scale would say what colors those actually are. Geometry: What's actually drawn on your graph (e.g., points, lines, bars, etc) Facets: If you're splitting your figure into multiple panels, what data is informing that? Let's look at an example: # Load packages &amp; data library(tidyverse) lizards &lt;- read_csv(&quot;example_data/anoles.csv&quot;) # If this throws an error, see Appendix A for how to download it. base_plot &lt;- ggplot(data = lizards) + # Data: sets up a plot around lizards aes(x = SVL, y = Tail) + # Aesthetics: Connects columns of lizards to x and y geom_point() # Geometry: we&#39;re using points # Scales aren&#39;t listed, so they&#39;re using default values base_plot # show results This is a functional plot, but it doesn't look much like a scientific figure. One quick option to change some of the default values is to use a theme. For this class, I'd like everyone to use the cowplot theme. Setting the theme will apply until you restart R. # Include these two lines after loading tidyverse/ggplot2 # at the top of each script library(cowplot) theme_set(theme_cowplot()) # Now view the plot again, and see the results base_plot B.2 Aesthetics and scales Aesthetics connect a column of data to a visual representation on the plot. For example, x and y are aesthetics that correspond to axis positions. B.2.1 Color Color is a commonly use aesthetic; let's add it to our base_plot. # Connect the color aesthetic with the Color_morph column in the data base_plot + aes(color = Color_morph) # This is a discrete color # Connect the color aesthetic with the Limb column in the data base_plot + aes(color = Limb) # This is a continuous color These aren't particularly great color defaults; we can use scales to change them. The viridis color scale is a good default option, since it's generally colorblind friendly and isn't terrible when printed in black &amp; white. base_plot + aes(color = Color_morph) + scale_color_viridis_d() # uses the &quot;Viridis&quot; colors, discrete scale base_plot + aes(color = Limb) + scale_color_viridis_c() # uses the &quot;Viridis&quot; colors, discrete scale You can also define your own colors for discrete variables: my_morph_colors = c(&quot;#a06f00&quot;, &quot;#004368&quot;, &quot;#e0a1c4&quot;) # Color Hex codes; if you&#39;re unfamiliar, google it. base_plot + aes(color = Color_morph) + scale_color_manual(values = my_morph_colors) B.2.2 Shape Shape only works for discrete variables base_plot + aes(shape = Color_morph) base_plot + aes(shape = Color_morph) + scale_shape(solid = FALSE) If you want to set manual shapes, look at ?pch to see which the options. B.2.3 Size base_plot + aes(size = Limb) This is kind of a mess in its current state. Let's fix that. B.2.4 Fixed aesthetics You can define an aesthetic value as a constant within a geom_* call, and it will refer to that literal value instead of a data column. # Note that I&#39;m including the aes() term with ggplot() instead # of adding it; these are equivalent ggplot(data = lizards, aes(x = SVL, y = Tail, size = Limb)) + # Define a default color &amp; shape for points geom_point(color = &quot;cornflowerblue&quot;, shape = 1) This makes the previous cloud of points a bit easier to separate. B.2.5 Combining aesthetics Aesthetics are particularly powerful when combined. It can be helpful to double-up the aesthetics for a variable (to help improve clarity to the reader). ggplot(data = lizards) + aes(x = SVL, y = Tail, shape = Color_morph, color = Color_morph) + geom_point(size = 2.5) + scale_shape(solid = FALSE) + scale_color_viridis_d() Or to use different aesthetics with different variables to explore different variable combinations base_plot + aes(color = Limb, shape = Color_morph) + scale_shape(solid = FALSE) + scale_color_viridis_c() B.3 Geometry Geometry layers are different ways to visualize your data (primarly along the x and y aesthetics); different types of geom_* objects are suitable to different types of x and y data. B.3.1 Continuous X, no Y Histograms: ggplot(data = lizards) + aes(x = Diameter) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Note that this generates a warning. R automatically assigns the data into bins. To remove the warning, povide the binwidth argument. ggplot(data = lizards) + aes(x = Diameter) + geom_histogram(binwidth = 2.5, color = &quot;black&quot;, fill = &quot;white&quot;) Note that we used the color and fill aesthetics; for solid objects (like bars), color refers to the outline and fill refers to the solid color. Density Plots do something similar, but with a smooth estimate. ggplot(data = lizards) + aes(x = Diameter) + geom_density() If you wanted to separate the density estimates by color morph, all you'd need to do is add that aesthetic. ggplot(data = lizards) + aes(x = Diameter, color = Color_morph) + geom_density() Challenge: How would you do the same with a histogram? B.3.2 Discrete X, continuous Y Boxplots: these show the quartile distributions of datasets. Let's compare perch height distribution at each site: box_plots &lt;- ggplot(data = lizards) + aes(x = Site, y = Height) + geom_boxplot() box_plots Now let's break that down by color morph box_plots + aes(fill = Color_morph) + # We&#39;re using fill because boxplots are solid theme(legend.position = &quot;bottom&quot;) # Move the legend to the bottom to give us more room Violin plots are similar to density plots, but are more effective at comparing several groups. ggplot(data = lizards) + aes(x = Site, y = Height) + geom_violin() Jitter plots show individual data points for discrete groups; they add a bit of random noise to each x and y to prevent points from overlapping; the width and height arguments control how much in each direction. In this case, we only want jitter along the x. ggplot(data = lizards) + aes(x = Site, y = Height) + geom_jitter(width = .25, height = 0) An alternate to the jitter plot is provided by geom_sina in the ggforce package (you'll need to install it to make this work). This jitters the points on the x axis so they'll fit within a violin plot. # install.packages(&quot;ggforce&quot;) # Uncomment this to install library(ggforce) ggplot(data = lizards) + aes(x = Site, y = Height) + geom_violin() + geom_sina(color = &quot;grey30&quot;, fill = &quot;grey70&quot;, shape = 21) # Note that shape 21 uses both color a fill as aesthetics Note that we've included two geom_* layers here, and that the one that was called second (geom_sina) was plotted on top of the one called first. Sometimes, you'll want to show means &amp; confidence intervals of your different groups. If possible, it's helpful to put those in the context of the raw data. The below plot looks at differences in perch diameter among colors, with the raw data in grey and the means in black. The error bars (geom_errorbar) take aesthetics ymin and ymax, which indicate their range. We used plus &amp; minus 1.96 standard errors because that's the definition of a 95% confidence interval for normally distributed data. Be sure to tell your reader/audience what an error bar represents in your figure captions. # We need to create a new data frame for mean &amp; standard error of perch diameter # This uses dplyr commands, which are explained in the next appendix diameter_mean_se = lizards %&gt;% group_by(Color_morph) %&gt;% summarize( Diameter_se = sd(Diameter) / sqrt(n()), # Standard error Diameter = mean(Diameter)) # This mean diameter ggplot(lizards) + aes(x = Color_morph, y = Diameter) + # Show the raw data (from the lizards data frame) geom_sina(, color = &quot;grey60&quot;) + # Show the Mean +/- 95% confidence interval geom_errorbar( # 95% CI is the mean diamter +/- 1.96 * se aes(ymin = Diameter - 1.96 * Diameter_se, ymax = Diameter + 1.96 * Diameter_se), color = &quot;black&quot;, width = .3, # How wide the error bars are data = diameter_mean_se # Use the summary data frame instead of lizards # The column names should match with the global aesthetics (in this case, x and y) ) + geom_point(color = &quot;black&quot;, size = 2, data = diameter_mean_se # This one also uses the summary data frame # It keeps the global aesthetics, which match # the color morph &amp; mean value ) In this example, we've also used two data frames in the plot. This can be useful if you're combining two different types of data (such as raw &amp; summary, or individual &amp; site-level). The important thing to remember is that any columns named in the global aesthetics (defined by an aes() call that isn't inside a geom_*) must be present in both data frames. In this case, those aesthetics are Color_morph and Diameter. Diameter_se is a local aesthetic (in geom_errorbar), so it doesn't need to appear in all datasets. B.3.3 Continuous X and Y We've already seen geom_point used for continuous data. Here are a few other options: Heatmap: this is sort of a 2-d histogram, where the data is divided into bins along both the x and y axis; the fill indicates how many data points fall into that region. This is helpful if you have a lot of points that are all overlapping in the same area. ggplot(lizards) + aes(x = SVL, y = Tail) + geom_bin2d(bins = 25) + scale_fill_viridis_c() It's often helpful to add regression lines to scatterpoint plots. This shows the the Tail ~ SVL regression, with the shaded region indicating the standard errors. regression_plot = ggplot(data = lizards) + aes(x = SVL, y = Tail) + geom_smooth(method = &quot;lm&quot;, se = TRUE) + # method = &quot;lm&quot; uses a linear regression # use se = FALSE to disable error regions geom_point() regression_plot You can also fit a regression to different groups of the data. This fits a separate one for each color: ggplot(data = lizards) + aes(x = SVL, y = Tail, color = Color_morph) + geom_smooth(method = &quot;lm&quot;, se = TRUE) + geom_point() + scale_color_viridis_d() Given that these regression lines all seem to be mostly the same, it may be better to fit them as one, but still indicate the different color morphs of the individual fits. You can specify certain aesthetics that only apply to a single geometric layer by including an aes() statement inside the geom_* call. ggplot(data = lizards) + aes(x = SVL, y = Tail) + geom_smooth(method = &quot;lm&quot;, se = TRUE) + geom_point(aes(color = Color_morph)) + # call color here to only make it apply to points scale_color_viridis_d() B.3.4 Time series data If your x variable is related to time (or date), you'll probably want to use a line plot to visualize it. Our anole dataset doesn't work for this, so you'll need to save this as &quot;example_data/beavers.csv&quot;. This data has info on the body temperature of two beavers over time. beavers = read_csv(&quot;example_data/beavers.csv&quot;) ## Parsed with column specification: ## cols( ## Time = col_datetime(format = &quot;&quot;), ## Temperature = col_double(), ## activ = col_double(), ## beaver = col_character() ## ) ggplot(beavers) + aes(x = Time, y = Temperature, color = beaver) + geom_line() + scale_x_datetime(date_labels = &quot;%H:%M&quot;) # This tells R that you&#39;ve got a time on the x axis # date_labels says to use hours:minutes as the axis format B.3.5 Discrete X and Y Bar graphs are good for showing counts, frequencies, and proportions. This shows how many individual lizards were in each site; It works by counting the number of rows in which the Site column has each value. ggplot(data = lizards) + aes(x = Site) + geom_bar() If you use a grouping aesthetic, you'll get a stacked bar plot by default: ggplot(data = lizards) + aes(x = Site, fill = Perch_type) + geom_bar() + scale_fill_viridis_d() Sometimes, stacking can be hard to interpret; you can have your categories lined next to each other by specifying the bar position as dodge: ggplot(data = lizards) + aes(x = Site, fill = Perch_type) + geom_bar(position = &quot;dodge&quot;) + scale_fill_viridis_d() It's usually a good idea to have your bars ordered in a descending frequency; you can do this by using fct_infreq() in your aes() statement. ggplot(data = lizards) + aes(x = fct_infreq(Site), # Note how this changes the axis label fill = Perch_type) + # We&#39;ll talk about how to fix that in a bit geom_bar() If you wish to use frequencies instead of counts along the y axis, it's usually a better idea to calculate them yourself and display those numbers. You can use geom_col() for these displays; it's like geom_bar(), but it takes a user-suplied y aesthetic. # This code uses dplyr, which is discussed in the next appendix. Don&#39;t worry if it doesn&#39;t make sense now. # Overal perch_height frequency lizard_perch_freq = lizards %&gt;% group_by(Perch_type) %&gt;% summarize(count = n()) %&gt;% # calculate frequencies per-group mutate(frequency = count/sum(count)) %&gt;% # sort by frequency arrange(desc(frequency)) %&gt;% # tell ggplot to plot Perch_type in its current order mutate(Perch_type = fct_inorder(Perch_type)) ## `summarise()` ungrouping output (override with `.groups` argument) # feel free to use View() to look at this ggplot(lizard_perch_freq) + aes(x = Perch_type, y = frequency) + geom_col() B.4 Facets You can use facets to make multi-panel figures. This can highlight differences between groups if including them in the same panel is too busy or messy. Let's start by taking our previous regression plot and separating it by color morph. regression_plot + facet_wrap(~Color_morph) # note the ~ It doesn't look like there's much there. What about faceting by site? regression_plot + facet_wrap(~Site) # note the ~ In this case, it looks like the data ranges are quite a bit different among the sites. This leads to a large amount of unused space. You may wish to remove this whitespace. regression_plot + facet_wrap(~Site, scales = &quot;free_x&quot;) # scales can also be &#39;free_y&#39; or &#39;free&#39; (which does both x and y) You can also facet by two variables into rows &amp; columns with facet_grid(). regression_plot + facet_grid(Perch_type~Color_morph) # rows ~ columns B.5 Changing the theme, axis titles, &amp; other visual elements By default, ggplot will name your axis labels &amp; legends by whatever you put in the aes string. You may wish to change that. For example, the labels on this plot could be improved: ggplot(lizards) + aes(x = Limb, y = Diameter, color = Color_morph) + geom_point() + scale_color_viridis_d() The xlab() and ylab() commands can provide labels for their respective axes, while the name argument can re-label scales. ggplot(lizards) + aes(x = Limb, y = Diameter, color = Color_morph) + geom_point() + scale_color_viridis_d(name = &quot;Color Morph&quot;) + xlab(&quot;Hind Limb Length (mm)&quot;) + ylab(&quot;Perch Diameter (mm)&quot;) More complicated options involve tweaking the theme. I'm not going to get into this right now, but I may update this later if conditions call for it. There is an example of using it to move the legend position several sections ago. B.6 More references You can find a cheatsheet for ggplot2 in RStudio under Help -&gt; Cheatsheets; this covers most of the basic functions. The official website has a full list of geoms, scales, aesthetics, theme options, and everything else; it's a more developed version of R's built-in help mechanism. R for Data Science has a chapter on ggplot2 that is also quite helpful. Finally, it's worth looking at the Figures chapter of this book for more examples; the code used to make those figures is linked at the bottom of the chapter. "],
["dplyr-tutorial.html", "C Data manipulation with dplyr C.1 The Pipe (%&gt;%) C.2 Adding/modifying columns (mutate) C.3 Subsetting by row (filter) C.4 Subsetting by column (select) C.5 Sorting by columns (arrange) C.6 Summarizing data C.7 Group Operations", " C Data manipulation with dplyr Let's talk about data manipulation. We'll be using the dplyr package, which is part of tidyverse. You can find a quick reference page under Help -&gt; Cheatsheets in RStudio. First, we need to load our packages &amp; data. library(tidyverse) library(cowplot) theme_set(theme_cowplot()) lizards &lt;- read_csv(&quot;example_data/anoles.csv&quot;) # See Appendix A if you don&#39;t have this data C.1 The Pipe (%&gt;%) The pipe ( %&gt;% ) operator strings functions together in a sequence. It takes the result of the function on its left and makes it the first argument to the function on the right. Let's say you wanted to calculate the base-12 log of the mean of the square root of the absolute value of numbers between -50 and 50. The traditional way to write that would be: log(mean(sqrt(abs(-50:50))), base = 12) ## [1] 0.6256332 This is rather difficult to read; it has a lot of nested parentheses, and you need to start from the inside and work your way out to see what's happening. With the pipe, you could re-write it like this: -50:50 %&gt;% abs() %&gt;% sqrt() %&gt;% mean() %&gt;% log(base = 12) ## [1] 0.6256332 Using pipes can make your code much clearer, and is quite helpful when creating a sequence of related transformations on data. In RStudio, you can insert the pipe by pressing Ctrl+Shift+M. C.2 Adding/modifying columns (mutate) The mutate() function creates a new column in a data frame. For example, the total length of a lizard is defined as its snout-vent length (SVL) plus it's tail length. mutate(.data = lizards, total_length = SVL + Tail) %&gt;% View() # Use View to look at the results in RStudio Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type total_length A Green 14.3 6.46 8 164 61.8 43.9 Other 105.7 A Brown 12.3 5.82 18 151 57.1 42.2 Tree 99.3 A Blue 10.5 4.29 36 130 49.1 25.0 Building 74.1 A Brown 10.3 5.29 31 131 51.2 38.2 Tree 89.4 A Brown 10.9 5.69 20 138 51.5 46.9 Shrub 98.4 A Brown 10.4 5.84 25 137 45.3 59.0 Shrub 104.3 A Green 11.1 5.91 7 138 49.7 47.6 Building 97.3 A Brown 10.0 5.09 20 141 48.0 34.9 Tree 82.9 A Brown 12.3 7.20 19 129 54.9 61.0 Tree 115.9 A Brown 11.2 6.66 15 134 52.7 50.4 Tree 103.1 This uses the lizards data to create a new column, total_length. Within the mutate command, you can reference columns directly by their names (like you do for aes() in ggplot). Mutate can create multiple new columns in a single command. mutate(lizards, # generally, the .data argument is not named # All subsequent arguments refer to new columns total_length = SVL + Tail, rel_limb = Limb/SVL, log_total_length = log(total_length), # You can also change an existing column by saving something to its name Color_morph = paste(Color_morph, &quot;morph&quot;) # add &quot;morph&quot; after each color ) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type total_length rel_limb log_total_length A Green morph 14.3 6.46 8 164 61.8 43.9 Other 105.7 0.2313916 4.660605 A Brown morph 12.3 5.82 18 151 57.1 42.2 Tree 99.3 0.2154116 4.598146 A Blue morph 10.5 4.29 36 130 49.1 25.0 Building 74.1 0.2138493 4.305415 A Brown morph 10.3 5.29 31 131 51.2 38.2 Tree 89.4 0.2011719 4.493121 A Brown morph 10.9 5.69 20 138 51.5 46.9 Shrub 98.4 0.2116505 4.589041 A Brown morph 10.4 5.84 25 137 45.3 59.0 Shrub 104.3 0.2295806 4.647271 A Green morph 11.1 5.91 7 138 49.7 47.6 Building 97.3 0.2233400 4.577799 A Brown morph 10.0 5.09 20 141 48.0 34.9 Tree 82.9 0.2083333 4.417635 A Brown morph 12.3 7.20 19 129 54.9 61.0 Tree 115.9 0.2240437 4.752728 A Brown morph 11.2 6.66 15 134 52.7 50.4 Tree 103.1 0.2125237 4.635699 Note that this doesn't modify the lizards dataset. It creates a new data frame that has an additional column. You'll need to save it as a new variable to use it. lizards_full = lizards %&gt;% # It&#39;s also traditional to pipe the data argument in mutate(total_length = SVL + Tail, rel_limb = Limb/SVL, log_total_length = log(total_length)) Tidyverse functions are designed to be piped together. For example: lizards %&gt;% mutate(Total_length = SVL + Tail) %&gt;% ggplot(aes(x = Site, y = Total_length)) + geom_boxplot() Creating a quick plot at the end of a data manipulation step can be a good way to get a visual idea of what you're doing. Here are a few other helpful things to do with mutate(): lizards %&gt;% mutate( intercept = 1, # Add a constant row_number = 1:n() # the n() function tells you how many rows are # in the current data frame (it only works in mutate &amp; related functions) ) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type intercept row_number A Green 14.3 6.46 8 164 61.8 43.9 Other 1 1 A Brown 12.3 5.82 18 151 57.1 42.2 Tree 1 2 A Blue 10.5 4.29 36 130 49.1 25.0 Building 1 3 A Brown 10.3 5.29 31 131 51.2 38.2 Tree 1 4 A Brown 10.9 5.69 20 138 51.5 46.9 Shrub 1 5 A Brown 10.4 5.84 25 137 45.3 59.0 Shrub 1 6 A Green 11.1 5.91 7 138 49.7 47.6 Building 1 7 A Brown 10.0 5.09 20 141 48.0 34.9 Tree 1 8 A Brown 12.3 7.20 19 129 54.9 61.0 Tree 1 9 A Brown 11.2 6.66 15 134 52.7 50.4 Tree 1 10 Here are a few exercises to try: Add a column to the lizards dataset that gives the lizard's height relative to the maximum height of any lizard (hint: use max(Height) in a mutate command to find that value). Calculate perch circumference (Diameter * pi), then pipe that result into a scatter plot of relative limb length vs. circumference. Note that pi is a pre-defined variable in R. C.3 Subsetting by row (filter) Let's define &quot;large lizards&quot; as: lizards %&gt;% mutate(large = SVL &gt; 60) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type large A Green 14.3 6.46 8 164 61.8 43.9 Other TRUE A Brown 12.3 5.82 18 151 57.1 42.2 Tree FALSE A Blue 10.5 4.29 36 130 49.1 25.0 Building FALSE A Brown 10.3 5.29 31 131 51.2 38.2 Tree FALSE A Brown 10.9 5.69 20 138 51.5 46.9 Shrub FALSE A Brown 10.4 5.84 25 137 45.3 59.0 Shrub FALSE A Green 11.1 5.91 7 138 49.7 47.6 Building FALSE A Brown 10.0 5.09 20 141 48.0 34.9 Tree FALSE A Brown 12.3 7.20 19 129 54.9 61.0 Tree FALSE A Brown 11.2 6.66 15 134 52.7 50.4 Tree FALSE The large column is a logical vector, with TRUE &amp; FALSE values. We can use logical vectors to get a subset of the data frame where the vector is TRUE with the filter() function. lizards %&gt;% mutate(large = SVL &gt; 60) %&gt;% filter(large) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type large A Green 14.3 6.46 8 164 61.8 43.9 Other TRUE B Brown 13.7 7.57 23 162 67.0 73.8 Building TRUE B Green 14.4 7.75 8 174 68.8 65.4 Tree TRUE B Blue 13.8 7.61 35 163 63.5 69.7 Building TRUE B Green 15.2 8.27 14 188 67.0 50.6 Tree TRUE B Green 14.1 6.73 17 176 64.8 49.0 Tree TRUE B Blue 14.2 8.43 29 177 69.6 85.3 Tree TRUE B Green 14.3 13.30 9 179 68.3 74.0 Tree TRUE B Blue 14.4 7.71 33 182 65.5 59.6 Shrub TRUE B Brown 14.1 7.95 32 178 70.1 69.0 Tree TRUE Note that only TRUE values of large remain the the data frame. It's not actually necessary to create a column before filtering: lizards %&gt;% filter(SVL &gt; 60) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type A Green 14.3 6.46 8 164 61.8 43.9 Other B Brown 13.7 7.57 23 162 67.0 73.8 Building B Green 14.4 7.75 8 174 68.8 65.4 Tree B Blue 13.8 7.61 35 163 63.5 69.7 Building B Green 15.2 8.27 14 188 67.0 50.6 Tree B Green 14.1 6.73 17 176 64.8 49.0 Tree B Blue 14.2 8.43 29 177 69.6 85.3 Tree B Green 14.3 13.30 9 179 68.3 74.0 Tree B Blue 14.4 7.71 33 182 65.5 59.6 Shrub B Brown 14.1 7.95 32 178 70.1 69.0 Tree The filter() command returns every row where its logical conditions are TRUE. Conditional statements that create logical statements include the following: x == y: TRUE if x equals y (This is not the same as x = y)! x != y: TRUE if x does not equal y x &gt; y: x &gt;= y; x &lt; y: x &lt;= y; between(x, y, z): TRUE if x &gt;= y AND x &lt;= z is.na(x): TRUE if x is a missing value (NA) x %in% y: TRUE if x is an element in y Note that all of these (except for x %in% y) are vectorized. c(1, 2) == c(2, 3) - 1 ## [1] TRUE TRUE c(1, 2, 3) == c(1, 4, 9) ## [1] TRUE FALSE FALSE c(1, 2) == c(2, 1) # positions don&#39;t match ## [1] FALSE FALSE c(1, 2, 3, 4, 5) %in% c(1, 2) # for %in%, position only matters for the left argument ## [1] TRUE TRUE FALSE FALSE FALSE You can also combine and modify logical values: x &amp; y: returns TRUE if both x and y are TRUE x | y: returns TRUE if either x or y are TRUE !x: returns the opposite of x; this one is particularly useful to combine with other logical functions; for example filter(data, !is.na(x)) will return all rows where x is not a missing value. If you give filter() more than one condition, it applies all of them by combining them with &amp;. lizards %&gt;% filter(Color_morph == &quot;Blue&quot;, Site %in% c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;)) %&gt;% ggplot(aes(x = SVL, y = Height, color = Site)) + geom_point() Exercises: Print a dataframe that shows only the lizards higher than 150 cm. How many are there (the console printout should tell you). How many lizards perching on trees or shrubs are not brown? Visualize the height to diameter relationship between them. Hint: you can use either %in% or a combination of == and | to meet the first condition. C.4 Subsetting by column (select) You can subset certain columns with the select() function. There are several ways to do this. The simplest is by name: lizards %&gt;% select(Site, Color_morph, SVL) %&gt;% View() Site Color_morph SVL A Green 61.8 A Brown 57.1 A Blue 49.1 A Brown 51.2 A Brown 51.5 A Brown 45.3 A Green 49.7 A Brown 48.0 A Brown 54.9 A Brown 52.7 You can also select by position: lizards %&gt;% select(1, 2, 7) %&gt;% View() Site Color_morph SVL A Green 61.8 A Brown 57.1 A Blue 49.1 A Brown 51.2 A Brown 51.5 A Brown 45.3 A Green 49.7 A Brown 48.0 A Brown 54.9 A Brown 52.7 This is more useful for ranges of values: lizards %&gt;% select(1:4, 7) %&gt;% View() Site Color_morph Limb Mass SVL A Green 14.3 6.46 61.8 A Brown 12.3 5.82 57.1 A Blue 10.5 4.29 49.1 A Brown 10.3 5.29 51.2 A Brown 10.9 5.69 51.5 A Brown 10.4 5.84 45.3 A Green 11.1 5.91 49.7 A Brown 10.0 5.09 48.0 A Brown 12.3 7.20 54.9 A Brown 11.2 6.66 52.7 You can also use character vectors: lizards %&gt;% select(&quot;Site&quot;, &quot;Color_morph&quot;, &quot;SVL&quot;) %&gt;% View() Site Color_morph SVL A Green 61.8 A Brown 57.1 A Blue 49.1 A Brown 51.2 A Brown 51.5 A Brown 45.3 A Green 49.7 A Brown 48.0 A Brown 54.9 A Brown 52.7 Note that if you want to use a variable that has column names saved as a character vector, you'll need to use a helper function (all_of) to tell select that you want to look for the contents of the variable, not the name of the variable: select_vars = c(&quot;Site&quot;, &quot;Color_morph&quot;, &quot;SVL&quot;) lizards %&gt;% select(all_of(select_vars)) %&gt;% # without all_of, it would try to look for a column called &quot;select_vars&quot; View() Site Color_morph SVL A Green 61.8 A Brown 57.1 A Blue 49.1 A Brown 51.2 A Brown 51.5 A Brown 45.3 A Green 49.7 A Brown 48.0 A Brown 54.9 A Brown 52.7 You can remove columns by using a negative sign. (Note that negative signs are ignored if you have any names without negative signs). lizards %&gt;% select(-Color_morph, -Limb) %&gt;% View() Site Mass Diameter Height SVL Tail Perch_type A 6.46 8 164 61.8 43.9 Other A 5.82 18 151 57.1 42.2 Tree A 4.29 36 130 49.1 25.0 Building A 5.29 31 131 51.2 38.2 Tree A 5.69 20 138 51.5 46.9 Shrub A 5.84 25 137 45.3 59.0 Shrub A 5.91 7 138 49.7 47.6 Building A 5.09 20 141 48.0 34.9 Tree A 7.20 19 129 54.9 61.0 Tree A 6.66 15 134 52.7 50.4 Tree lizards %&gt;% select(-(1:5)) %&gt;% View() Height SVL Tail Perch_type 164 61.8 43.9 Other 151 57.1 42.2 Tree 130 49.1 25.0 Building 131 51.2 38.2 Tree 138 51.5 46.9 Shrub 137 45.3 59.0 Shrub 138 49.7 47.6 Building 141 48.0 34.9 Tree 129 54.9 61.0 Tree 134 52.7 50.4 Tree You can also use the where helper function to select columns based on their characteristics. For example, the is.numeric function returns TRUE if its argument is a number; you can use it to select all numeric columns. lizards %&gt;% select(where(is.numeric)) %&gt;% View() Limb Mass Diameter Height SVL Tail 14.3 6.46 8 164 61.8 43.9 12.3 5.82 18 151 57.1 42.2 10.5 4.29 36 130 49.1 25.0 10.3 5.29 31 131 51.2 38.2 10.9 5.69 20 138 51.5 46.9 10.4 5.84 25 137 45.3 59.0 11.1 5.91 7 138 49.7 47.6 10.0 5.09 20 141 48.0 34.9 12.3 7.20 19 129 54.9 61.0 11.2 6.66 15 134 52.7 50.4 You could do the same for text or logical vectors with is.character or is.logical, respectively. Note that there aren't parentheses after is.numeric in the above code. that's because we aren't calling it on any particular value; instead, the where function calls it on every column of the data frame, and we're just telling it what function to use. There's a lot more you can do with this if you want to get fancy; the documentation is available at ?tidyselect::language. C.5 Sorting by columns (arrange) You can use arrange() to sort by one or more column values. To sort lizards from lowest to highest mass: lizards %&gt;% arrange(Mass) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type A Blue 10.5 4.29 36 130 49.1 25.0 Building L Brown 9.5 4.33 22 209 40.5 34.7 Other H Blue 9.4 4.42 28 161 40.3 41.5 Tree H Green 9.3 4.82 14 150 44.5 43.7 Tree L Blue 9.2 4.82 31 191 42.6 44.5 Tree L Blue 10.5 4.82 31 215 44.6 39.9 Shrub L Green 10.2 4.85 15 214 45.2 35.6 Tree K Green 9.7 4.89 18 58 47.7 23.7 Other H Blue 10.4 4.96 37 174 43.3 40.0 Shrub H Green 10.8 4.99 6 166 47.8 33.0 Tree If you wish to sort from highest to lowest, use the desc() helper function: lizards %&gt;% arrange(desc(Mass)) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type B Green 14.3 13.30 9 179 68.3 74.0 Tree J Brown 16.7 11.83 31 145 80.4 69.2 Other N Brown 15.8 10.13 25 130 73.2 90.0 Tree M Brown 11.9 9.79 24 210 56.0 70.7 Tree P Blue 15.4 9.74 41 221 76.3 95.7 Tree O Brown 16.4 9.63 24 217 74.3 65.7 Tree P Brown 15.4 9.58 29 216 70.4 81.6 Tree N Blue 14.9 9.54 38 128 68.4 67.5 Tree J Green 17.2 9.35 0 166 79.1 79.9 Tree O Blue 13.9 9.35 27 203 67.8 77.8 Shrub When you have categorical variables, you'll often have ties: lizards %&gt;% arrange(Site) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type A Green 14.3 6.46 8 164 61.8 43.9 Other A Brown 12.3 5.82 18 151 57.1 42.2 Tree A Blue 10.5 4.29 36 130 49.1 25.0 Building A Brown 10.3 5.29 31 131 51.2 38.2 Tree A Brown 10.9 5.69 20 138 51.5 46.9 Shrub A Brown 10.4 5.84 25 137 45.3 59.0 Shrub A Green 11.1 5.91 7 138 49.7 47.6 Building A Brown 10.0 5.09 20 141 48.0 34.9 Tree A Brown 12.3 7.20 19 129 54.9 61.0 Tree A Brown 11.2 6.66 15 134 52.7 50.4 Tree In this case, it's helpful to sort by multiple variables; the following code orders by Site, then by color morph within site, then by SVL. lizards %&gt;% arrange(Site, Color_morph, SVL) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type A Blue 10.6 5.53 36 134 46.1 50.3 Other A Blue 10.9 5.73 29 146 47.0 56.5 Other A Blue 10.1 5.40 27 133 48.2 45.7 Tree A Blue 10.5 4.29 36 130 49.1 25.0 Building A Blue 10.8 6.02 30 148 50.1 57.9 Tree A Blue 11.4 5.72 32 134 50.7 48.8 Tree A Blue 12.1 5.67 35 150 50.8 51.7 Other A Blue 10.8 5.27 30 141 51.2 43.3 Tree A Blue 12.5 6.18 28 140 52.9 48.4 Tree A Blue 11.0 6.68 31 143 53.8 49.5 Shrub One particularly useful thing you can do with this is create rankings. lizards %&gt;% arrange(desc(SVL)) %&gt;% mutate(size_rank = 1:n()) %&gt;% View() Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type size_rank O Blue 18.7 9.33 43 230 84.5 88.9 Tree 1 J Green 18.2 8.65 2 169 84.3 76.3 Tree 2 J Brown 16.4 9.21 30 147 81.0 86.8 Shrub 3 J Brown 16.7 11.83 31 145 80.4 69.2 Other 4 O Brown 17.3 8.04 23 223 80.2 56.6 Other 5 R Green 17.1 8.83 6 231 80.0 71.1 Tree 6 O Blue 16.1 8.50 36 221 79.3 73.8 Tree 7 J Green 17.2 9.35 0 166 79.1 79.9 Tree 8 J Blue 17.0 8.31 41 164 78.6 74.4 Tree 9 R Brown 17.1 8.30 23 217 78.5 50.3 Building 10 C.6 Summarizing data Summarize is like mutate, but it generally produces columns that are shorter than the input. It's typically used for summary stats. For example, this calculates several characteristics of SVL. lizards %&gt;% summarize(mean_SVL = mean(SVL), sd_SVL = sd(SVL), med_SVL = median(SVL), count = n()) %&gt;% View() mean_SVL sd_SVL med_SVL count 60.75282 8.708924 59.6 657 A useful trick for summarize is to take the mean of a logical vector; TRUE and FALSE are interpreted as 1 and 0, so this gives you a frequency. For example, if you wanted to get the proportion of color morphs: lizards %&gt;% summarize(freq_Blue = mean(Color_morph == &quot;Blue&quot;), freq_Brown = mean(Color_morph == &quot;Brown&quot;), freq_Green = mean(Color_morph == &quot;Green&quot;) ) ## # A tibble: 1 x 3 ## freq_Blue freq_Brown freq_Green ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.327 0.336 0.336 You can use the across helper function to apply the same summary function to multiple rows. lizards %&gt;% summarize( across(.cols = c(SVL, Tail), .fns = mean) ) %&gt;% View() SVL Tail 60.75282 57.55205 The .cols argument identifies the columns to use for the summary, using the same methods as select(), the .fns should be one or more functions to apply to each column. If you wish to use more than one summary function, you need to create a named vector: lizards %&gt;% summarize( across(.cols = where(is.numeric), # apply to all numeric functions .fns = c(Mean = mean, StDev = sd)) # named vector (Mean and StDev) ) %&gt;% View() Limb_Mean Limb_StDev Mass_Mean Mass_StDev Diameter_Mean Diameter_StDev Height_Mean Height_StDev SVL_Mean SVL_StDev Tail_Mean Tail_StDev 13.16088 1.83096 7.024368 1.088521 22.73364 10.13449 168.7382 42.69773 60.75282 8.708924 57.55205 12.12895 This applies the functions mean and sd to all numeric columns; The results have the names &quot;Mean&quot; and &quot;StDev&quot; that we gave each function applied to the end of the column. C.7 Group Operations The real power of the dplyr package comes from being able to apply all of the above functions to grouped subsets of a data frame. To create a grouped table use the group_by function: lizards %&gt;% group_by(Site) ## # A tibble: 657 x 9 ## # Groups: Site [19] ## Site Color_morph Limb Mass Diameter Height SVL Tail Perch_type ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 A Green 14.3 6.46 8 164 61.8 43.9 Other ## 2 A Brown 12.3 5.82 18 151 57.1 42.2 Tree ## 3 A Blue 10.5 4.29 36 130 49.1 25 Building ## 4 A Brown 10.3 5.29 31 131 51.2 38.2 Tree ## 5 A Brown 10.9 5.69 20 138 51.5 46.9 Shrub ## 6 A Brown 10.4 5.84 25 137 45.3 59 Shrub ## 7 A Green 11.1 5.91 7 138 49.7 47.6 Building ## 8 A Brown 10 5.09 20 141 48 34.9 Tree ## 9 A Brown 12.3 7.2 19 129 54.9 61 Tree ## 10 A Brown 11.2 6.66 15 134 52.7 50.4 Tree ## # … with 647 more rows This doesn't appear to do much on its own; however, look what happens when you combine it with summarize: lizards %&gt;% group_by(Site) %&gt;% summarize(mean_SVL = mean(SVL), sd_SVL = sd(SVL), count = n()) %&gt;% View() Site mean_SVL sd_SVL count A 51.69615 3.679944 26 B 66.92222 2.182673 36 C 58.09722 5.576250 36 D 70.70000 3.058280 27 E 53.17727 2.776887 44 F 58.77955 2.734583 44 G 63.87308 6.027507 26 H 52.18571 5.101008 42 I 57.04412 4.973639 34 J 74.34857 3.625512 35 This calculates the mean, SD of SVL for each site. You can group by multiple factors lizards %&gt;% group_by(Site, Color_morph) %&gt;% summarize(mean_SVL = mean(SVL), count = n()) %&gt;% ungroup() %&gt;% # Removes grouping; usually a good idea at the end unless you want surprises View() Site Color_morph mean_SVL count A Blue 49.99000 10 A Brown 52.01538 13 A Green 56.00000 3 B Blue 67.54000 10 B Brown 66.74667 15 B Green 66.60000 11 C Blue 58.96250 8 C Brown 57.03125 16 C Green 58.94167 12 D Blue 70.43750 8 Grouping doesn't just work with summarize; for example, you can use it with mutate to find the relative height of each lizard within its site: lizards %&gt;% group_by(Site) %&gt;% mutate( rel_height = Height/max(Height)) %&gt;% # max(Height) returns the max height in each site ungroup() %&gt;% ggplot(aes(x = Site, y = rel_height)) + geom_jitter(width = .2, height = 0) You can also use this to easily calculate frequencies: An alternate way to do this would be to combine summarise and mutate. lizards %&gt;% group_by(Site, Color_morph) %&gt;% summarize(count = n()) %&gt;% # count is the total number of each morph at each site group_by(Site) %&gt;% # Calculate color morph frequency at each site mutate(site_frequency = count / sum(count)) %&gt;% View() Site Color_morph count site_frequency A Blue 10 0.3846154 A Brown 13 0.5000000 A Green 3 0.1153846 B Blue 10 0.2777778 B Brown 15 0.4166667 B Green 11 0.3055556 C Blue 8 0.2222222 C Brown 16 0.4444444 C Green 12 0.3333333 D Blue 8 0.2962963 Some Exercises: Visualize the relationship between the maximum height at a site and the average limb length. Use this to help: lizards %&gt;% # Put your summarize() code here # You should name your new columns max_height and mean_limb ggplot(aes(x = max_height, y = mean_limb)) + geom_smooth(method = &quot;lm&quot;) + geom_point() For each site, what's the mean limb length of the five largest individuals by SVL? What proportion of these individuals is blue? "],
["r-analysis-tutorial.html", "D Performing some useful analyses in R D.1 A note on factors D.2 Comparing categorical frequencies (Contingency Tables &amp; related analyses) D.3 Linear Models: Regression and ANOVA D.4 To do (In progress)", " D Performing some useful analyses in R I'm going to give some examples of how to do common analyses you'll need for this class. I won't be spending much time on the statistical assumptions or diagnostics. library(tidyverse) library(cowplot) theme_set(theme_cowplot()) lizards &lt;- read_csv(&quot;example_data/anoles.csv&quot;) # See Appendix A if you don&#39;t have this data D.1 A note on factors R has two ways of representing textual data: character vectors (also called strings) and factors. Character vectors are just text; they have no inherent underlying meaning. Factors are a data type with a specific number of levels; they're often used to represent different experimental treatments. Examples could include {low, medium, high} or {control, treatment}. Each level of a factor is associated with a number. For the most part, it's easier and safer to work with character vectors. Most functions we'll be using know how to convert them when it's necessary. One important thing to note is that ggplot arranges character vectors alphabetically on its categorical scales, but orders factors by their level number. Thus, to change the order of categorical x-axes (and other scales), you need to make your categories into a factor. This is done with the fct_inorder, fct_infreq, and related functions, which are part of the forcats package and loaded with tidyverse. The easiest one to use is fct_inorder, which changes the level values to be in the order of your data; when combined with arrange() and other dplyr functions, this is quite flexible and powerful. For more information on these and other factor functions, take a look at the forcats website. If you want to manually create a factor, you can use the factor command, which is in base R (no package). color_levels = c(&quot;Red&quot;,&quot;Green&quot;,&quot;Blue&quot;) # Randomly select 20 colors from color_levels color_example = sample(color_levels, size = 20, replace = TRUE) color_example ## [1] &quot;Green&quot; &quot;Blue&quot; &quot;Green&quot; &quot;Green&quot; &quot;Blue&quot; &quot;Green&quot; &quot;Green&quot; &quot;Green&quot; &quot;Blue&quot; ## [10] &quot;Blue&quot; &quot;Red&quot; &quot;Blue&quot; &quot;Green&quot; &quot;Green&quot; &quot;Blue&quot; &quot;Green&quot; &quot;Red&quot; &quot;Blue&quot; ## [19] &quot;Blue&quot; &quot;Blue&quot; # Convert it into a factor color_as_factor = factor(color_example, levels = color_levels) color_as_factor ## [1] Green Blue Green Green Blue Green Green Green Blue Blue Red Blue ## [13] Green Green Blue Green Red Blue Blue Blue ## Levels: Red Green Blue D.2 Comparing categorical frequencies (Contingency Tables &amp; related analyses) These tests generally compare the frequencies of count data. D.2.1 Contingency Tables The easiest way to make a contingency table is from a data frame where each column is a categorical variable you want in the table &amp; each row is an observation. Let's say we wanted to create a color morph by perch type contingency with our lizard data. color_by_perch_tbl = lizards %&gt;% select(Color_morph, Perch_type) %&gt;% # select only the columns you want table() # feed them into the table command color_by_perch_tbl ## Perch_type ## Color_morph Building Other Shrub Tree ## Blue 17 41 27 130 ## Brown 31 25 25 140 ## Green 30 25 32 134 If you want to switch your contingency table from counts to frequencies, just divide it by its sum: color_by_perch_tbl / sum(color_by_perch_tbl) ## Perch_type ## Color_morph Building Other Shrub Tree ## Blue 0.02587519 0.06240487 0.04109589 0.19786910 ## Brown 0.04718417 0.03805175 0.03805175 0.21308980 ## Green 0.04566210 0.03805175 0.04870624 0.20395738 D.2.2 Chi-squared &amp; Fisher's Exact Tests Once you have a contingency table, you can test for independence between the rows and columns. This provides you with your test statistic (X-squared), degrees of freedom, and p-value. chisq.test(color_by_perch_tbl) ## ## Pearson&#39;s Chi-squared test ## ## data: color_by_perch_tbl ## X-squared = 11.603, df = 6, p-value = 0.07143 Chi-squared tests assume that there's at least five observations in each cell of the contingency table. If this fails, then the resulting values aren't accurate. For example: site_a_contingency = lizards %&gt;% filter(Site == &quot;A&quot;) %&gt;% # cut down the data size select(Color_morph, Perch_type) %&gt;% # select only the columns you want table() # feed them into the table command print(site_a_contingency) ## Perch_type ## Color_morph Building Other Shrub Tree ## Blue 1 3 1 5 ## Brown 0 0 2 11 ## Green 1 1 0 1 chisq.test(site_a_contingency) ## Warning in chisq.test(site_a_contingency): Chi-squared approximation may be ## incorrect ## ## Pearson&#39;s Chi-squared test ## ## data: site_a_contingency ## X-squared = 9.752, df = 6, p-value = 0.1355 Note the warning that &quot;Chi-squared approximation may be incorrect.&quot; In this case, it's a good idea to run the Fisher's exact test, which investigates the same null hypotheses, but works with low counts. Fisher's test is less powerful than the Chi-squared test, so it should only be used when it's the only option. fisher.test(site_a_contingency) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: site_a_contingency ## p-value = 0.06251 ## alternative hypothesis: two.sided You can also run a chi-squared or Fisher's exact test directly on two vectors or data frame columns: chisq.test(lizards$Color_morph, lizards$Perch_type) ## ## Pearson&#39;s Chi-squared test ## ## data: lizards$Color_morph and lizards$Perch_type ## X-squared = 11.603, df = 6, p-value = 0.07143 D.3 Linear Models: Regression and ANOVA Linear regression and Analysis of Variance (ANOVA) are both special cases of the general linear model (LM), which fits a continuous response (y) to one or more predictors (x). You specify linear models in R with a formula syntax, which generally follows as: response ~ predictor. Combining this formula with the lm() function and a datset gives you the basis of a linear model. D.3.1 Regression Lets say we wanted to see how snout-vent length (SVL) affects mass: simple_reg = lm(Mass ~ SVL, data = lizards) simple_reg ## ## Call: ## lm(formula = Mass ~ SVL, data = lizards) ## ## Coefficients: ## (Intercept) SVL ## 1.62577 0.08886 By default, this creates an LM object, which tells us the regression coefficients. For a linear regression (continuous response), these tell us the regression equation; in this case, that for every \\(1 \\text{ mm}\\) increase in SVL, mass increases by \\(0.089 \\text{ g}\\). Note that in this case, it may make sense to re-scale SVL to be in cm, so that the coefficient would be easier to interpret (e.g., use lizards %&gt;% mutate(SVL_cm = SVL/10). To extract the coeficients directly, use: coef(simple_reg) ## (Intercept) SVL ## 1.6257700 0.0888617 For more information, use the summary function: summary(simple_reg) ## ## Call: ## lm(formula = Mass ~ SVL, data = lizards) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.2672 -0.4699 -0.0530 0.3959 5.6050 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.625770 0.210781 7.713 4.59e-14 *** ## SVL 0.088862 0.003434 25.874 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7661 on 655 degrees of freedom ## Multiple R-squared: 0.5055, Adjusted R-squared: 0.5047 ## F-statistic: 669.5 on 1 and 655 DF, p-value: &lt; 2.2e-16 The most important components of this are the \\(R^2\\) (which is listed as Multiple R-squared), the standard errors and p-values for each of your coefficients (Coefficients section), and the overall F-statistic and p-value (the last line). A quick note on p-values: Don't base all of your interpretation on p-values; the \\(R^2\\) and adjusted \\(R^2\\) of a model are more important. The overall p-value relates to how the whole model explains the variance in the data; the coefficient p-value relates to whether the specific coefficient is different from zero. Coefficient-level p-values tend to be rather fragile, and shouldn't be used. D.3.1.1 Plotting linear regressions For a simple linear regression, ggplot can automatically plot the trendline (a.k.a., fitted values) and confidence intervals with geom_smooth(). lizards %&gt;% ggplot() + aes(x = SVL, y = Mass) + geom_point() + geom_smooth(method = &quot;lm&quot;, # use a linear regression se = TRUE, # Include a confidence interval around the line level = .95) # the level of the confidence interval; default = 95% For more complicated models, this approach may not work very well; it can be helpful to calculate the fitted values &amp; confidence intervals from the model object and plot them directly. You can get these values directly with the predict() function. The code below calculates the trendline and 95% confidence interval for the regression, and adds them to a data frame with the original data. simple_reg_preds = simple_reg %&gt;% # Predict fitted values wish 95% confidence intervals predict(interval = &quot;confidence&quot;, level = .95) %&gt;% # The output of predict() is a matrix; that&#39;s hard to work with, so... as_tibble() # we convert the output of predict() to a data frame (tibble) simple_reg_plot_data = lizards %&gt;% select(SVL, Mass) %&gt;% # we only need these columns bind_cols(simple_reg_preds) # adds columns of simple_reg_preds to our lizards View(simple_reg_plot_data) SVL Mass fit lwr upr 61.8 6.46 7.117423 7.058313 7.176533 57.1 5.82 6.699773 6.636126 6.763420 49.1 4.29 5.988879 5.890800 6.086959 51.2 5.29 6.175489 6.088343 6.262634 51.5 5.69 6.202147 6.116487 6.287808 45.3 5.84 5.651205 5.531606 5.770804 49.7 5.91 6.042196 5.947328 6.137065 48.0 5.09 5.891132 5.787013 5.995249 54.9 7.20 6.504277 6.433552 6.575002 52.7 6.66 6.308782 6.228823 6.388740 To plot this, you'd use a combination of geom_line() for the fitted values and geom_ribbon(), which would create the confidence interval region. ggplot(simple_reg_plot_data) + aes(x = SVL) + geom_point(aes(y = Mass), color = &quot;cornflowerblue&quot;) + geom_ribbon(aes(ymin = lwr, ymax = upr), fill = alpha(&quot;black&quot;, .2), # dark fill with 80% transparency (alpha) color = grey(.4), # dark-ish grey border line linetype = 2) + # dotted border line geom_line(aes(y = fit)) You can also use predict() to calculate the respected value of your response variable given new predictor(s); this is useful for interpolation and extrapolation. # Create a data frame with new predictors svl_predictors = tibble(SVL = c(20, 150, 600)) # New predictors mass_predictions = predict(simple_reg, newdata = svl_predictors) # The newdata argument is key here # If unspecified, it uses the original data svl_predictors %&gt;% mutate(Mass_estimate = mass_predictions) ## # A tibble: 3 x 2 ## SVL Mass_estimate ## &lt;dbl&gt; &lt;dbl&gt; ## 1 20 3.40 ## 2 150 15.0 ## 3 600 54.9 For more information, see the help page ?predict.lm. D.3.2 ANOVA Analysis of variance (ANOVA) is a special case of linear model where all of the predictors are all categorical. However, ANOVAs are usually treated differently from regressions for historical reasons. In R, you fit an ANOVA in the same way as a regression (with the lm() command); however, it's common to use the aov() command on the lm's output to reformat the results into a more traditional style. For the simple (one-way) ANOVA follows: # Fit the model wtih a regression simple_anova_lm = lm(Diameter ~ Color_morph, data = lizards) # Reformat into traditional ANOVA style; this is usually done with a pipe as part of the previous step simple_anova = aov(simple_anova_lm) # Look at the ANOVA table simple_anova %&gt;% summary() ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Color_morph 2 50586 25293 985.2 &lt;2e-16 *** ## Residuals 654 16790 26 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The ANOVA table gives us estimates of variation explained by the predictor and the residuals. Note how different the output is from the summary of a regression, even though the underlying math is the same: summary(simple_anova_lm) ## ## Call: ## lm(formula = Diameter ~ Color_morph, data = lizards) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.8837 -3.1176 -0.1176 3.1163 18.1163 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 32.8837 0.3456 95.16 &lt;2e-16 *** ## Color_morphBrown -8.7661 0.4854 -18.06 &lt;2e-16 *** ## Color_morphGreen -21.4086 0.4854 -44.11 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.067 on 654 degrees of freedom ## Multiple R-squared: 0.7508, Adjusted R-squared: 0.75 ## F-statistic: 985.2 on 2 and 654 DF, p-value: &lt; 2.2e-16 Two quick notes about this: While \\(R^2\\) isn't included in the aov() summary, it can be calculated as the total sum of squares of your predictors (in this case, Color_morph) divided by the total sum of squares including the residual; For this example, we have \\(5.0586239\\times 10^{4} / (5.0586239\\times 10^{4} + 1.6790147\\times 10^{4}) = 0.7508007\\). The aov() table provides a line for each predicting factor and the residuals; the lm() summary includes estimates for the intercept and the specific levels of the factors (e.g., Color_morphBrown). These represent the dummy coded variables that R uses under the hood; you don't need to worry about this, but I've got an explanation for them below if you're interested. Dummy coding: R converts an ANOVA into a (multiple) regression model by changing a categorical predictor with \\(n\\) levels into \\(n-1\\) predictor variables that can have values of 0 or 1. The first level of the factor doesn't get a dummy variable; its mean is represented by the regression's intercept. The other dummy coefficients represent the mean difference between the reference level and the level they represent. In our example, the reference category is Blue, so the regression's intercept is the mean Diameter for blue lizards. The average value for brown lizards would be the intercept plus the Color_morphBrown coefficient (and similarly for green). The aov() function reinterprets the dummy coded results as a traditionally categorical analysis. D.3.2.1 ANOVA means &amp; confidence intervals # make a data frame with just your predictors (distinct removes duplicates) color_levels = lizards %&gt;% distinct(Color_morph) color_levels ## # A tibble: 3 x 1 ## Color_morph ## &lt;chr&gt; ## 1 Green ## 2 Brown ## 3 Blue simple_anova_means = # Calculate means &amp; 95% CI predict(simple_anova, newdata = color_levels, interval = &quot;confidence&quot;, level = 0.95) %&gt;% as_tibble() %&gt;% # Convert to data frame bind_cols(color_levels) # add the prediction data as more columns simple_anova_means ## # A tibble: 3 x 4 ## fit lwr upr Color_morph ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 11.5 10.8 12.1 Green ## 2 24.1 23.4 24.8 Brown ## 3 32.9 32.2 33.6 Blue D.3.2.2 Post-hoc tests In general, the ANOVA tests whether a factor (such as color morph) explains a significant amount of variation in the response. To test whether there are significant differences between specific levels of a factor, you need to run post-hoc tests on your ANOVA. A common post-hoc is Tukey's HSD (honest significant difference). simple_anova %&gt;% TukeyHSD() ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = simple_anova_lm) ## ## $Color_morph ## diff lwr upr p adj ## Brown-Blue -8.766074 -9.906219 -7.625929 0 ## Green-Blue -21.408608 -22.548753 -20.268463 0 ## Green-Brown -12.642534 -13.774806 -11.510261 0 You can use the witch argument to specify specific level comparisons, but by default it compares all of them. A traditional way of summarizing post-hoc tests is to assign one or more letters to significantly different levels, where levels with different letters are significantly different from each other. For example, the letter grouping c(&quot;A&quot;, &quot;AB&quot;, &quot;B&quot;, &quot;C&quot;) would indicate that group 1 and group 3 are different from each other, but not from group 2; group 4 is different from everything. In the above example, everything is different, so we could assign the letters A through C. # We&#39;ll store these in a data frame for later use anova_means_letters = simple_anova_means %&gt;% arrange(Color_morph) %&gt;% # These will be plotted alphabetically, so we&#39;ll sort them that way to keep things easy mutate(anova_labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)) anova_means_letters ## # A tibble: 3 x 5 ## fit lwr upr Color_morph anova_labels ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 32.9 32.2 33.6 Blue A ## 2 24.1 23.4 24.8 Brown B ## 3 11.5 10.8 12.1 Green C D.3.2.3 Plotting ANOVAs The basics of plotting ANOVA results was covered in the last part of Section @ref(ggp_discx_conty), but we'll refine them a bit here. The main additions are the use of geom_text() to include the labels above each category and scale_y_continuous, which we use to customize the y axis a bit so that it doesn't cut off the labels. Be sure to indicate in your figure captions what the letters mean. library(ggforce) # for geom_sina() # We&#39;re going to add post-hoc letters to this plot letter_y_position = max(lizards$Diameter) * 1.05 # Put letters at the top anova_plot = ggplot(lizards) + aes(x = Color_morph) + # Color_morph column is in both lizards AND anova_means_letters # Show the raw data geom_sina(aes(y = Diameter), # Diameter column is in lizards data frame color = alpha(&quot;blue&quot;, .2)) + # semi-transparent points geom_errorbar( aes(ymin = lwr, ymax = upr), # columns lwr and upr are in anova_means_letters data = anova_means_letters, # Use the summary data frame instead of lizards color = &quot;black&quot;, width = .3 # How wide the error bars are ) + geom_point(aes(y = fit), # fit column is in anova_means_letters color = &quot;black&quot;, size = 2, data = anova_means_letters) + geom_text(aes(label = anova_labels), # label is the aesthetic used to indicate text y = letter_y_position, # This is a fixed spot, not an aesthetic fontface = &quot;bold&quot;, size = 6, # font size data = anova_means_letters) + scale_y_continuous( # insure the letters aren&#39;t cut off at the top limits = c(NA, letter_y_position), # This is the same as ylim() breaks = seq(from = 0, to = 50, by = 10), # set axis ticks every 10 points name = c(&quot;Perch Diameter (mm)&quot;) # this is the same as ylab() ) + xlab(&quot;Color Morph&quot;) anova_plot D.4 To do (In progress) D.4.1 Comparing two means (t-tests) If you have to do this and I haven't finished this section, just use an ANOVA; mathematically, it works out to more or less the same thing. D.4.2 Advanced workflow tips D.4.3 Model comparisons "],
["tidyr-tutorial.html", "E Wrangling, reshaping, and tidying data with tidyr E.1 Tidy data E.2 Going from many columns to many rows: pivot_longer() E.3 Splitting and merging columns: separate() and unite() E.4 Pivoting multiple columns E.5 Going from many rows to many columns: pivot_wider() E.6 Combining data frames (In Progress)", " E Wrangling, reshaping, and tidying data with tidyr E.1 Tidy data Most of the previous appendices have required you to have your data in a tidy format. Tidy data consist of data frames with the following characteristics: Each column is a different variable Each row is a single observation Each cell is a single value The packages in the tidyverse are generally designed to operate on tidy data; however, other functions may require the data to be in a different shape. It's also frequently convenient to record field data in a non-tidy format. The tidyr package is designed to reshape your data. For more information on tidy data, please see this article. We're going to be using some new datasets for this chapter; if you don't have them already, download them here and put them in your &quot;example_data&quot; directory. library(tidyverse) library(cowplot) theme_set(theme_cowplot()) lizards &lt;- read_csv(&quot;example_data/anoles.csv&quot;) # See Appendix A if you don&#39;t have this data succession_data_wide &lt;- read_csv(&quot;example_data/succession_wide.csv&quot;) yeast_data &lt;- read_csv(&quot;example_data/yeast_data_partial.csv&quot;) E.2 Going from many columns to many rows: pivot_longer() Let's look at the succession data file; this is slightly modified data from Fall 2018, which was collected as part of the first lab (Section @ref(#lab1)). View(succession_data_wide) Type Team Sample Quadrant Distance DBH Acer negundo (Boxwood elder) Bumelia lanuginosa (Gum elastic) Carya illinoiensis (Pecan) Celtis spp. (Hackberry) Fraxinus texana (Texas ash) Juniperus spp. (Juniper) Melia azederach (Chinaberry) Morus rubra (Red mulberry) Populus deltoides (Cottonwood) Prunus caroliniana (Laurel cherry) Quercus buckleyi (Spanish oak) Quercus fusiformis (Live oak) Quercus stellata (Post Oak) Triadica sebifera (Chinese Tallow) Ulmus americana (American elm) Ulmus crassifolia (Cedar elm) P-C A 1 a 4 15.0 NA NA NA NA NA 1 NA NA NA NA NA NA NA NA NA NA P-U A 1 a 4 NA NA NA NA NA NA NA NA NA NA NA NA 1 NA NA NA NA P-C A 1 b 5 16.5 NA NA NA NA NA 1 NA NA NA NA NA NA NA NA NA NA P-U A 1 b 3 NA NA NA NA NA NA NA NA NA NA NA NA 1 NA NA NA NA P-C A 1 c 2 15.0 NA NA NA NA NA 1 NA NA NA NA NA NA NA NA NA NA P-U A 1 c 4 NA NA NA NA NA NA 1 NA NA NA NA NA NA NA NA NA NA P-C A 1 d 4 14.0 NA NA NA 1 NA NA NA NA NA NA NA NA NA NA NA NA P-U A 1 d 2 NA NA NA NA 1 NA NA NA NA NA NA NA NA NA NA NA NA P-C A 2 a 2 21.5 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 1 P-U A 2 a 3 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 1 A quick description of the columns: Type: Contains information on both the habitat type and Canopy/Understory Team, Sample, Quadrant: identifiers for where the data were collected Distance: Distance in meters fromt the central point to the tree DBH: Diameter at breast height for canopy trees 16 species columns: These indicate whether the named species is present with a 1; there should only be a single 1 per row. This clearly does not meet the definition of tidy data; the &quot;Species&quot; variable is split between columns, and the habitat type and tree type are both combined into a single &quot;type&quot; column. The first step to tidying this data is consolidate the last sixteen columns; we're going to use pivot_longer() for that. In its simplest form, pivot_longer() converts several columns into two: one with the original column names, and the other with the original column values. This will result in a data frame with more rows than the original (hence, &quot;longer&quot;). succession_data_wide %&gt;% pivot_longer( # The first argument is the column names you want to reshape # This uses the same syntax of select() and across() from dplyr cols = -c(Type:DBH), # minus sign grabs everything NOT between Type &amp; DBH: names_to = &quot;Species&quot;, # Name of the column that stores the old column names values_to = &quot;is_present&quot;) %&gt;% # Name of the oclumn that stores old cell values View() Type Team Sample Quadrant Distance DBH Species is_present P-C A 1 a 4 15 Acer negundo (Boxwood elder) NA P-C A 1 a 4 15 Bumelia lanuginosa (Gum elastic) NA P-C A 1 a 4 15 Carya illinoiensis (Pecan) NA P-C A 1 a 4 15 Celtis spp. (Hackberry) NA P-C A 1 a 4 15 Fraxinus texana (Texas ash) NA P-C A 1 a 4 15 Juniperus spp. (Juniper) 1 P-C A 1 a 4 15 Melia azederach (Chinaberry) NA P-C A 1 a 4 15 Morus rubra (Red mulberry) NA P-C A 1 a 4 15 Populus deltoides (Cottonwood) NA P-C A 1 a 4 15 Prunus caroliniana (Laurel cherry) NA If you'll notice, the first 16 rows are identical in the Type:DBH columns, while Species and is_present vary. A few alternative ways to do the same thing: # The only difference between these is the .cols argument succession_data_wide %&gt;% pivot_longer( .cols = 7:22, # positions of the columns to pivot names_to = &quot;Species&quot;, values_to = &quot;is_present&quot;) succession_data_wide %&gt;% pivot_longer( -c(Type, Team, Sample, Quadrant, Distance, DBH), # explicitly list names names_to = &quot;Species&quot;, values_to = &quot;is_present&quot;) succession_data_wide %&gt;% pivot_longer( # You can use ranges of column names to keep, though that&#39;s not practical here `Acer negundo (Boxwood elder)`:`Ulmus crassifolia (Cedar elm)`, names_to = &quot;Species&quot;, values_to = &quot;is_present&quot;) succession_data_wide %&gt;% pivot_longer( .cols = contains(&quot;(&quot;), # graps all columns with an open parentheses in them names_to = &quot;Species&quot;, values_to = &quot;is_present&quot;) Note that the .cols argument generally doesn't have quotations around its column names, while the names_to and values_to do. The simplest explanation for it is that the .cols columns already exist in the data, so R knows how to find them; the others don't, so we use quotes to create the names (This isn't entirely true, but the full details are quite complicated and it's a useful rule of thumb for tidyverse functions). One thing to note about our output is that there's a lot of NA values in is_present, indicating species that were not found at each point. We don't really care about those, so let's get rid of them. succession_longer = succession_data_wide %&gt;% pivot_longer( cols = -c(Type:DBH), names_to = &quot;Species&quot;, values_to = &quot;is_present&quot;) %&gt;% filter(!is.na(is_present)) %&gt;% # Remove missing values select(-is_present) # This column is no longer useful View(succession_longer) Type Team Sample Quadrant Distance DBH Species P-C A 1 a 4 15.0 Juniperus spp. (Juniper) P-U A 1 a 4 NA Quercus fusiformis (Live oak) P-C A 1 b 5 16.5 Juniperus spp. (Juniper) P-U A 1 b 3 NA Quercus fusiformis (Live oak) P-C A 1 c 2 15.0 Juniperus spp. (Juniper) P-U A 1 c 4 NA Juniperus spp. (Juniper) P-C A 1 d 4 14.0 Celtis spp. (Hackberry) P-U A 1 d 2 NA Celtis spp. (Hackberry) P-C A 2 a 2 21.5 Ulmus crassifolia (Cedar elm) P-U A 2 a 3 NA Ulmus crassifolia (Cedar elm) (( Add example to practice with genotype data)) E.3 Splitting and merging columns: separate() and unite() To fully tidy this, we need to split the &quot;Type&quot; column into habitat type and tree type columns. The separate() function is useful for this. succession_sep = succession_longer %&gt;% separate(col = Type, # Column to separate; note that the arg is col, not .col into = c(&quot;Habitat&quot;, &quot;Tree_type&quot;), # Names of the new columns to separate into sep = &quot;-&quot;) # the character used to mark the separation View(succession_sep) Habitat Tree_type Team Sample Quadrant Distance DBH Species P C A 1 a 4 15.0 Juniperus spp. (Juniper) P U A 1 a 4 NA Quercus fusiformis (Live oak) P C A 1 b 5 16.5 Juniperus spp. (Juniper) P U A 1 b 3 NA Quercus fusiformis (Live oak) P C A 1 c 2 15.0 Juniperus spp. (Juniper) P U A 1 c 4 NA Juniperus spp. (Juniper) P C A 1 d 4 14.0 Celtis spp. (Hackberry) P U A 1 d 2 NA Celtis spp. (Hackberry) P C A 2 a 2 21.5 Ulmus crassifolia (Cedar elm) P U A 2 a 3 NA Ulmus crassifolia (Cedar elm) Note that the sep argument can be either text or a integer(s); if it's a character vector, the character(s) are removed during the split (as with above). If sep is an integer (or integer vector), then the split is made after that/those position(s) in the text without removing anything. It would also be useful to have a column that specifically identifies the each sample point; currenlty, that information is split between the Habitat, Team, and Sample columns. The unite() function does this (it's the complement of separate). succession_tidy = succession_sep %&gt;% unite(col = &quot;sample_point&quot;, # Name of new colum Habitat, Team, Sample, # columns to unite (note; these are all seaprate args) sep = &quot;-&quot;, # separate the columns with a dash remove = FALSE # by default, unite() removes the columns to separate; this disables that because we want to keep Habitat ) %&gt;% select(-Team, -Sample) succession_tidy %&gt;% View() sample_point Habitat Tree_type Quadrant Distance DBH Species P-A-1 P C a 4 15.0 Juniperus spp. (Juniper) P-A-1 P U a 4 NA Quercus fusiformis (Live oak) P-A-1 P C b 5 16.5 Juniperus spp. (Juniper) P-A-1 P U b 3 NA Quercus fusiformis (Live oak) P-A-1 P C c 2 15.0 Juniperus spp. (Juniper) P-A-1 P U c 4 NA Juniperus spp. (Juniper) P-A-1 P C d 4 14.0 Celtis spp. (Hackberry) P-A-1 P U d 2 NA Celtis spp. (Hackberry) P-A-2 P C a 2 21.5 Ulmus crassifolia (Cedar elm) P-A-2 P U a 3 NA Ulmus crassifolia (Cedar elm) An alternative option to unite() is to use a combination of mutate() and paste(): succession_sep %&gt;% mutate(sample_point = paste(Habitat, Team, Sample, sep = &quot;-&quot;)) %&gt;% select(-Team, -Sample) %&gt;% View() # The column order will be different, but otherwise it&#39;s the same. E.4 Pivoting multiple columns We're going to take a look a dataset from Brauer et al (2008). The experiment tested yeast gene expression under nutrient limitation (for several different nutrients &amp; several different concentrations). View(yeast_data) gene_name bio_process mol_func syst_id G0.05 G0.1 G0.15 G0.2 G0.25 G0.3 N0.05 N0.1 N0.15 N0.2 N0.25 N0.3 P0.05 P0.1 P0.15 P0.2 P0.25 P0.3 S0.05 S0.1 S0.15 S0.2 S0.25 S0.3 L0.05 L0.1 L0.15 L0.2 L0.25 L0.3 U0.05 U0.1 U0.15 U0.2 U0.25 U0.3 SFB2 ER to Golgi transport molecular function unknown YNL049C -0.24 -0.13 -0.21 -0.15 -0.05 -0.05 0.20 0.24 -0.20 -0.42 -0.14 0.09 -0.26 -0.20 -0.22 -0.31 0.04 0.34 -0.51 -0.12 0.09 0.09 0.20 0.08 0.18 0.18 0.13 0.20 0.17 0.11 -0.06 -0.26 -0.05 -0.28 -0.19 0.09 NA biological process unknown molecular function unknown YNL095C 0.28 0.13 -0.40 -0.48 -0.11 0.17 0.31 0.00 -0.63 -0.44 -0.26 0.21 -0.09 -0.04 -0.10 0.15 0.20 0.63 0.53 0.15 -0.01 0.12 -0.15 0.32 0.16 0.09 0.02 0.04 0.03 0.01 -1.02 -0.91 -0.59 -0.61 -0.17 0.18 QRI7 proteolysis and peptidolysis metalloendopeptidase activity YDL104C -0.02 -0.27 -0.27 -0.02 0.24 0.25 0.23 0.06 -0.66 -0.40 -0.46 -0.43 0.18 0.22 0.33 0.34 0.13 0.44 1.29 -0.32 -0.47 -0.50 -0.42 -0.33 -0.30 0.02 -0.07 -0.05 -0.13 -0.04 -0.91 -0.94 -0.42 -0.36 -0.49 -0.47 CFT2 mRNA polyadenylylation* RNA binding YLR115W -0.33 -0.41 -0.24 -0.03 -0.03 0.00 0.20 -0.25 -0.49 -0.49 -0.43 -0.26 0.05 0.04 0.03 -0.04 0.08 0.21 0.41 -0.43 -0.21 -0.33 -0.05 -0.24 -0.27 -0.28 -0.05 0.02 0.00 0.08 -0.53 -0.51 -0.26 0.05 -0.14 -0.01 SSO2 vesicle fusion* t-SNARE activity YMR183C 0.05 0.02 0.40 0.34 -0.13 -0.14 -0.35 -0.09 -0.08 -0.58 -0.14 -0.12 -0.16 0.18 0.21 0.08 0.23 -0.29 -0.70 0.05 0.10 -0.07 -0.10 -0.32 -0.59 -0.13 0.00 -0.11 0.04 0.01 -0.45 -0.09 -0.13 0.02 -0.09 -0.03 PSP2 biological process unknown molecular function unknown YML017W -0.69 -0.03 0.23 0.20 0.00 -0.27 0.17 -0.40 -0.54 -1.19 -0.42 1.89 -0.32 -0.06 -0.62 -0.50 -0.37 NA NA -0.20 -0.09 0.06 -0.19 -0.14 -0.17 -0.07 0.25 -0.21 0.12 -0.11 NA -0.65 0.09 0.06 -0.07 -0.10 RIB2 riboflavin biosynthesis pseudouridylate synthase activity* YOL066C -0.55 -0.30 -0.12 -0.03 -0.16 -0.11 0.04 0.00 -0.63 -0.51 -0.37 -0.24 -0.35 -0.32 -0.39 -0.60 -0.29 -0.25 -0.14 -0.50 -0.19 -0.13 -0.01 -0.04 -0.02 -0.05 0.27 0.24 0.05 0.19 0.07 -0.31 -0.08 0.12 0.05 0.06 VMA13 vacuolar acidification hydrogen-transporting ATPase activity, rotational mechanism YPR036W -0.75 -0.12 -0.07 0.02 -0.32 -0.41 0.11 -0.16 -0.26 -0.42 0.18 0.13 -0.19 -0.25 -0.25 -0.47 -0.24 -0.49 0.09 0.13 0.15 -0.02 0.24 -0.08 -0.11 -0.01 0.15 0.15 0.00 0.03 -0.40 -0.02 0.26 0.31 0.14 0.11 EDC3 deadenylylation-independent decapping molecular function unknown YEL015W -0.24 -0.22 0.14 0.06 0.00 -0.13 0.30 0.07 -0.30 -0.01 0.15 0.13 -0.26 -0.20 -0.22 -0.17 -0.23 -0.38 -0.35 -0.14 0.10 -0.04 0.22 0.02 0.12 -0.01 0.17 0.07 0.10 0.11 0.01 -0.16 0.07 0.20 0.02 0.10 VPS5 protein retention in Golgi* protein transporter activity YOR069W -0.16 -0.38 0.05 0.14 -0.04 -0.01 0.39 0.20 0.27 0.19 0.20 0.06 -0.23 -0.20 -0.07 -0.13 -0.14 -0.42 -0.38 -0.14 0.00 -0.06 0.16 -0.15 -0.20 -0.18 0.11 0.00 0.02 0.09 -0.26 -0.13 -0.10 0.07 -0.04 -0.12 The first four columns are single variables (gene name, biological process, molecular function, and systematic_id). The remaining columns (G0.05 through U0.3) contain TWO variables in their name: the nutrient that was added to the substrate (first letter) and rate at which it was added (the rest). The values in these columns is the gene expression level. To tidy the data, we need to convert these into three columns: Substrate Concentration Gene expression While we could do this with a combination of pivot_longer() and separate(), pivot_longer() can do both tasks at once with a few extra arguments. yeast_data %&gt;% pivot_longer(G0.05:U0.3, names_to = c(&quot;Substrate&quot;, &quot;Concentration&quot;), # The names will go into these columns names_sep = 1, # separate the names between columns after the first character values_to = &quot;Gene_expression&quot;) %&gt;% glimpse() ## Rows: 199,332 ## Columns: 7 ## $ gene_name &lt;chr&gt; &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2… ## $ bio_process &lt;chr&gt; &quot;ER to Golgi transport&quot;, &quot;ER to Golgi transport&quot;, &quot;ER… ## $ mol_func &lt;chr&gt; &quot;molecular function unknown&quot;, &quot;molecular function unk… ## $ syst_id &lt;chr&gt; &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;… ## $ Substrate &lt;chr&gt; &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;… ## $ Concentration &lt;chr&gt; &quot;0.05&quot;, &quot;0.1&quot;, &quot;0.15&quot;, &quot;0.2&quot;, &quot;0.25&quot;, &quot;0.3&quot;, &quot;0.05&quot;, … ## $ Gene_expression &lt;dbl&gt; -0.24, -0.13, -0.21, -0.15, -0.05, -0.05, 0.20, 0.24,… The names_sep argument works exactly like sep in separate(). Notice that Concentration is listed as a character vector (&lt;chr&gt;). It's probably a good idea to have it as a numeric vector instead. The names_transform argument lets you specify a function that can be applied to the names column(s) after they're re-shaped. In this case, we're going to use as.numeric() to convert it into a number. # We&#39;re going to create a list that tells pivot_longer to use the # as.numeric() function on Concentration # a list() is basically a big box you can put any other kind of data structure into # Each item in a list is called an elements; elements can be named or not # This list has one named element; if we wanted to transform more columns, we could include them here as well convert_concentration = list( Concentration = as.numeric # Note there&#39;s no parentheses; this is because we&#39;re identifying the function, not calling it. ) # We&#39;ll talk more about lists later tidy_yeast = yeast_data %&gt;% pivot_longer(G0.05:U0.3, names_to = c(&quot;Substrate&quot;, &quot;Concentration&quot;), names_sep = 1, names_transform = convert_concentration, # We could also have defined the list here values_to = &quot;Gene_expression&quot;) tidy_yeast %&gt;% glimpse() ## Rows: 199,332 ## Columns: 7 ## $ gene_name &lt;chr&gt; &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2&quot;, &quot;SFB2… ## $ bio_process &lt;chr&gt; &quot;ER to Golgi transport&quot;, &quot;ER to Golgi transport&quot;, &quot;ER… ## $ mol_func &lt;chr&gt; &quot;molecular function unknown&quot;, &quot;molecular function unk… ## $ syst_id &lt;chr&gt; &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;, &quot;YNL049C&quot;… ## $ Substrate &lt;chr&gt; &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;… ## $ Concentration &lt;dbl&gt; 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.05, 0.10, 0.15,… ## $ Gene_expression &lt;dbl&gt; -0.24, -0.13, -0.21, -0.15, -0.05, -0.05, 0.20, 0.24,… E.4.1 Combining pivot_longer() with summarise() Here's a particularly powerful combination of tidyverse() functions you can use when you're exploring a new dataset: calculate summary statistics on all of your variables with summarise(across(...)), tidy the results with pivot_longer(), then create a faceted ggplot. lizard_smry_by_color = lizards %&gt;% # Group the data by color morph group_by(Color_morph) %&gt;% summarize( across(where(is.numeric), # For all numeric columns... list(Mean = mean, Med = median, SD = sd) # run mean(), meidan(), and sd() on each group &amp; variable # Note that the list elements follows the pattern Name = function ),N = n() ) # This is outside of across, since it&#39;s only run once per group ## `summarise()` ungrouping output (override with `.groups` argument) glimpse(lizard_smry_by_color) ## Rows: 3 ## Columns: 20 ## $ Color_morph &lt;chr&gt; &quot;Blue&quot;, &quot;Brown&quot;, &quot;Green&quot; ## $ Limb_Mean &lt;dbl&gt; 13.08791, 13.27692, 13.11584 ## $ Limb_Med &lt;dbl&gt; 13.1, 13.1, 12.8 ## $ Limb_SD &lt;dbl&gt; 1.802216, 1.778345, 1.911442 ## $ Mass_Mean &lt;dbl&gt; 6.955116, 7.118371, 6.997738 ## $ Mass_Med &lt;dbl&gt; 6.92, 7.09, 6.99 ## $ Mass_SD &lt;dbl&gt; 1.067424, 1.097275, 1.098401 ## $ Diameter_Mean &lt;dbl&gt; 32.88372, 24.11765, 11.47511 ## $ Diameter_Med &lt;dbl&gt; 33, 24, 11 ## $ Diameter_SD &lt;dbl&gt; 5.495152, 4.539194, 5.132390 ## $ Height_Mean &lt;dbl&gt; 171.2744, 167.2534, 167.7557 ## $ Height_Med &lt;dbl&gt; 184, 172, 175 ## $ Height_SD &lt;dbl&gt; 43.11129, 41.40915, 43.63552 ## $ SVL_Mean &lt;dbl&gt; 60.28000, 61.55928, 60.40633 ## $ SVL_Med &lt;dbl&gt; 59.5, 60.9, 57.9 ## $ SVL_SD &lt;dbl&gt; 8.741475, 8.349435, 9.006788 ## $ Tail_Mean &lt;dbl&gt; 56.90837, 57.97647, 57.75385 ## $ Tail_Med &lt;dbl&gt; 56.3, 58.0, 58.2 ## $ Tail_SD &lt;dbl&gt; 12.46141, 11.69319, 12.25767 ## $ N &lt;int&gt; 215, 221, 221 This creates a data frame with columns for the color, the sample size, and a bunch that follow the pattern Trait_statistic. An ideal way to tidy these data would be reduce these columns into Trait, Mean, Median, and SD. We can do that like this: lizard_smry_tidy = lizard_smry_by_color %&gt;% pivot_longer(-c(Color_morph, N), # exclude the columns names_to = c(&quot;Trait&quot;, &quot;.value&quot;), names_sep = &quot;_&quot;) %&gt;% mutate(SE = SD/sqrt(N)) # may as well calculate standard error while we&#39;re here View(lizard_smry_tidy) Color_morph N Trait Mean Med SD SE Blue 215 Limb 13.087907 13.10 1.802216 0.1229101 Blue 215 Mass 6.955116 6.92 1.067424 0.0727977 Blue 215 Diameter 32.883721 33.00 5.495152 0.3747663 Blue 215 Height 171.274419 184.00 43.111289 2.9401655 Blue 215 SVL 60.280000 59.50 8.741475 0.5961636 Blue 215 Tail 56.908372 56.30 12.461410 0.8498611 Brown 221 Limb 13.276923 13.10 1.778345 0.1196244 Brown 221 Mass 7.118371 7.09 1.097275 0.0738107 Brown 221 Diameter 24.117647 24.00 4.539193 0.3053392 Brown 221 Height 167.253394 172.00 41.409145 2.7854805 This call didn't have a values_to argument in it; instead, one of the names_to was listed as &quot;.value&quot;. This is a special indicator that tells pivot_longer to create one column for each matching name and place the corresponding values into it. From here, you can make a nice little summary statistic plot: lizard_smry_tidy %&gt;% ggplot(aes(x = Color_morph)) + facet_wrap(~Trait, scales = &quot;free_y&quot;) + # SD: geom_linerange(aes(ymin = Mean - SD, ymax = Mean + SD), color = &quot;cornflowerblue&quot;) + # Confidence Interval: geom_errorbar(aes(ymin = Mean - SE * 1.96, ymax = Mean + SE * 1.96), color = &quot;red&quot;, width = .3) + # Mean geom_point(aes(y = Mean), size = 2) + ylab(&quot;Trait Mean, SD, and 95% CI&quot;) E.5 Going from many rows to many columns: pivot_wider() (In progress) E.6 Combining data frames (In Progress) E.6.1 Binding rows E.6.2 Binding columns by position E.6.3 Joining rows by value "]
]
